<!doctype html>
<html lang="en">
    <head>
    <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<title>Revisiting the file server | Die wunderbare Welt von Isotopp</title>
<meta name="description" content="Kris Köhntopp&#39;s blog (Fedi: @isotoppinfosec.exchange)">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon" href="icon.png">
<link rel="icon" href="favicon.ico" type="image/ico">
<link rel="shortcut icon" href="favicon.ico">
<link rel="canonical" href="https://blog.koehntopp.info/2022/02/06/revisiting-the-file-server.html">

<link rel="alternate" type="application/rss+xml" href='https://blog.koehntopp.info/feed.xml' title="Die wunderbare Welt von Isotopp">
<link rel="alternate" type="application/rss+xml" href='https://blog.koehntopp.info/tags/mysql/feed.xml' title="Feed: mysql Articles for Die wunderbare Welt von Isotopp">
<link rel="alternate" type="application/rss+xml" href='https://blog.koehntopp.info/tags/review/feed.xml' title="Feed: review Articles for Die wunderbare Welt von Isotopp">


<meta name="generator" content="Hugo 0.145.0">
<meta property="og:title" content='Revisiting the file server | Die wunderbare Welt von Isotopp' />
<meta property="og:site_name" content='Die wunderbare Welt von Isotopp' />
<meta property="og:locale" content="en_US" />
<meta name="description" content='Kris Köhntopp&#39;s blog (Fedi: @isotoppinfosec.exchange)' />
<meta property="og:description" content='Kris Köhntopp&#39;s blog (Fedi: @isotoppinfosec.exchange)' />
<meta property="og:url" content="https://blog.koehntopp.info/2022/02/06/revisiting-the-file-server.html" />
<meta property="og:type" content="article" />
<meta name="article:published_time" content='2022-02-06T21:06:03&#43;01:00' />
<meta name="fediverse:creator" content="@isotopp@infosec.exchange">
<meta property="og:image" content='https://blog.koehntopp.info/assets/img/background/rijksmuseum.jpg' />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:creator" content='@isotopp@infosec.exchange' />
<meta property="twitter:title" content='Revisiting the file server' />
<meta property="twitter:description" content='Kris Köhntopp&#39;s blog (Fedi: @isotoppinfosec.exchange)' />
<meta property="twitter:image" content='https://blog.koehntopp.info/assets/img/background/rijksmuseum.jpg' />


    



<link rel="stylesheet" href="https://blog.koehntopp.info/style.min.dd9d518fe6cac55191b6af874e18327dff051055754ffc7e106131baf826e6d3.css">


    </head>
    <body>
        

        <nav class="navbar navbar-expand-lg navbar-light px-lg-4 pt-lg-4">
    <div class="container-fluid">
        <a class="navbar-brand justify-content-center" href="https://blog.koehntopp.info/" rel="home" title="Die wunderbare Welt von Isotopp">
            <img alt="Kris" height='48' width='48' src='/assets/img/avatars/isotopp.jpg' class='p-0 me-3 d-block d-lg-inline'>
            <span class='h4 d-block d-lg-inline'>Die wunderbare Welt von Isotopp</span>
        </a>

        <button class="navbar-toggler ms-auto" type="button" data-bs-toggle="collapse"
                data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
                aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse text-center" id="navbarSupportedContent">
            <ul class="navbar-nav ms-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="/about/">
                        <span class="">About</span>
                        
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="/contribute/">
                        <span class="">Contribute</span>
                        
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="/search/">
                        <span class=""><svg class='bi' height='1.5rem' width='1.5rem' fill='currentColor'><use xlink:href='/bootstrap-icons.svg#search'/></svg></span>
                        
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="/tags/">
                        <span class=""><svg class='bi' width='1.5rem' height='1.5rem' fill='currentColor'><use xlink:href='/bootstrap-icons.svg#tags-fill'/></svg></span>
                        
                    </a>
                </li>
                
            </ul>
            
        </div>

    </div>
</nav>


        <main role="main" class="container-fluid p-0">

            









<div class="page">
	<article class="revisiting-the-file-server-page">
		<div class='row  justify-content-center text-center my-4 mx-0'>
			<header class="headerbanner">
				<div class='col'>
					<h1 class="title mb-lg-4 text-white">
						Revisiting the file server
					</h1>
					<div class='text-uppercase text-light' style='letter-spacing: 0.1rem;'>
						<img alt='@isotopp@infosec.exchange image' src='/assets/img/avatars/isotopp.jpg' class='me-1 p-0'
						     style='width: 1.9rem; border-radius: 1rem;'>
						<a href="https://infosec.exchange/@isotopp" class='text-light text-decoration-none'>
							Kristian Köhntopp
						</a>
						
						<span class='d-none d-lg-inline'>-</span>
						<div class='d-block d-lg-inline'>February 6, 2022</div>
						
					</div>
				</div>
				
				<img alt='a featured image' src="/assets/img/background/rijksmuseum.jpg">
				
			</header>
		</div>

		<div class='row justify-content-center mx-0'>
			<div class='col-lg-4 text-center text-lg-start'>
				
				<div>
					<div class='letter-spacing-01 text-uppercase text-secondary'>
						Previous Post
					</div>
					<a class='text-decoration-none' href="https://blog.koehntopp.info/2022/02/01/time-to-grow-the-file-server.html">Time to grow the file server</a>
				</div>
				
			</div>

			<div class='col-lg-4 text-lg-end mt-5 mt-lg-0 text-center'>
				
				<div>
					<div class='letter-spacing-01 text-uppercase text-secondary'>
						Next Post
					</div>
					<a class='text-decoration-none' href="https://blog.koehntopp.info/2022/02/16/databases-how-large-is-too-large.html">Databases: How large is too large?</a>
				</div>
				
			</div>
		</div>

		<div class='row justify-content-center mx-0 mt-3 mb-5'>
			<div class="col-lg-8 mb-3">
				
			</div>
			<div class='col-lg-8'>
				<p>The new disks in the file server had synchronized nicely, and that resulted in an interesting graph:</p>
<p><p class="md__image">
  <img src="/uploads/2022/02/disk-sync.jpg" alt=""  />
</p>

</p>
<p><em>Sectors on the outer part of a hard disk are transferred faster than inner sectors. You can see how the disk speed halves between the outermost and the innermost part.</em></p>
<p>While watching, I decided on a whim that I wanted to convert the entire setup from using Linux <code>mdraid</code> to <code>dmraid</code>, the LVM2 implementation of RAID1.
It is essentially the same code, but integrated into LVM2 instead of using <code>mdadm</code> for control.</p>
<p>I had already experimented with <code>dmraid</code> before, as documented in <a href="/2019/12/02/cloning-and-splitting-logical-volumes.html">an earlier article</a>

, and that was <a href="/2019/12/03/trying-lvmraid-for-real.html">not without problems</a>

.
But since the array would contain no original data, only backups, I decided to give it a try.</p>
<p>So here we go:</p>
<h1 id="destroying-the-mdraid">
    <a href="#destroying-the-mdraid">
	Destroying the <code>mdraid</code>
    </a>
</h1>
<p>I had created a RAID-1 pair of the disks <code>/dev/sdb2</code> and <code>/dev/sdc2</code> under the name <code>/dev/md126</code>, then added <code>/dev/md126</code> to the <code>hdd</code> volume group. In order to get the disks back, I had to undo this.</p>
<p>So we need to check if the <code>/dev/md126</code> PV is empty:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvdisplay --map /dev/sda2
</span></span><span class="line"><span class="cl"><span class="go">  --- Physical volume ---
</span></span></span><span class="line"><span class="cl"><span class="go">  PV Name               /dev/md126
</span></span></span><span class="line"><span class="cl"><span class="go">  VG Name               hdd
</span></span></span><span class="line"><span class="cl"><span class="go">  PV Size               9.09 TiB / not usable 1022.98 MiB
</span></span></span><span class="line"><span class="cl"><span class="go">  Allocatable           yes
</span></span></span><span class="line"><span class="cl"><span class="go">  PE Size               1.00 GiB
</span></span></span><span class="line"><span class="cl"><span class="go">  Total PE              9303
</span></span></span><span class="line"><span class="cl"><span class="go">  Free PE               9303
</span></span></span><span class="line"><span class="cl"><span class="go">  Allocated PE          0
</span></span></span><span class="line"><span class="cl"><span class="go">  PV UUID               ...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">  --- Physical Segments ---
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 1 to 9302:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span></code></pre></div><p>That&rsquo;s fine. We can remove the pair from the volume group again, remove the LVM2 label, and then stop and destroy the raid:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> vgreduce hdd /dev/md126
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> pvremove /dev/md126
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> mdadm --stop /dev/md126
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> mdadm --remove /dev/md126
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> mdadm --zero-superblock /dev/sdb2 /dev/sdc2
</span></span></code></pre></div><p>That did not work: An Ubuntu Component, <code>os-prober</code>, took possession of the devices after removing the RAID-1. I had to actually uninstall the component and remove the <code>osprober</code> from devicemapper before I could continue:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> <span class="c1">### After uninstalling os-prober:</span>
</span></span><span class="line"><span class="cl"><span class="gp">#</span> dmsetup ls
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> dmsetup remove osprober-linux-sdb2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> dmsetup remove osprober-linux-sdc2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> mdadm --zero-superblock /dev/sdb2 /dev/sdc2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><h1 id="preparing-the-disks-individually-for-lvm2">
    <a href="#preparing-the-disks-individually-for-lvm2">
	Preparing the disks individually for LVM2
    </a>
</h1>
<p>Only then I could continue, add the disks to LVM2 and extend the <code>hdd</code> volume group:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvcreate /dev/sd<span class="o">{</span>b,c<span class="o">}</span><span class="m">2</span>
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> vgextend hdd /dev/sd<span class="o">{</span>b,c<span class="o">}</span><span class="m">2</span>
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>We now have a very weird, asymmetric VG in which there is a single 9.09 TiB raid PV and two 9.09 TiB unraided PVs.
Our next objective is to evacuate the raided PV, and then destroy this as well, adding the disks back unraided.
This will result in a 36 TiB total VG.</p>
<h1 id="evacuating-devmd127-to-unraid-it">
    <a href="#evacuating-devmd127-to-unraid-it">
	Evacuating <code>/dev/md127</code> to unraid it
    </a>
</h1>
<p>This is going to take a long time. We need to do this in a <code>tmux</code> session:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvmove /dev/md127 /dev/sdb2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>This will, over the course of about one day, move all physical extents from <code>/dev/md127</code> to <code>/dev/sdb2</code>.
This exposes us to disk failure, as for the moment the data on <code>/dev/sdb2</code> is unraided.</p>
<h1 id="restoring-redundancy">
    <a href="#restoring-redundancy">
	Restoring redundancy
    </a>
</h1>
<p>There are two kinds of backup on this disk pack:
A number of Apple Time Machine targets and an Acronis Windws target, <code>tm_*</code> and <code>win_*</code>, and an internal backup that is being produced by a cron job, <code>rsync</code>ing data from the internal SSDs to the disks, <code>/backup</code>.</p>
<p>I decided to destroy the <code>/backup</code> LV and recreate it as a <code>raid10</code> across all 4 disks.
This was relatively easy, and worked immediately &ndash; it just took a few hours for the backup job to run from scratch.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> umount /backup
</span></span><span class="line"><span class="cl"><span class="gp">#</span> lvremove /dev/hdd/backup
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> lvcreate --type raid10 -i2 -m1 -n backup -L4T hdd
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> mkfs -t xfs -f /dev/hdd/backup
</span></span><span class="line"><span class="cl"><span class="gp">#</span> mount /backup
</span></span><span class="line"><span class="cl"><span class="gp">#</span> /root/bin/make-backup
</span></span></code></pre></div><p>For the Time Machine and Acronis targets, I decided to <code>lvconvert</code> them to <code>raid1</code>.
<a href="/2019/12/02/cloning-and-splitting-logical-volumes.html">As stated before</a>

, there are two competing implementations of of RAID in LVM2, <code>--type mirror</code> and <code>--type raid1</code>.
The <code>mirror</code> implementation is very extremely strongly deprecated, the <code>raid1</code> implementation is okay, because it uses the same code as  <code>mdraid</code> internally.</p>
<p>We need to make sure to specify <code>--type raid1</code> in the <code>lvconvert</code> command to ensure the proper type is being used.
For each target we do</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> lvconvert --type raid1 -m1 /dev/hdd/tm_...
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>This returns immediately, and begins to sync the mirror halves internally.
If we at this point convert all Time Machine and Acronis targets at once, the sync speed is abysmally slow, because of disk head treshing.
There is no way to stop this.
The only option is to slow down all resyncs except one:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> <span class="c1">### for all targets, slow them down to minimum</span>
</span></span><span class="line"><span class="cl"><span class="gp">#</span>  lvchange --maxrecoveryspeed<span class="o">=</span>1k /dev/hdd/tm_...
</span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">#</span> <span class="c1">### for one target, set a very large max speed:</span>
</span></span><span class="line"><span class="cl"><span class="gp">#</span> lvchange --maxrecoveryspeed<span class="o">=</span>100000k /dev/hdd/tm_...
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>and then let one <code>tm_...</code> target finish.
After that, we can increase the max sync speed for the next target, and so on.</p>
<p>This is what a <code>--type raid1</code> looks like in <code>lsblk</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> lsblk /dev/sda2 /dev/sdg2
</span></span><span class="line"><span class="cl"><span class="go">NAME                     MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
</span></span></span><span class="line"><span class="cl"><span class="go">sda2                       8:2    0  9.1T  0 part
</span></span></span><span class="line"><span class="cl"><span class="go">├─hdd-tm_aircat_rmeta_0  253:18   0    1G  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">│ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">├─hdd-tm_aircat_rimage_0 253:25   0    1T  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">│ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">sdg2                       8:98   0  9.1T  0 part
</span></span></span><span class="line"><span class="cl"><span class="go">├─hdd-tm_aircat_rmeta_1  253:26   0    1G  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">│ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">├─hdd-tm_aircat_rimage_1 253:30   0    1T  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">│ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>That is, for each leg of the RAID1 you get a <code>rimage</code> and <code>rmeta</code> LV.
If the LVs are named <code>mimage_0</code> and <code>mimage1</code> and there is no <code>rmeta</code> but only a single <code>mlog</code>, this is not <code>--type raid</code>, but the deprecated <code>mirror</code> implementation.
This is not good, and should be converted to <code>--type raid1</code>.</p>
<p>There is no way to convert a <code>linear</code> or <code>raid1</code> to <code>raid10</code>, unfortunately.</p>
<h1 id="checking-status-and-progress">
    <a href="#checking-status-and-progress">
	Checking status and progress
    </a>
</h1>
<p>A few handy commands to check the status and the progress of the conversion.</p>
<p>Monitor the sync state of the devices:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> lvs -a -o name,copy_percent,devices,raid_max_recovery_rate,raid_mismatch_count,raid_sync_action hdd
</span></span></code></pre></div><p>The <code>-a</code> shows all the LVs, even the internal ones.
We are interested into the <code>copy_percent</code> to see the progress of the sync.
We also want the <code>max_recovery_rate</code>, because we might have throttled it with the <code>lvchange</code> command mentioned above.
And we want to see the <code>raid_mismatch_count</code> and <code>raid_sync_action</code> to see what&rsquo;s going on.</p>
<p>Of course, the ubiquitous <code>lvs -a -o +devices</code> is always handy to get an impression of the entire VG:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> lvs -a -o +devices hdd
</span></span><span class="line"><span class="cl"><span class="go">  LV                   VG  Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert Devices
</span></span></span><span class="line"><span class="cl"><span class="go">  backup               hdd rwi-aor---   4.00t                                    100.00           backup_rimage_0(0),backup_rimage_1(0),backup_rimage_2(0),backup_rimage_3(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rimage_0]    hdd iwi-aor---   2.00t                                                     /dev/sdb2(2561)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rimage_1]    hdd iwi-aor---   2.00t                                                     /dev/sdc2(1)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rimage_2]    hdd iwi-aor---   2.00t                                                     /dev/sda2(1026)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rimage_3]    hdd iwi-aor---   2.00t                                                     /dev/sdg2(3158)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rmeta_0]     hdd ewi-aor---   1.00g                                                     /dev/sdb2(2560)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rmeta_1]     hdd ewi-aor---   1.00g                                                     /dev/sdc2(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rmeta_2]     hdd ewi-aor---   1.00g                                                     /dev/sda2(1025)
</span></span></span><span class="line"><span class="cl"><span class="go">  [backup_rmeta_3]     hdd ewi-aor---   1.00g                                                     /dev/sdg2(3157)
</span></span></span><span class="line"><span class="cl"><span class="go">  tm_aircat            hdd rwi-aor---   1.00t                                    100.00           tm_aircat_rimage_0(0),tm_aircat_rimage_1(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_aircat_rimage_0] hdd iwi-aor---   1.00t                                                     /dev/sda2(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_aircat_rimage_1] hdd iwi-aor---   1.00t                                                     /dev/sdg2(2133)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_aircat_rmeta_0]  hdd ewi-aor---   1.00g                                                     /dev/sda2(1024)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_aircat_rmeta_1]  hdd ewi-aor---   1.00g                                                     /dev/sdg2(2132)
</span></span></span><span class="line"><span class="cl"><span class="go">  tm_joram             hdd rwi-aor---   1.50t                                    100.00           tm_joram_rimage_0(0),tm_joram_rimage_1(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_joram_rimage_0]  hdd iwi-aor---   1.50t                                                     /dev/sdc2(2049)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_joram_rimage_1]  hdd iwi-aor---   1.50t                                                     /dev/sdb2(1)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_joram_rmeta_0]   hdd ewi-aor---   1.00g                                                     /dev/sdc2(3585)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_joram_rmeta_1]   hdd ewi-aor---   1.00g                                                     /dev/sdb2(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  tm_mini              hdd rwi-aor--- 512.00g                                    100.00           tm_mini_rimage_0(0),tm_mini_rimage_1(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_mini_rimage_0]   hdd iwi-aor--- 512.00g                                                     /dev/sdb2(8786)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_mini_rimage_1]   hdd iwi-aor--- 512.00g                                                     /dev/sdc2(4609)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_mini_rmeta_0]    hdd ewi-aor---   1.00g                                                     /dev/sdb2(9298)
</span></span></span><span class="line"><span class="cl"><span class="go">  [tm_mini_rmeta_1]    hdd ewi-aor---   1.00g                                                     /dev/sdc2(4608)
</span></span></span><span class="line"><span class="cl"><span class="go">  win_kk               hdd rwi-aor---   2.08t                                    100.00           win_kk_rimage_0(0),win_kk_rimage_1(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [win_kk_rimage_0]    hdd iwi-aor---   2.08t                                                     /dev/sdg2(2)
</span></span></span><span class="line"><span class="cl"><span class="go">  [win_kk_rimage_1]    hdd iwi-aor---   2.08t                                                     /dev/sda2(3075)
</span></span></span><span class="line"><span class="cl"><span class="go">  [win_kk_rmeta_0]     hdd ewi-aor---   1.00g                                                     /dev/sdg2(0)
</span></span></span><span class="line"><span class="cl"><span class="go">  [win_kk_rmeta_1]     hdd ewi-aor---   1.00g                                                     /dev/sda2(3074)
</span></span></span></code></pre></div><p>Another way to look at the construct is <code>lsblk</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> lsblk /dev/sd<span class="o">{</span>a,b,c,g<span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="go">NAME                       MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
</span></span></span><span class="line"><span class="cl"><span class="go">sda                          8:0    0  9.1T  0 disk
</span></span></span><span class="line"><span class="cl"><span class="go">├─sda1                       8:1    0   10G  0 part
</span></span></span><span class="line"><span class="cl"><span class="go">└─sda2                       8:2    0  9.1T  0 part
</span></span></span><span class="line"><span class="cl"><span class="go">  ├─hdd-tm_aircat_rmeta_0  253:18   0    1G  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">  │ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">  ├─hdd-tm_aircat_rimage_0 253:25   0    1T  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">  │ └─hdd-tm_aircat        253:20   0    1T  0 lvm  /export/tm_aircat
</span></span></span><span class="line"><span class="cl"><span class="go">  ├─hdd-backup_rmeta_2     253:35   0    1G  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">  │ └─hdd-backup           253:39   0    4T  0 lvm  /backup
</span></span></span><span class="line"><span class="cl"><span class="go">  ├─hdd-backup_rimage_2    253:36   0    2T  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">  │ └─hdd-backup           253:39   0    4T  0 lvm  /backup
</span></span></span><span class="line"><span class="cl"><span class="go">  ├─hdd-win_kk_rmeta_1     253:42   0    1G  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">  │ └─hdd-win_kk           253:23   0  2.1T  0 lvm  /export/win_kk
</span></span></span><span class="line"><span class="cl"><span class="go">  └─hdd-win_kk_rimage_1    253:43   0  2.1T  0 lvm
</span></span></span><span class="line"><span class="cl"><span class="go">    └─hdd-win_kk           253:23   0  2.1T  0 lvm  /export/win_kk
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><h1 id="what-is-where">
    <a href="#what-is-where">
	What is where?
    </a>
</h1>
<p>And of course, we might be interested into the actual distribution of data on the disk:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvdisplay --map /dev/sd<span class="o">{</span>a,b,c,g<span class="o">}</span><span class="m">2</span>
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">  --- Physical volume ---
</span></span></span><span class="line"><span class="cl"><span class="go">  PV Name               /dev/sdg2
</span></span></span><span class="line"><span class="cl"><span class="go">  VG Name               hdd
</span></span></span><span class="line"><span class="cl"><span class="go">  PV Size               9.09 TiB / not usable 1022.98 MiB
</span></span></span><span class="line"><span class="cl"><span class="go">  Allocatable           yes
</span></span></span><span class="line"><span class="cl"><span class="go">  PE Size               1.00 GiB
</span></span></span><span class="line"><span class="cl"><span class="go">  Total PE              9303
</span></span></span><span class="line"><span class="cl"><span class="go">  Free PE               4098
</span></span></span><span class="line"><span class="cl"><span class="go">  Allocated PE          5205
</span></span></span><span class="line"><span class="cl"><span class="go">  PV UUID               ...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">  --- Physical Segments ---
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 0 to 0:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/win_kk_rmeta_0
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 0
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 1 to 1:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 2 to 2131:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/win_kk_rimage_0
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 2129
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 2132 to 2132:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/tm_aircat_rmeta_1
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 0
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 2133 to 3156:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/tm_aircat_rimage_1
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 1023
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 3157 to 3157:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/backup_rmeta_3
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 0
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 3158 to 5205:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/backup_rimage_3
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 2047
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 5206 to 9302:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span></code></pre></div><h1 id="defragmenting-devsdb2">
    <a href="#defragmenting-devsdb2">
	Defragmenting <code>dev/sdb2</code>
    </a>
</h1>
<p>Due to the way we created things, initially all <code>RAID1</code> have the left leg of their mirror on <code>/dev/sdb2</code>, because that is where we <code>pvmove</code>ed stuff initially.
We might want to fix that, and push a few things over.
I did that, as can be seen by the <code>lvs -a -o +devices hdd</code> output further up.</p>
<p>Here is how:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvmove -n &lt;LV_name&gt; /dev/sdb2 /dev/sdg2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>This will move all data belonging to <code>LV_name</code> that is currently on <code>/dev/sdb2</code> to <code>/dev/sdg2</code>.
Again, this will take a long time, and there should be no other sync action currently active for maximum speed, as rotating disks slow down a lot when there are competing disk seeks.</p>
<p>This leaves us with a fragmented <code>/dev/sdb2</code> and LVs on higher numbered extents, which are a lot slower than lower numbered extents.
We could fix that as well, again with <code>pvmove</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> pvdisplay --map /dev/sdc2
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 3587 to 3596:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/keks_rimage_1
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 9
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 3597 to 4607:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> pvmove -n keks --alloc anywhere /dev/sdc2:3587-3596 /dev/sdc2:4000-4009
</span></span><span class="line"><span class="cl"><span class="go"> /dev/sdc2: Moved: 0.00%
</span></span></span><span class="line"><span class="cl"><span class="go"> ...
</span></span></span><span class="line"><span class="cl"><span class="go"> /dev/sdc2: Moved: 100.00%
</span></span></span></code></pre></div><p>This moves extents internally on a drive.
<code>pvmove</code> normally refuses to do this, so we have to tell it to shut up about this, using <code>--alloc anywhere</code>.
We then use extent-addressing to change the map manually:
We move data from <code>/dev/sdc2:3587-3596</code>, the entire <code>keks</code> Test-LV, somewhere into the <code>FREE</code> space, <code>4000-4009</code>.
The result looks like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 3587 to 3999:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 4000 to 4009:
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical volume      /dev/hdd/keks_rimage_1
</span></span></span><span class="line"><span class="cl"><span class="go">    Logical extents     0 to 9
</span></span></span><span class="line"><span class="cl"><span class="go">  Physical extent 4010 to 4607:
</span></span></span><span class="line"><span class="cl"><span class="go">    FREE
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">#</span> lvremove /dev/hdd/keks
</span></span><span class="line"><span class="cl"><span class="go">Do you really want to remove and DISCARD active logical volume hdd/keks? [y/n]: y
</span></span></span><span class="line"><span class="cl"><span class="go">  Logical volume &#34;keks&#34; successfully removed
</span></span></span></code></pre></div><p>And that concludes a largely pointless refactoring of my home storage, because I could.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">#</span> vgs
</span></span><span class="line"><span class="cl"><span class="go">  VG     #PV #LV #SN Attr   VSize   VFree
</span></span></span><span class="line"><span class="cl"><span class="go">  data     2  15   0 wz--n-   7.28t   3.25t
</span></span></span><span class="line"><span class="cl"><span class="go">  hdd      4   5   0 wz--n-  36.34t  18.17t
</span></span></span><span class="line"><span class="cl"><span class="go">  system   1   4   0 wz--n- 466.94g 234.94g
</span></span></span></code></pre></div><h1 id="do-you-have-checksums">
    <a href="#do-you-have-checksums">
	Do you have checksums?
    </a>
</h1>
<p>Not yet.
There is a thing called <code>dm-integrity</code>, though, and a <a href="https://gist.github.com/MawKKe/caa2bbf7edcc072129d73b61ae7815fb" target="_blank" rel="noopener">gist</a>

 that I have to try. The <a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/dm-integrity.html" target="_blank" rel="noopener">dm-integrity Documentation</a>

 is here.
And <code>integritysetup</code> is part of <code>cryptsetup-bin</code> on Ubuntu.</p>

			</div>
		</div>

		
		
		<div class='row justify-content-center py-3 mb-3 mx-0'>
			<div class='col-lg-8 text-center'>
				<span class='letter-spacing-01 text-uppercase text-secondary me-2'>Tags</span>
				
				<a href="/tags/#lang_en" class='btn btn-sm btn-outline-primary mb-1'>
				<svg class="bi" width="1rem" height="1rem" fill="currentColor">
					<use xlink:href="/bootstrap-icons.svg#tag-fill"></use>
				</svg>
				lang_en
				</a>
				
				<a href="/tags/#computer" class='btn btn-sm btn-outline-primary mb-1'>
				<svg class="bi" width="1rem" height="1rem" fill="currentColor">
					<use xlink:href="/bootstrap-icons.svg#tag-fill"></use>
				</svg>
				computer
				</a>
				
				<a href="/tags/#linux" class='btn btn-sm btn-outline-primary mb-1'>
				<svg class="bi" width="1rem" height="1rem" fill="currentColor">
					<use xlink:href="/bootstrap-icons.svg#tag-fill"></use>
				</svg>
				linux
				</a>
				
				<a href="/tags/#storage" class='btn btn-sm btn-outline-primary mb-1'>
				<svg class="bi" width="1rem" height="1rem" fill="currentColor">
					<use xlink:href="/bootstrap-icons.svg#tag-fill"></use>
				</svg>
				storage
				</a>
				
			</div>
		</div>

		
		
		
		
		<div class='row justify-content-center py-3 mb-3 mx-0'>
			<div class='col-lg-8 text-center'>
				<a href="https://github.com/isotopp/isotopp.github.io/edit/main/content/posts/2022-02-06-revisiting-the-file-server.md"
				   rel="noopener noreferrer" target="_blank">
					<span class='letter-spacing-01 text-uppercase text-secondary me-2'>Suggest Changes</span>
				</a>
			</div>
		</div>
		

		<div class='row justify-content-center mx-0'>
			<div class='col-lg-4 text-center text-lg-start'>
				
				<div>
					<div class='letter-spacing-01 text-uppercase text-secondary'>
						Previous Post
					</div>
					<a class='text-decoration-none' href="https://blog.koehntopp.info/2022/02/01/time-to-grow-the-file-server.html">Time to grow the file server</a>
				</div>
				
			</div>

			<div class='col-lg-4 text-lg-end mt-5 mt-lg-0 text-center'>
				
				<div>
					<div class='letter-spacing-01 text-uppercase text-secondary'>
						Next Post
					</div>
					<a class='text-decoration-none' href="https://blog.koehntopp.info/2022/02/16/databases-how-large-is-too-large.html">Databases: How large is too large?</a>
				</div>
				
			</div>
		</div>


		
	</article>
</div>



            <footer class='row justify-content-center mb-4 pb-4 mx-0'>
  <div class='col-8 text-center'>
    <div>
      A collection of old stuff, new stuff and random stuff.
    </div>
    <div class='row text-primary mt-4'>
      <div class='col'>

        <a href='/feed.xml' title='Follow RSS feed' class='me-3 text-decoration-none'>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#rss-fill'/>
          </svg>
        </a>

        <a href='mailto:kristian.koehntopp@gmail.com' title='Email' class='me-3 text-decoration-none'>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#envelope'/>
          </svg>
        </a>

        <a href='https://github.com/isotopp' title='Follow on GitHub' class='me-3 text-decoration-none'>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#github'/>
          </svg>
        </a>

        <a rel="me" href="https://infosec.exchange/@isotopp" title='Follow on Mastodon' class='me-3 text-decoration-none'>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#mastodon'/>
          </svg>
        </a>

        
        <a href='http://steamcommunity.com/id/ixotopp' title='Follow on Steam' class='me-3 text-decoration-none'>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#steam'/>
          </svg>
        </a>

        

        <a href='https://www.youtube.com/user/isotopp' title='Follow on YouTube' class=''>
          <svg class='bi' height='2.5rem' width='2.5rem' fill='currentColor'>
            <use xlink:href='/bootstrap-icons.svg#youtube'/>
          </svg>
        </a>
      </div>
    </div>
  </div>
</footer>


        </main>

	





<script src="https://blog.koehntopp.info/js/bootstrap.js"></script>




<script src="https://blog.koehntopp.info/js/lunr.js"></script>





<script src="https://blog.koehntopp.info/js/app.js"></script>


    </body>
</html>
