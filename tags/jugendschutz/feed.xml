<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jugendschutz on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/jugendschutz.html</link>
    <description>Recent content in Jugendschutz on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Jul 2024 09:45:23 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/jugendschutz/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>JusProg ist nur der Anfang</title>
      <link>https://blog.koehntopp.info/2024/01/16/jusprog-ist-nur-der-anfang.html</link>
      <pubDate>Tue, 16 Jan 2024 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2024/01/16/jusprog-ist-nur-der-anfang.html</guid>
      <description>&lt;p&gt;Es ist also dies hier passiert:
&lt;a href=&#34;https://lilithwittmann.medium.com/wen-sch%C3%BCtzen-eigentlich-jugendschutzprogramme-7f13fb8ebc51&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wen schützen eigentlich Jugendschutzprogramme?&lt;/a&gt;


Lilith Wittmann nimmt den Filter von JusProg e.V. auseinander und es ist eine einzige Eskalation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Die Filterkriterien sind nicht nachvollziehbar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gefilterte Websites wissen nichts von ihrer Einstufung.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Die Einstufungen sind systematisch falsch, und man kann eine politische Richtung erkennen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Das ist JusProg e.V. aber eigentlich egal, denn es sind ja auch viele Websites nicht geblockt worden.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Die Website für den Download ist ein kompromittiertes Wordpress.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Eventuell hat das Wordpress Malware verteilt, aber JusProg e.V. kann das nicht ausschließen und auch nicht nachvollziehen, weil sie die Software nicht im Griff hat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Die Infektion mit Malware war JusProg e.V. bekannt, und sie haben versucht, daran herumzudoktern, aber erfolglos. Das besorgt sie aber nicht besonders.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Was passiert hier, und warum zerfetzt Lilith Wittmann ausgerechnet JusProg?
Dazu müssen wir ein wenig ausholen und fast 30 Jahre zurückschauen.&lt;/p&gt;
&lt;h1 id=&#34;warum-jugendschutz&#34;&gt;
    &lt;a href=&#34;#warum-jugendschutz&#34;&gt;
	Warum Jugendschutz?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Der Jugendschutz im Allgemeinen ist eine im Grundgesetz verankerte staatliche Aufgabe.
Er ist nicht einfach etwas, das der Staat nicht machen kann.&lt;/p&gt;
&lt;p&gt;Ausnahmen vom Jugendschutz sind klar geregelt und sind im Wesentlichen das &amp;ldquo;Elternprivileg&amp;rdquo;.
Erziehungsberechtigte, und nur diese, dürfen für Ihr Kind – im Rahmen bestimmter Grenzen – frei entscheiden,
was ihr Kind wann darf oder nicht darf.
Darum darf Deine Mutter Dich mit drei Jahren an ihrem Bier probieren lassen,
wenn Du interessiert wissen willst, was sie da trinkt.
Und darum darf Dein Vater Dich mit 6 Jahren Harry Potter Teil 4 und Folgende sehen lassen,
wenn Du unbedingt sehen möchtest wie es weiter geht.&lt;/p&gt;
&lt;p&gt;Lehrer an Schulen dürfen das nicht.
Das Elternprivileg gilt nicht für sie.
Sie müssen also, wenn Schüler Medien in irgendeiner Form zu sich nehmen wollen,
dies im Rahmen des grundgesetzlich vorgeschriebenen und gesetzlich ausgestalteten Jugendschutzes tun,
wenn sie sich von Klagen durch besorgte Bürger frei stellen wollen.&lt;/p&gt;
&lt;p&gt;Internet an Schulen ist für die Schule auf viele Weisen ein Risiko,
und Haftung auf der Basis von Verletzungen des Jugendschutzes ist eines davon.&lt;/p&gt;
&lt;p&gt;Schlimmer noch, auch Anbieter von Medien jeder Art unterliegen den Regelungen des Jugendschutzes.
Niemand kann Filme, Hörspiele, Bücher, aber auch keine Webseiten oder Computerspiele anbieten,
ohne dabei den Jugendschutz zu berücksichtigen.
Alle diese Dinge brauchen eine Einordnung und eine wirksame Zugriffsbeschränkung,
sonst Klage und, schlimmer, schlechte Presse.&lt;/p&gt;
&lt;h1 id=&#34;pre-internet-jugendschutz&#34;&gt;
    &lt;a href=&#34;#pre-internet-jugendschutz&#34;&gt;
	Pre-Internet Jugendschutz
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Das hat in der Vergangenheit bis in die späten 90er Jahre wunderbar funktioniert.
Hauptsächlich deswegen, weil es keine kostenlosen und damit unfinanzierten Veröffentlichungen gab.
Und weil deswegen Veröffentlichung stark ge-gateway-ed war –
man konnte kein Buch, kein Spiel und schon gar kein Hörspiel oder keinen Film machen und dann verbreiten,
ohne durch einen Mediator zu gehen.
Also einen Verlag, eine Rundfunkanstalt oder einen anderen Vertriebs- und Verbreitungspartner,
der dabei dann auch massenhaft redaktionelle Bearbeitung betrieben hat,
und natürlich dabei auch die Formalien wie Anmeldungen bei Verwertungsgesellschaften oder Bewertung durch den Jugendschutz vorgenommen hat.&lt;/p&gt;
&lt;p&gt;Weil Inhalte grundsätzlich nie kostenlos waren, hat das nicht nur die Verfügbarkeit von Inhalten eingeschränkt,
sondern auch diese Formalien mit finanziert.
Auch wichtig: Es hat die Anzahl der Stellen reduziert, mit denen die staatlichen Stellen und ihre Organe zu tun hatten,
und durch die Pflicht zur kommerziellen Viabilität wurde auch eine Vorauswahl getroffen.&lt;/p&gt;
&lt;p&gt;Seit den späten 90er Jahren haben wir mediatorfreie Kommunikation.
Jeder Mensch kann mit genau gar keinem Aufwand Medien produzieren und publizieren.
Das kann durch Editieren eines existierenden Wikis passieren – das hat Brockhaus das Genick gebrochen.&lt;/p&gt;
&lt;p&gt;Es kann auch durch das Betreiben und Veröffentlichen eines Blogs, durch das Schreiben von Posts und Threads in Social Media,
durch das Aufnehmen und Verbreiten von Podcasts über diese Blogs,
oder halt durch das Produzieren von Filmen mit massiv verbilligten Produktionsmitteln geschehen.
Das letztere hat zum Beispiel zu &amp;ldquo;In the Pirkinning&amp;rdquo; und zu &amp;ldquo;Prelude to Axanar&amp;rdquo; geführt hat,
und dann zu entsprechenden rechtlichen Reaktionen von Rechte-Inhabern.&lt;/p&gt;
&lt;h1 id=&#34;drei-gründe-für-das-zusammenbrechen-des-jugendschutzes-im-internet&#34;&gt;
    &lt;a href=&#34;#drei-gr%c3%bcnde-f%c3%bcr-das-zusammenbrechen-des-jugendschutzes-im-internet&#34;&gt;
	Drei Gründe für das Zusammenbrechen des Jugendschutzes im Internet
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Es führt auch zu einem Zusammenbruch der deutschen Idee von Jugendschutz.
Das deutsche Jugendschutz-Konstrukt ist überhaupt nicht darauf eingerichtet,
mit mediatorfreier, massenhafter und weltweiter Generierung von Content klarzukommen.
Das sind drei unabhängige Probleme, die alle auch einzeln zum Zusammenbruch führen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mediatorfrei&lt;/strong&gt; heißt, daß kein Verlag oder Aggregator zwingend involviert ist.
Ich habe einen Inhalt, ich stelle den irgendwo hin und Du kannst den finden, herunterladen und konsumieren.
Die Idee von JusProg und anderen Filterprogrammen ist immer das Konzept eines installierbaren Zwangs-Mediators,
dem Filter, der den direkten Zugriff auf bestimmte Inhalte verhindert.
Das setzt bestimmte Dinge voraus, wir werden da gleich noch drauf eingehen.&lt;/p&gt;
&lt;p&gt;Und &lt;strong&gt;massenhaft&lt;/strong&gt; heißt, daß es keine Vorauswahl gibt.
Nicht durch einen Mediator, etwa einen Verlag mit einem Editor, der das gut finden muss, was Du publizieren willst.
Aber auch nicht finanziell – die Grundkosten sind so niedrig, daß effektiv jede Person alles publizieren kann,
was diese Person publizieren möchte.
Und auch nicht durch eine Lizenz – man muss im Internet nicht wie beim deutschen BTX der späten 80er Jahre
als Anbieter statt Nutzer registrieren lassen, damit man Dinge schreiben darf und mehr tun kann als konsumieren.&lt;/p&gt;
&lt;p&gt;Massenhaft hat zur Folge, dass die Anzahl und Menge der produzieren Medien die Bewertungskapazität der zur Verfügung stehenden qualifizierten Bewerter massiv übersteigt.
Damit ist nicht nur keine Diskussion über individuelle Bewertungen mehr möglich,
sondern Bewertungen müssen schematisch nach Syntax, nicht Semantik erfolgen.
Sie können nicht einmal mehr stichprobenhaft auf Korrektheit kontrolliert werden.&lt;/p&gt;
&lt;p&gt;Und &lt;strong&gt;weltweit&lt;/strong&gt; heißt, daß sowohl Inhalte als auch ihre Klassifizierung die Grenzen eines homogenen Kulturraumes weit überschreiten.
Eine sinnvolle Einigung über Klassifikationen ist nicht mehr möglich.
Teilweise ist nicht einmal eine Unterhaltung über Dimensionen und Skalen einer Klassifikation möglich.&lt;/p&gt;
&lt;p&gt;Schon innerhalb Deutschlands sind die Maßstäbe der Inhaltsbewertung traditionell massiv uneinheitlich.
Der bayrische Rundfunk hat zum Beispiel die Ausstrahlung bestimmter Folgen &amp;ldquo;Scheibenwischer&amp;rdquo; verweigert,
und sich aus dem Netz der ARD verabschiedet.
Auch die inzwischen eingestellte Sendung &amp;ldquo;Sesamstraße&amp;rdquo; war in Bayern nicht verfügbar.&lt;/p&gt;
&lt;p&gt;Wenn es um Inhalte im Internet geht, ist aber republikweit entlang bestimmter politischer Bruchlinien schon lange massiv keine sinnvolle Einigung möglich.
Weltweit noch viel weniger.
Man stelle sich ein Inhaltsbewertungssystem vor, das sowohl für Schweden, Spanien, Saudi-Arabien, die USA und Thailand funktioniert.&lt;/p&gt;
&lt;p&gt;Jede Form von inhaltlicher Bewertung kann sich also nur an objektiven Kriterien orientieren:
&amp;ldquo;Nippel sichtbar&amp;rdquo;, &amp;ldquo;Messer, Gewalt, Blut sichtbar&amp;rdquo;, oder halt der berühmte &amp;ldquo;körperbezogene Penisneigungswinkel&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;In einem solchen System ist das Foto eines durchschnittlichen Gummifetischisten dann halt unkritisch, weil
keine Haut sichtbar ist (keine Nacktheit), die Pose nicht sexuell suggestiv ist (kein Sex),
keine Gewalt zu sehen ist (keine Gewalt) und auch keine unangemessene Sprache verwendet wird (keine Flüche oder verbotene Worte).
Zugleich werden ein Haufen Stakeholder protestieren und dieses Bild irgendwie klassifiziert sehen wollen.&lt;/p&gt;
&lt;h1 id=&#34;jugendschutz-ist-nicht-systematisch-objektivierbar-und-automatisierbar&#34;&gt;
    &lt;a href=&#34;#jugendschutz-ist-nicht-systematisch-objektivierbar-und-automatisierbar&#34;&gt;
	Jugendschutz ist nicht systematisch objektivierbar und automatisierbar
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Es geht darum, welche Inhalte unserem Nachwuchs wie und mit welcher Bewertung präsentiert werden,
denn das ist, was Erziehung ist – die Vermittlung von Werten.
Daher ist jede Bewertung, die sich an Syntax (objektiv sichtbaren Merkmalen) orientiert zum Scheitern verurteilt.&lt;/p&gt;
&lt;p&gt;Und in dem Moment, wo Jugendschutz automatisierbar ist, haben wir eine Maschine gebaut,
die erfolgreich eine bestimmte moralische Bewertung in irgendeinem bestimmten moralischen System vornehmen kann,
also unseren Nachfolger als Menschheit geschaffen.
Wir können von der Bühne des Universums abtreten und denen die Realität überlassen.&lt;/p&gt;
&lt;p&gt;Mögen sie erfolgreicher und anpassungsfähiger sein als wir.&lt;/p&gt;
&lt;p&gt;Das ist natürlich keine Einsicht oder Position, die ein Politiker in einem öffentlichen Diskurs einnehmen kann,
also sehen wir seit wortwörtlich 30 Jahren denselben dysfunktionalen Kram ohne einen Millimeter Fortschritt in irgendeiner Richtung.&lt;/p&gt;
&lt;h1 id=&#34;der-default-ist-ab-18&#34;&gt;
    &lt;a href=&#34;#der-default-ist-ab-18&#34;&gt;
	Der Default ist &amp;ldquo;ab 18&amp;rdquo;
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Wie dem auch sei – rein rechtlich ist es so, daß jeder Inhalt in jedem Medium, das für Deutsche erreichbar ist,
eine Bewertung haben muss oder eine Ausnahmeregelung greifen muss (etwa für Nachrichten).
Das führt nicht nur zu Youtube-Kanälen, in denen Damen mit freiem Oberkörper Nachrichten verlesen,
sondern auch dazu, daß mir eine DVD mit einer Aufnahme der Zauberflöte nur gegen Vorlage des Personalausweises ausgehändigt wurde,
weil sie bei Amazon ohne Jugendschutz-Klassifikation hinterlegt war – der Default für alle Inhalte ist immer &amp;ldquo;ab 18&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Inhalte brauchen also zwingend eine Klassifikation,
damit sie für Jugendliche hinter einem echten oder hypothetisch installierten Filter überhaupt sichtbar werden.
Diese Klassifikation kann durch den Anbieter selbst erfolgen – das ist diese &amp;ldquo;age.xml&amp;rdquo;-Datei, von der Lilith Wittmann redet.
Oder halt durch Dritte, und da kaum jemand eine solche &amp;ldquo;age.xml&amp;rdquo;-Datei mit Selbstbewertung erzeugt,
generiert JusProg als Dritter diese Bewertung.&lt;/p&gt;
&lt;p&gt;Das machte vor dem Internet total Sinn:
Da alle Inhalte kommerziell waren, waren Anbieter von Inhalten und ihre Mediatoren daran interessiert, Inhalte bewertet zu sehen
und dabei die Bewertung auch so niedrig wie möglich anzusetzen, damit die Inhalte so vielen Menschen als möglich zugänglich werden.&lt;/p&gt;
&lt;p&gt;Im Internet ist das nicht so:
Ich habe gar kein Interesse daran, daß meine kostenlosen Inhalte so vielen Menschen wie möglich zugänglich werden,
sondern sie sollen &lt;em&gt;den richtigen&lt;/em&gt; Menschen zugänglich sein.
Mein Markt und meine Reichweite sind so groß, daß alles andere sogar ein Problem wäre
und für mich selbst zu Skalierbarkeitsproblemen führen würde.
Ich würde in für meine Mission nicht relevanten Interaktionen mit unwichtigen Menschen ertrinken.&lt;/p&gt;
&lt;p&gt;Damit ist die Motivationsgrundlage entfallen, die das deutsche Jugendschutzsystem vor dem Internet am Laufen gehalten hat.&lt;/p&gt;
&lt;h1 id=&#34;aber-wir-brauchen-bewertungen--für-unsere-sites&#34;&gt;
    &lt;a href=&#34;#aber-wir-brauchen-bewertungen--f%c3%bcr-unsere-sites&#34;&gt;
	Aber wir brauchen Bewertungen – für unsere Sites
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Die Mitglieder von JusProg e.V. sind traditionelle Medienanbieter.
Lilith Wittmann nennt Mitglieder und stellt die Motivation klar:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[JusProg eV] wurde mit dem Ziel gegründet, eine solche Software bereitzustellen.
Seine Mitglieder sind große deutsche Digitalunternehmen wie z.B. Vodafone oder RTL.
Die finanzieren das gerne.
Denn solange es ein anerkanntes Jugendschutzprogramm gibt, können sie eben auf viele andere Jugendschutzmaßnahmen verzichten.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Die Mission ist also, die Inhalte der Mitglieder kostengünstig aus dem Schußfeld des Jugendschutzgesetzes herauszuholen,
nicht effektiven Jugendschutz zu leisten.
Das wäre auch, wie oben gezeigt, systematisch sehr schwierig, wenn nicht unmöglich.&lt;/p&gt;
&lt;p&gt;Damit das eine glaubhafte Wirksamkeitsfiktion erzeugt, müssen nicht nur die Webseiten der Mitglieder eine Bewertung erhalten.
Sondern alle.
Das erfolgt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;geheim&lt;/strong&gt;, die Liste der Bewertungen ist nicht öffentlich, und die Kriterien sind es auch nicht.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ohne Benachrichtigung&lt;/strong&gt; der Bewerteten.
Deine Website ist durch JusProg bewertet, aber Du weißt es nicht.
Für eine solche Benachrichtigung müßte man Ansprechpartner und Kommunikationswege identifizieren können,
das ist aber nicht einheitlich automatisierbar.
Und wäre es das, dann hat man die Benachrichtigten am Hacken, die mit einem über die Bewertung diskutieren wollen,
was Zeit und Geld kostet und nicht skalierbar ist.&lt;/li&gt;
&lt;li&gt;und damit systematisch folgefalsch mit den beobachteten Problemen,
auf der Grundlage intransparenter syntaktischer Kriterien, und eventuell auch mit einer nicht offengelegten politischen Agenda.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das ist natürlich nicht nur kein Jugendschutz, sondern auch Demokratiegift,
weil nun auf die gesamte Bevölkerung ein Zwangsmediator ausgerollt wird,
dem man sich nicht entziehen kann (darf),
weil man ja ein Jugendlicher sein könnte.
Und weil es Inhalte gibt, die nach JSchG nicht einmal Erwachsenen zugänglich gemacht werden dürfen.&lt;/p&gt;
&lt;p&gt;Daher wäre es im Grunde ideal, die zwar grundgesetzlich vorgeschriebene Idee des Jugendschutzes im Internet als zu Recht gescheitert anzusehen.
JusProg wäre dann ein Feigenblatt,
mit dem kommerzielle Medienanbieter sich durch Generierung und Installation einer &amp;ldquo;age.xml&amp;rdquo;-Datei haftungsrechtlich freikaufen können,
und dann installiert einfach niemand JusProg.&lt;/p&gt;
&lt;p&gt;So ist es aber nicht.
Dieser Status Quo ist einmal durch Installation von JusProg in öffentlichen Netzen eingerissen worden,
wie Lilith Wittmann korrekt anmerkt.&lt;/p&gt;
&lt;p&gt;Zum anderen ist da der feuchte Traum, jeden Internetbenutzer mit einem elektronischen Ausweisdokument jederzeit identifizieren zu können,
der gerade in der EU in eIDAS, Verimi und vielen anderen Dingen wieder auflebt.
Dabei kommen die Interessen
von &amp;ldquo;Bedarfsträgern&amp;rdquo;,
die Interessen von Leuten mit politischem Filterwillen,
der &amp;ldquo;Jugendschutz&amp;rdquo; als Legitimierungsfeigenblatt,
und die kommerziellen Interessen der Werbeindustrie zusammen, die Identität als staatlich zwangsverordneten Supercookie mitnutzen will.&lt;/p&gt;
&lt;p&gt;Das darf so nicht passieren.
Daher muss nicht nur JusProg sterben.
Aber es ist nur ein Baustein in einer Entwicklung, die fraktal falsch ist.&lt;/p&gt;
&lt;p&gt;Das ist der Grund, warum Lilith da überall drauf haut.
Und darum sollten wir ihr alle auf jede denkbare Art Beistand leisten.
Gerade jetzt, wo um uns herum eine politische Ideologie auflebt, die nur darauf wartet, solche Mechanismen auf tödliche Weise zu missbrauchen.&lt;/p&gt;
&lt;h1 id=&#34;siehe-auch&#34;&gt;
    &lt;a href=&#34;#siehe-auch&#34;&gt;
	Siehe auch
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Seit 27 Jahren kein Fortschritt im Diskurs:
&lt;a href=&#34;https://blog.koehntopp.info/1997/05/14/sperrungen-im-internet.html&#34;&gt;Sperrungen im Internet&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Seit 15 Jahren kein Fortschritt im Diskurs:
&lt;a href=&#34;https://blog.koehntopp.info/2009/08/06/jugendschutzfilter-saugen-und-daf-r-gibt-es-einen-grund.html&#34;&gt;Jugendschutzfilter saugen und dafür gibt es einen Grund&lt;/a&gt;

 –
Warum wir nicht einfach alles &amp;ldquo;ab 18&amp;rdquo; machen können und warum damit ein Haufen Leuten mit unproblematischen Inhalten notlos Arbeit aufgebürdet wird.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>/b/ wie &#34;Verzweiflung&#34;</title>
      <link>https://blog.koehntopp.info/2012/03/05/b-wie-verzweiflung.html</link>
      <pubDate>Mon, 05 Mar 2012 19:34:48 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/03/05/b-wie-verzweiflung.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/fsk-b.jpeg&#34; alt=&#34;Blogmarke /b/&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://netzpolitik.org/2012/neue-cdu-idee-b-fur-blogs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Netzpolitik.org&lt;/a&gt;


weist auf das Positionspapier
&amp;ldquo;&lt;a href=&#34;http://www.cdu.de/doc/pdfc/120305-jugendmedienschutzstaatsvertrag.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eckpunkte für eine Novelle des Jugendmedienstaatsvertrags&lt;/a&gt;

&amp;rdquo;
(PDF) der CDU hin.  Dort findet man die Idee, neben den bekannten
Kennzeichnungen der Altersstufen &amp;ldquo;6&amp;rdquo;, &amp;ldquo;12&amp;rdquo;, &amp;ldquo;16&amp;rdquo; und &amp;ldquo;18&amp;rdquo; eine weitere
aufzunehmen: &amp;ldquo;B&amp;rdquo; für Blogs.&lt;/p&gt;
&lt;p&gt;Bei netzpolitik.org findet man das lustig, aber der Hintergrund ist ernst.
Zum besseren Verständnis hier noch einmal der Verweis auf
&lt;a href=&#34;http://www.heise.de/ct/artikel/Unerwuenschte-Freiheiten-1431667.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unerwünschte Freiheiten&lt;/a&gt;


von Holger Bleich bei der c&amp;rsquo;t, um die Interessenlage der Player in
Erinnerung zu rufen.&lt;/p&gt;
&lt;p&gt;Die Idee des &amp;ldquo;Kennzeichen /b/&amp;rdquo; ist eine direkte Folge des besonderen
Schutzes der Familie und der Jugend im Grundgesetz, also der Verpflichung
des Staates zum Jugendschutz vs.  den Willen eine Pornoindustrie haben zu
wollen.&lt;/p&gt;
&lt;p&gt;In Lang: Die Verpflichtung zum Jugendschutz ergibt sich in Deutschland aus
dem Grundgesetz und ist nicht leicht &amp;ldquo;weg&amp;rdquo; zu bekommen.  Der Staat muß sie
also erfüllen, oder ihre Erfüllung glaubwürdig simulieren.  Er tut das mit
dem Jugendschutzgesetz, dem Jugendmedienschutz-Staatsvertrag und einigen
anderen Dingen.&lt;/p&gt;
&lt;p&gt;Im Internet gibt es nun eine Reihe von Firmen, die auch Inhalte von
Deutschland aus publizieren wollen, die nach dem Jugendschutzgesetz, dem
Staatsvertrag etc jugendgefährdend sind.  Damit diese Anbieter auch von
Deutschland aus operieren können (und damit auch in Deutschland
steuerpflichtig sind!), muß der Staat eine Möglichkeit schaffen, daß sie das
können, ohne daß er seine grundgesetzliche Verpflichtung zum Jugendschutz
verletzt.&lt;/p&gt;
&lt;p&gt;Das hat er mit dem neuen Jugendmedienschutzstaatsvertrag versucht, ist aber
an den Eigenschaften des Mediums Internet gescheitert.  Denn während in
traditionellen Medien Anbieter von Inhalten kommerziell sind, und daher ein
Interesse haben, sich dieser Regulierung zu unterwerfen und ein möglichst
niedriges, gerade noch zulässiges Rating zu erwerben, um ein möglichst
großes Publikum zu erreichen, ist dies im Internet nicht mehr der Fall.&lt;/p&gt;
&lt;p&gt;Hier haben nichtkommerzielle Anbieter (unter anderem die genannten Blogs)
das Interesse daran, möglichst kostengünstig rechtssicher zu agieren.  Und
wenn das bedeutet &amp;ldquo;Kinder müssen draußen bleiben&amp;rdquo;, dann bevorzugen sie eben
dieses Rating.  Nicht im Sinne der Jugendschützer.&lt;/p&gt;
&lt;p&gt;Diese Disparität zwischen kommerziellen und nichtkommerziellen Anbietern
killt den Regulierungsmechanismus und der Versuch des neuen Staatsvertrages
ist daran gestorben.&lt;/p&gt;
&lt;p&gt;Die Marke /b/ ist der Versuch, einen Ausweg zu finden und den kommerziellen
deutschen Pornoanbietern endlich einen Weg ins Netz zu bauen, der gangbar
ist, ohne vom nichtkommerziellen &amp;ldquo;Ich will doch nur ein Blog betreiben&amp;rdquo;-Netz
einen Shitstorm ins Gesicht geblasen zu bekommen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JMStV: Nix neues</title>
      <link>https://blog.koehntopp.info/2011/12/05/jmstv-nix-neues.html</link>
      <pubDate>Mon, 05 Dec 2011 11:10:50 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/12/05/jmstv-nix-neues.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://mrtopf.de/blog/politik-politics/jugendmedienschutztagung-zdf/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Christian Scholz berichtet&lt;/a&gt;


berichtet von der
&lt;a href=&#34;http://www.unternehmen.zdf.de/index.php?id=245&amp;amp;artid=473&amp;amp;backpid=244&amp;amp;cHash=64c3b1168a/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jugendmedienschutztagung&lt;/a&gt;


von ZDF, ARD und Kirchen (sic!) in Mainz.&lt;/p&gt;
&lt;p&gt;Die Zusammenfassung ist: Die Debatte kommt nicht von der Stelle, die
Argumente und Positionen sind noch immer dieselben wie vor 2 und 12 Jahren.
Die Filterfraktion preist ihre technischen Lösungen an. Die Eltern- und
Praktikerfraktion lacht trocken. Die Besitzer relativ neuer &amp;lsquo;Endgeräte&amp;rsquo;, die
nicht Computer sind, sondern Handies, Playstations oder andere Spezialgeräte
mit Internetzugang fragen, ob&amp;rsquo;s die Filter denn auch für $EXOTISCHE_HARDWARE
gibt. Und am Ende verweigert man sich gemeinsam der Erkenntnis, daß sich
Erziehung nun einmal nicht technisieren läßt, Jugendschutz also damit
beginnt und endet, Eltern auszubilden und zu motivieren.&lt;/p&gt;
&lt;p&gt;Wir danken für dieses Gespräch. &lt;em&gt;Pieeep&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Doom und Doom II nicht mehr jugendgefährdend</title>
      <link>https://blog.koehntopp.info/2011/08/31/doom-und-doom-ii-nicht-mehr-jugendgef-hrdend.html</link>
      <pubDate>Wed, 31 Aug 2011 19:47:02 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2011/08/31/doom-und-doom-ii-nicht-mehr-jugendgef-hrdend.html</guid>
      <description>&lt;p&gt;Nachtrag zu
&lt;a href=&#34;https://blog.koehntopp.info/2010/07/21/jugendmediendoom.html&#34;&gt;Jugendmediendoom&lt;/a&gt;

:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.golem.de/1108/86095.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doom und Doom II vom Index gestrichen&lt;/a&gt;

.
Mit Wirkung von heute sind Doom und Doom II nicht mehr jugendgefährdend. Die
Begründung liegt als
&lt;a href=&#34;http://www.bundespruefstelle.de/bpjm/redaktion/PDF-Anlagen/bpjm-aktuell-doom-listenstreichnung-aus-03-11,property=pdf,bereich=bpjm,sprache=de,rwb=true.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;


vor.&lt;/p&gt;
&lt;p&gt;Die Zusammenfassung lautet: Es liegt an den Pixeln, äh, der Entscheidung
liegt &amp;ldquo;die technische Weiterentwicklung von Spielen [zugrunde], in deren
Folge die Darstellungen der beiden Shooter-Klassiker heute nicht mehr als
realistisch anzusehen sind.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Diese wunderbaren Dokumente der Zeitgeschichte sind nun frei ab 16 Jahren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ein paar Zwischenbemerkungen, bevor der Tanz wieder losgeht</title>
      <link>https://blog.koehntopp.info/2010/12/15/ein-paar-zwischenbemerkungen-bevor-der-tanz-wieder-losgeht.html</link>
      <pubDate>Wed, 15 Dec 2010 18:00:35 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/12/15/ein-paar-zwischenbemerkungen-bevor-der-tanz-wieder-losgeht.html</guid>
      <description>&lt;p&gt;Es ist ein Fehler anzunehmen, die CDU hätte in NRW gegen den JMStV gestimmt,
weil sie inhaltlich gegen den JMStV gewesen wäre - keine der Parteien
irgendwo in Deutschland hat aus inhaltlichen Gründen für oder gegen den
JMStV gestimmt, sondern das ganze war eine einzige Macht-Taktiererei -
&lt;a href=&#34;http://oeffingerfreidenker.blogspot.com/2010/12/was-fur-eine-farce.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eine Farce&lt;/a&gt;

.
In NRW war es so, daß die minderheitsregierenden Parteien sich mit
Enthaltungen aus der Verantwortung stehlen wollten, und die CDU deswegen
angekündigt hat, gegen das Ding zu stimmen, weil sie Rotgrün so zwingen
konnte, Stellung zu beziehen und so im vorübergehen billig jemanden eins
reinwürgen.&lt;/p&gt;
&lt;p&gt;Es ist auch ein Fehler anzunehmen, daß eine Ablehnung des JMStV ein Sieg
wäre. Damit meine ich nicht Kurt Beck, der mit seiner Ankündigung
&lt;a href=&#34;http://www.rlp.de/einzelansicht/archive/2010/december/article/politische-machtdemonstration-der-cdu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;der nuklearen Sperrverfügungsoption&lt;/a&gt;


seine Offlinigkeit dokumentiert und sich damit final in die Riege der
Politikergeneration einreiht, die wegen mangelnder Zukunftstauglichkeit
dringend abgetreten werden muß.&lt;/p&gt;
&lt;p&gt;Sondern ich meine damit, daß es immer noch notwendig ist, die
gesellschaftliche Diskussion über Jugendmedienschutz ins 21. Jahrhundert zu
holen und klar zu machen, daß das Schutzmodell in einer vernetzten
Gesellschaft auf keiner Ebene funktioniert. Weder sind noch Mittler da, die
soziale Kontrolle ausüben können, noch sind die Anreize da, die das System
bei Film und Spielen am Leben halten, noch ist das Bewertungssystem
großflächig erfolgreich vermittelbar. Erziehung ist nicht mit
Filterprogrammen automatisierbar, und die Welt ist größer als Deutschland -
diese Erkenntnis muß halt rein in die Köpfe.&lt;/p&gt;
&lt;p&gt;Ich bekam eine Anfrage per Mail:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hallo Kristian,&amp;hellip;Hättest du nicht Lust, einen Gastbeitrag [ zu
Filtersoftware ] bei uns zu schreiben?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Das habe ich nun drei Mal angefangen und den Text wieder weg geworfen -
daher auch die langsame Reaktion. Das Thema macht mich müde, oder ich werde,
wenn ich nicht müde werde, zu spitzzüngig für eine sinnvolle Diskussion. Es
ist nicht so, daß es kompliziert zu verstehen wäre, wenn man sich denn
einmal von der Beschützen-Ideologie des existierenden Jugendschutzes frei
macht und sich ansieht, was denn die zu lösenden Probleme bedeuten. Das
passiert nur niemals, jedenfalls nicht auf einer gesellschaftlichen Ebene,
die nahe genug an der Politik ist, denn dafür sind die Konsequenzen zu
unbequem.&lt;/p&gt;
&lt;p&gt;Die Kinder-müssen-beschützt-werden Fraktion hat versucht, Inhalte mit
Schlüsselworten und dem Zählen von hautfarbenen Pixeln automatisch zu
bewerten, schon 1996.&lt;/p&gt;
&lt;p&gt;Das ist ein Unterfangen, das zwangsläufig scheitern muß, denn es versucht
Syntax, Kriterien der äußeren Form, zu definieren, um davon ein moralisches
oder ethisches Urteil abzuleiten (&amp;ldquo;Diese Inhalte sind schlecht oder für
Kinder nicht geeignet.&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;Wäre dies so einfach, könnten wir Juristen durch Roboter ersetzen, ja sogar
als menschliche Rasse zur Gänze beruhigt abtreten, da wir Maschinen
geschaffen haben, die Moral und Ethik haben - das ist nichts weniger als die
Singularität, das Nirvana der KI, die Vereinigung von Mensch und Maschine.
Aber die Tatsache, daß dieser Ansatz aus technischer Sicht so offensichtlich
lächerlich ist, hält niemanden davon ab, ihn auch 2010 noch zu propagieren -
natürlich nicht mehr als ausschließliches Kriterium, sondern lediglich
&amp;rsquo;ergänzend, wenn keine weitere Kriterien zur Verfügung stehen&#39;.&lt;/p&gt;
&lt;p&gt;In der zweiten Welle haben die Kinderbeschützer dann versucht, mit PICS ein
System zu schaffen, mit dem man beliebige Labels an Content kleben kann -
sogar das heutige &amp;ldquo;ab x Jahren&amp;rdquo;-System kann man in PICS darstellen, es
besteht kein Grund, dafür de-xml dilettantisch neu zu definieren. PICS,
heute POWDER, hätte im Gegensatz zu de-xml außerdem den Vorteil, daß dafür
bereits haufenweise Software existiert, die solches Zeugs verstehen kann.&lt;/p&gt;
&lt;p&gt;Damals, wir sind inzwischen so um 1999 herum, hat man Ratingsysteme mit
quasi-objektiven Kriterien definiert. In RSAC zum Beispiel gab es vier
Kategorien (Gewalt, Sex, Nacktheit und Sprache), und in jeder Kategorie dann
wiederum fünf Stufen - Gewalt zum Beispiel wird von 0 (Harmloser Konflikt,
leichte Sachbeschädigung), 1 (Lebewesen werden verletzt oder getötet,
Sachbeschädigung), 2 (Menschen werden verletzt oder getötet, wenig Blut), 3
(Menschen werden getötet, Blut und Splatter) und schließlich 4 (Unnötige und
graphische Gewaltdarstellung, Folter, Vergewaltigung) unterteilt. Für die
anderen Kategorien werden ähnliche Unterteilungen vorgesehen.&lt;/p&gt;
&lt;p&gt;Auch das ist natürlich wieder eine Syntax, ein formaler Regelsatz, der zu
einem Werturteil führen soll. Und natürlich kann man hier bei Kenntnis der
Regeln leicht pathologische Fälle finden, die sogar häufig sind, und bei
denen jedes System bei korrekter Anwendung der Regeln - nein, &lt;em&gt;wegen&lt;/em&gt;
korrekter Anwendung der Regeln - zu nicht akzeptablen Ergebnissen kommt.&lt;/p&gt;
&lt;p&gt;Was es braucht, so die Beschützerfraktion, ist also ein Bewertungssystem,
das subjektiv ist, also eines bei dem der Sender (derjenige, der das Label
an einen Inhalt klebt) ein Urteil im kulturellen Kontext eines Rezipienten
(genauer: aller möglichen Rezipienten des betroffenen Kulturkreises) treffen
muß. Das ist natürlich unmöglich - wer es nicht glaubt, mag sich gerne eine
Diskussion zwischen &amp;ldquo;Gamern&amp;rdquo; und beliebigen Politikern zum Thema First
Person Shooter anhören (&amp;ldquo;Killerspiele vs. Spielekiller&amp;rdquo;). Oder sich die
Beispiele ansehen, die der AK Zensur und Alvar Freude herausgesucht haben,
um sie durch Laien nach dem aktuell propagieren &amp;ldquo;Ab x Jahren&amp;rdquo;-System
bewerten zu lassen - mit einer Fehlerquote von 80%.&lt;/p&gt;
&lt;p&gt;Wer hier an einen erzielbaren gesamtgesellschaftlichen Konsens glaubt, der
hat die Postmoderne verschlafen.&lt;/p&gt;
&lt;p&gt;Wieder 11 Jahre zurück. Schon in der vom BMWi in Auftrag gegebenen Studie
&amp;ldquo;Jugendschutz und Filtertechnologien im Internet&amp;rdquo;
(&lt;a href=&#34;https://blog.koehntopp.info/uploads/secorvo-studie-jugendschutz.pdf&#34;&gt;PDF&lt;/a&gt;

)
kam man zu der Erkenntnis, das Kinder und Jugendliche Filter nicht zu
umgehen versuchen würden, würden sie sie als nützlich empfinden. Sie werden
nicht als nützlich empfunden, da die Beschützer- und Filterbefürworter
offiziell noch immer die Aufgabe eines Jugendschutzprogrammes falsch
formuliert.&lt;/p&gt;
&lt;p&gt;Die Aufgabe eines Jugendschutzprogrammes ist es eben &lt;em&gt;genau nicht&lt;/em&gt;,
jugendgefährdende Inhalte zu blockieren.&lt;/p&gt;
&lt;p&gt;Wäre es so einfach, wäre das Problem leicht lösbar: Man sperrt einfach alle
Seiten ohne Label (&amp;ldquo;Keine Einstufung nach &amp;hellip;&amp;rdquo;) wie man es bei Videospielen
und Filmen auch tut, und niemand klebt ein Label an seine Inhalte. Mithin
sind alle Seiten gesperrt, also auch alle jugendgefährdenden Inhalte aller
Altersstufen.&lt;/p&gt;
&lt;p&gt;Das ist Overblocking, und nicht akzeptabel.&lt;/p&gt;
&lt;p&gt;Die korrekte Formulierung der Aufgabe ist eben &amp;ldquo;Damit Jugendschutzprogramme
erfolgreich sein können, müssen ihre Filter alle jugendgefährdenden Inhalte
blockieren und alle nicht jugendgefährdenden Inhalte durchlassen.
Overblocking, false-positives, das Sperren von nicht jugendgefährdenden
Inhalten sind genau so ein Problem wie Underblocking, false-negatives, das
Durchlassen von jugendgefährdenden Inhalten.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Das ist ein viel schwierigeres Problem als das Blockieren von
jugendgefährdenden Inhalten. Daher geht mit der Propagierung des Konzeptes
&amp;lsquo;Filterprogramm mit Label&amp;rsquo; zwingend auch die Konstruktion einer Pflicht zur
Labelung von Inhalten einher, wenn das Konzept &amp;lsquo;Filterprogramm mit Label&amp;rsquo;
ein Erfolg werden soll. Streng genommen müßte man idealerweise sogar dazu
verpflichten, das minimale gerade noch akzeptable Label zu wählen.&lt;/p&gt;
&lt;p&gt;In den vergangenen 11 Jahren seit der o.a. Secorvo/BMWi-Studie sind
überhaupt keine Fortschritte in der öffentlichen Diskussion gemacht worden.
Weder wird die Aufgabenstellung korrekt formuliert, noch werden die sich
daraus ergebenden Konsequenzen thematisiert, die wegen der
Overblocking/Underblocking-Problematik lauten:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pflicht zur Bewertung,&lt;/li&gt;
&lt;li&gt;Pflicht zur minimalen Bewertung&lt;/li&gt;
&lt;li&gt;Bindung von Bewertungen an Inhalte mit einer PKI, damit eine Verfälschung oder Entfernung der Labels auf dem Web zum Rezipienten
&lt;a href=&#34;http://blog.odem.org/2010/12/jmstv-filter-umgehen.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a la odem.org&lt;/a&gt;


nicht möglich ist&lt;/li&gt;
&lt;li&gt;Definition eines subjektiven Bewertungssystems, also Verpflichtung des
Senders, die Erziehungs-Wünsche und Moralvorstellungen aller Empfänger zu
antizipieren, da quasi-objektive Systeme nicht funktionieren&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Es ist natürlich Absicht, daß das nicht thematisiert wird. Würde man es tun,
wäre sofort erkennbar, daß jeder Ansatz, der auf Jugendschutzlabels und
Filtern basiert zwingend zum Scheitern verurteilt wird - die Liste da oben
sind offensichtlich unmögliche Forderungen.&lt;/p&gt;
&lt;p&gt;Wir leben in einer Gesellschaft mit Technologie, die es beliebigen Personen -
auch Kindern - ermöglicht, sich ad-hoc zu vernetzen und Daten
auszutauschen. Das kann per Speicherkarten gehen, USB-Stick, Bluetooth,
lokale Wi-Fi-Hotspots, lokale ad-hoc Kabelnetze wie auf LAN-Parties,
P2P-Netzwerkstrukturen auf dem Substrat des Internet oder Darknets wie tor
und Freenet. Oh, und normalen Internet-Zugriffen, einige davon mit
unverschlüsseltem http.&lt;/p&gt;
&lt;p&gt;Das bedeutet, daß jede beliebige Person Inhalte beliebig publizieren kann.
Ein Ansatz, bei dem auf Mittler eingewirkt wird, wie es beim klassischen
Urheberrecht, Jugendschutz und anderen sozialen Kontrollinstanzen der Fall
war, funktioniert hier nicht, da es keine Mittler mehr gibt. Anbieter und
Konsumenten von Inhalten finden sich und vernetzen sich nach Bedarf und ohne
Einschaltung von Dritten, müssen einander nicht persönlich kennen und für
den Datentausch nicht persönlich Kontakt haben, und eine Alterung der Kopien
über Generationen des Duplizierungsprozesses findet nicht statt.&lt;/p&gt;
&lt;p&gt;Kindern und Jugendlichen Inhalte vorzuenthalten (&amp;ldquo;sperren&amp;rdquo;) funktioniert
schlicht nicht mehr, schon im Ansatz nicht.&lt;/p&gt;
&lt;p&gt;Sperren ist auch weniger wichtig als die Beschützer-Fraktion denkt. Malte
Welding formuliert es in einem
&lt;a href=&#34;http://www.malte-welding.com/2010/11/30/jugendmedienschutz-ist-furs-arsch/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blogartikel&lt;/a&gt;


so: &amp;ldquo;Obst verdirbt, Kinder nicht, Kinder schalten ab.&amp;rdquo;. Wichtiger ist es,
eine Wertung zu vermitteln, wenn Kinder Inhalte wahrnehmen. &amp;ldquo;Medienkompetenz
vermitteln&amp;rdquo; ist konkret umgesetzt genau das: Kindern zu lehren, daß es
erstens okay ist, bestimmte Dinge im Netz schlecht zu finden und ihnen
zweitens klar zu machen, welche Dinge wir bei unserem Stamm schlecht und
welche wir gut finden.&lt;/p&gt;
&lt;p&gt;Wollte man bei dem gesellschaftlichen Diskurs um den Jugendschutz
Fortschritte machen, ist es wichtig zu lernen, zu verstehen und zu
akzeptieren, warum dies die einzige Möglichkeit ist, die uns im Angesicht
moderner Technologie bleibt.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ich denke, der Jugendmedienschutz ist ein gutes Beispiel dafür, wie
mangelhaft die Zusammenarbeit zwischen Juristen und Technikern oft ist.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ich denke, der Jugendmedienschutz ist ein gutes Beispiel dafür, wie Menschen
versuchen, Heil in der Entwicklung von Technologien zu suchen, wenn
Technologie für die Lösung der gestellten Aufgabe komplett ungeeignet ist.
Aus der oben dargelegten Folge von Erfahrungen und Überlegungen wird
hoffentlich klar, warum gerade Techniker bei dem Problem prinzipbedingt
nichts hilfreiches beitragen können.&lt;/p&gt;
&lt;p&gt;Schon das Wort ist falsch. Es geht nicht um JugendmedienSCHUTZ. Das kann
2010 nicht funktionieren. Es hat schon 1996 nicht funktioniert. Was wir
brauchen ist JugendmedienERZIEHUNG. Durch Menschen. Mit Werten und
Überzeugungen.&lt;/p&gt;
&lt;p&gt;Und nicht einen netzwerkweiten Schutzroboter.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Egal wie es mit dem JMStV in nächster Zukunft läuft - verändern kann man
nur etwas, wenn man sich über Alternativen Gedanken macht. Könntest du dir
vorstellen, da mit uns zusammen einen ersten Schritt zu machen?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Wie gesagt, ich bin dieser Diskussion unsagbar müde. Ich führe sie seit fast
15 Jahren. Den Text da oben könnt Ihr verwenden, falls Ihr den brauchbar
findet.&lt;/p&gt;
&lt;p&gt;Gruß, Kris&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jugendmediendoom</title>
      <link>https://blog.koehntopp.info/2010/07/21/jugendmediendoom.html</link>
      <pubDate>Wed, 21 Jul 2010 14:55:04 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/07/21/jugendmediendoom.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Doom_II:_Hell_on_Earth&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doom II&lt;/a&gt;

 -
laut Wikipedia eingestuft als 18+/Indexed bei der
&lt;a href=&#34;http://en.wikipedia.org/wiki/Unterhaltungssoftware_Selbstkontrolle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;USK&lt;/a&gt;

.
Auf dem PC. Genau wie &lt;a href=&#34;http://www.amazon.de/ACTIVISION-Doom-III/dp/B0002OJU1Y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doom III&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Dasselbe
&lt;a href=&#34;http://itunes.apple.com/de/app/doom-ii-rpg/id354051766?mt=8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doom II&lt;/a&gt;


in feinem 1024x768 auf dem iPad im iTunes Store.&lt;/p&gt;
&lt;p&gt;Und hier
&lt;a href=&#34;http://www.macnotes.de/2010/07/20/app-store-jugendschutz-usk-bpjm-und-andere-deutsche-spezialitaten/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;warum das alles so ist&lt;/a&gt;

.
Logik hat das keine mit dem JMStV - nicht im alten und auch nicht im neuen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Die Netzsperren schlagen zurück</title>
      <link>https://blog.koehntopp.info/2010/02/19/die-netzsperren-schlagen-zur-ck.html</link>
      <pubDate>Fri, 19 Feb 2010 12:19:25 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/02/19/die-netzsperren-schlagen-zur-ck.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.spiegel.de/netzwelt/netzpolitik/0,1518,678608,00.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bundespräsident Horst Köhler&lt;/a&gt;


hat das Zugangserschwerungsgesetz, vulgo Zensursula-Gesetz, nun doch
unterschrieben. Das muß er tun, denn der Bundespräsident hat gemäß
Konstruktion unserer Verfassung nicht das Recht eines Vetos gegenüber der
Regierung wie das etwa in der Weimarer Republik gewesen wäre.&lt;/p&gt;
&lt;p&gt;Der Spiegel beschreibt das Ergebnis mit dem Absatz&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bundespräsident Horst Köhler hat an diesem Mittwoch mit einer einzigen
Unterschrift nicht nur eine, sondern gleich zwei Bundesregierungen
blamiert: Die Große Koalition der vergangenen Legislaturperiode, die das
nicht nur umstrittene, sondern handwerklich völlig vermurkste
&amp;ldquo;Zugangserschwerungsgesetz&amp;rdquo; gegen Kinderpornografie im Netz gemacht hat.
Und die jetzige schwarz-gelbe Koalition, die das Gesetz eigentlich gar
nicht mehr haben will, nun aber umsetzen muss.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;und faßt die Situation so sehr schön zusammen.&lt;/p&gt;
&lt;p&gt;Die ganze Geschichte dieses Gesetzes ist ein Testament fortdauernden
Politikversagens: Erst die fragwürdigen Geheimverträge zwischen Regierung,
BKA und Providern, dann die unsägliche Debatte mit dem Regierungs-sträuben
gegen jeglichen Rat von Technik- und Verfassungsexperten, das Umfallen im
Umfallen der SPD und deren Verkrachen mit ihrem Internet-Rat, die
überhastete Verabschiedung des Gesetzes, während die erfolgreichsten
Petition aller Zeiten noch lief, und schließlich das durch diese Aktivitäten
mit herbeigeführte 2%-Ergebnis der Piratenpartei.&lt;/p&gt;
&lt;p&gt;Die Anhörung ist übrigens
&lt;a href=&#34;http://www.netzpolitik.org/2010/bundespraesident-hat-zugangserschwerungsgesetz-unterschrieben/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;am Montag&lt;/a&gt;


und das Parlament debattiert über mögliche Aufhebungsgesetze dann am 25.
Februar, wird diese aber alle aus Prinzip ablehnen, da die Vorschläge
allesamt von der Opposition eingebracht worden sind und man einem
politischen Gegner aus taktischen Gründen keinen Erfolg gönnen darf.&lt;/p&gt;
&lt;p&gt;Wie dem auch sei: Jetzt ist das Gesetz, das plötzlich keiner mehr will,
unterzeichnet und muß umgesetzt werden, bis auch dieses Gesetz für
&lt;a href=&#34;http://ak-zensur.de/2010/02/unterzeichnung.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;verfassungswidrig&lt;/a&gt;

 erklärt
wird - wenn man nicht vorher schon ein
&lt;a href=&#34;http://www.internet-law.de/2010/02/bundesprasident-unterzeichnet.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aufhebungsgesetz&lt;/a&gt;


machen will.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bfdi.bund.de/bfdi_forum/showthread.php?s=2ec824f5fbb912c41904e8a68cb0a436&amp;amp;p=4952#post4952&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Denn Gesetze, die in Kraft sind, nach Belieben nicht anzuwenden kann auch nicht die Grundlage eines Rechtsstaates sein&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Damit nicht genug: Man redet von einem Löschgesetz statt eines Sperrgesetzes -
aber die Rechtsgrundlage zur Löschung von Kinderpornograpie im Internet
gibt es schon,
&lt;a href=&#34;http://www.netzpolitik.org/2010/piratenpartei-loeschen-von-kinderpornographie-ueberfluessig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wie die Piratenpartei in die Debatte einwirft&lt;/a&gt;

.
Und man baut gerade an einem Jugendmedienstaatsvertrag, dessen bekannt
gewordene Version 2.0 noch mehr Eingriffe in die Kommunikation verpflichtend
gemacht hätte als dieses unselige Gesetz es vorsieht. Dessen Version 3.0
wird dann
&lt;a href=&#34;http://www.golem.de/1002/73237.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bereits am 24. verhandelt&lt;/a&gt;

, ist aber
wegen des Drucks des Netzes zur Version 2.0 angeblich entschärft.
Stattdessen setzt man auf elternseitig installierte Filterprogramme. Die
werden zwar
&lt;a href=&#34;https://blog.koehntopp.info/2009/08/06/jugendschutzfilter-saugen-und-daf-r-gibt-es-einen-grund.html&#34;&gt;auch nicht funktionieren&lt;/a&gt;

,
aber immerhin niemandem schaden außer den Kindern der Eltern, die so was
einsetzen.&lt;/p&gt;
&lt;p&gt;Es gibt also wieder viel zu tun, solange wir noch offensiv dumme und
internet-analphabetische Politiker haben. Oder, wenn man die böse
Zynikerbrille aufsetzt, dann faßt man es wie
&lt;a href=&#34;http://oerks.de/blog/2010/02/19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aleks&lt;/a&gt;

 und Alvar zusammen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ab 18</title>
      <link>https://blog.koehntopp.info/2010/01/26/ab-18.html</link>
      <pubDate>Tue, 26 Jan 2010 10:30:40 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/01/26/ab-18.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/blog_altersfreigabe.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Vor mehr als 10 Jahren habe ich einmal im Auftrag des BMWI an
einer Studie zum Thema Jugendschutz im Internet
&lt;a href=&#34;http://blog.koehntopp.de/uploads/secorvo-studie-jugendschutz.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(PDF)&lt;/a&gt;


mitgearbeitet. Das war anstrengend, da das Thema Spielball zahlreicher
politischer Interessen ist, die sich dort gerne wiederfinden möchten, aber
die in der Studie wiedergegebene Ausgangslage ist heute noch unverändert.
Ich habe mein persönliches Fazit in kürzerer Form in einem
&lt;a href=&#34;https://blog.koehntopp.info/1999/05/01/rating-does-not-work.html&#34;&gt;Artikel&lt;/a&gt;


abgelegt,
aber auch dieses Ergebnis ist noch zu lang und zu technisch. Im Grunde kann
man die aktelle Situation wie in
&lt;a href=&#34;https://blog.koehntopp.info/2009/08/06/jugendschutzfilter-saugen-und-daf-r-gibt-es-einen-grund.html&#34;&gt;Jugendschutzfilter saugen und dafür gibt es einen
Grund&lt;/a&gt;


kurz und knackig darstellen.&lt;/p&gt;
&lt;p&gt;Eine Lösung für dieses Problem gibt es nicht. Es ist auch heute, 11 Jahre
nach der Studie, noch einfacher, sicherer und günstiger, Inhalte unbewertet
ins Internet zu stellen oder als Privatanbieter &amp;lsquo;frei ab 18&amp;rsquo; zu bewerten,
als sich um das niedrigste legale Rating für seine Inhalte zu bemühen. Und
so sind konsequenterweise auch meine Sites alle mit dem höchsten
generierbaren ICRA-Label versehen, das Minderjährige konsequent ausschließt
(wenn es denn jemanden kümmern würde, daß ein solches Label an meiner Site
klebt).&lt;/p&gt;
&lt;p&gt;Der &lt;a href=&#34;http://blog.odem.org/2010/01/12/Arbeitsentwurf-JMStV--Stand-2009-12-07.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;neue Jugendmedienschutz-Staatsvertrag&lt;/a&gt;


ist nun nichts weiter als ein Hilferuf des Staates. Der Staat &lt;em&gt;will&lt;/em&gt; nun
endlich nach Jugendschutzkriterien bewertete Angebote im Internet, und dabei
muß er Bedingungen erzeugen, die einerseits bewirken, daß die Bewertungen
nicht zu niedrig sind, andererseits es aber Anbietern nicht attraktiv
erscheinen lassen, sich sicherheitshalber zu hoch zu bewerten oder gar
unbewertet zu publizieren (was einer &amp;ldquo;ab 18&amp;rdquo;-Einstufung gleich käme).&lt;/p&gt;
&lt;p&gt;Der Arbeitsentwurf, der dabei veröffentlicht wurde, setzt allen Anbietern -
Inhaltsanbietern, Hostern und Providern - jetzt die Pistole auf die Brust.
Es ist die Art der Politik zu sagen &amp;ldquo;Löst dieses Problem jetzt, oder wir
machen Regeln, mit denen niemand zufrieden ist&amp;rdquo;. Blöd nur, daß die
wirtschaftlichen Rahmenbedingungen sich dabei in jedem Fall so verändern
werden, daß die Transaktionskosten für eine Veröffentlichung von irgendwas
steigen werden: Kostenlos ist grad teurer geworden.&lt;/p&gt;
&lt;p&gt;Andererseits ist das auch genau eine Linie der Politik der aktuellen
Regierung: Es sind die
&lt;a href=&#34;https://blog.koehntopp.info/2009/07/01/dir-fehlen-die-worte-oder-die-position-der-piratenpartei-zum-urheberrecht-in-einer-flatrategesellschaft.html&#34;&gt;kostenlosen&lt;/a&gt;


&lt;a href=&#34;https://blog.koehntopp.info/2009/07/01/urheberrecht-360-grad-ansicht.html&#34;&gt;Angebote&lt;/a&gt;


in ausreichender bis exzellenter Qualität, die derzeit den Medienwandel
treiben. Unsere Klientelregierung hat nun versprochen, dieses Problem zu
beheben. Konsequenterweise ist dieser Entwurf eines Jugendmedienschutzes
auch ein Anschlag auf die kooperative Kultur des Internets, denn es gilt,
kostenlose Angebote unattraktiver zu machen, um kompetetiven, traditionell
geldgestützt operierenden Sites mehr Luft zum Atmen zu geben. Da diese Sites
auch traditionellen Regulierungsinstrumentarien zugänglich sind, ist dies
politisch und wirtschaftlich wünschenswert.&lt;/p&gt;
&lt;p&gt;Die Analysen und Aufrufe von&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.1und1.de/2010/01/22/das_ende_der_freien_kommunikation_im_internet/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1 und 1&lt;/a&gt;

,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://andipopp.wordpress.com/2010/01/26/ich-schliese-mich-dem-vorauseilenden-gehorsam-an/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andi Popp&lt;/a&gt;

,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.internet-law.de/2010/01/zensur-uber-den-umweg-des.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Stadler&lt;/a&gt;

,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nerdcore.de/wp/2010/01/25/zensur-dank-jugendschutz/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nerdcore&lt;/a&gt;

 und&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.windfluechter.net/archives/889-Zensur-ueber-Umweg-des-Jugendmedienschutz-Staatsvertrags.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingo Jürgensmann&lt;/a&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;zeigen die wichtigen Punkt auf. Sie zeigen aber nicht, daß sich hier gerade
eine unheilige Allianz von Politik und Großmedien aufbaut, denen eine solche
Entwicklung genau die gewünschten Veränderungen erzeugt:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Die Publikation von kostenlosen, kooperativ erzeugten freien Inhalten wird aufwendiger.&lt;/li&gt;
&lt;li&gt;Es wird die Überwachungs- und Zensurinfrastruktur legitimiert, die schon
im Rahmen der Zensursula-Diskussion gewünscht wurde.&lt;/li&gt;
&lt;li&gt;Das ganze wird am Ende ein Muster-Anwendungsfall für den
elektronischen Personalausweis, der notwendig wird, um sich beim Provider
und beim Site-Betreiber für den Internet-Zugang und den Inhaltszugriff zu
legitimieren  und die Bedarfsträger können endlich mit Identitäten statt
IP-Nummern operieren, wenn sie ermitteln wollen.&lt;/li&gt;
&lt;li&gt;Mit diesen Identitäten lassen sich auch Meldungen und ihre Weitergabe
ausgezeichnet tracken, sodaß wir auch eine technische Basis für den
Verteilschlüssel der Einnahmen aus dem neuen Leistungsschutzrecht
haben.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Diesen politischen und wirtschaftlichen Drücken stellt man sich entgegen,
wenn man gegen diesen Entwurf ist. Um den Jugendschutz geht es dabei nur am
Rande.&lt;/p&gt;
&lt;p&gt;Andererseits kann man das ganze natürlich auch als die neue Kampagne der
etablierten Parteien für die Piratenpartei interpretieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jugendschutzfilter saugen und dafür gibt es einen Grund</title>
      <link>https://blog.koehntopp.info/2009/08/06/jugendschutzfilter-saugen-und-daf-r-gibt-es-einen-grund.html</link>
      <pubDate>Thu, 06 Aug 2009 09:10:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/08/06/jugendschutzfilter-saugen-und-daf-r-gibt-es-einen-grund.html</guid>
      <description>&lt;p&gt;Heise newstickert:
&lt;a href=&#34;http://www.heise.de/newsticker/Bundesregierung-sieht-grosse-Maengel-bei-Jugendschutz-Filtern--/meldung/143110&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bundesregierung sieht große Mängel bei
Jugendschutz-Filtern&lt;/a&gt;

.
Ach!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bislang habe keines der staatlich getesteten Jugendschutzprogramme, die
Filterregeln für beispielsweise von Eltern zu installierender
Schutzsoftware vorgeben, eine &amp;ldquo;akzeptable Wirksamkeit&amp;rdquo; entfaltet, schreibt
der federführende Beauftragte für Kultur und Medien, Bernd Neumann, in
seiner jetzt verfügbaren Antwort (PDF-Datei) auf eine Anfrage der grünen
Bundestagsfraktion. Zu viele zulässige Inhalte würden blockiert, und zu
viele ungeeignete Angebote würden durchgelassen, schreibt der
CDU-Politiker unter Berufung auf Tests im Prüflabor der Kommission für
Jugendmedienschutz (KJM) bei der länderübergreifenden Stelle
jugendschutz.net. Beide Mängel seien nicht wünschenswert.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Der Bericht hebt weiter darauf ab, daß die Anzahl der zu bewertenden Sites
sehr groß sei und die Inhalte sich zum Teil recht schnell ändern würden.
Eine automatische Klassifizierung von Inhalten funktioniere nicht, und daher
wolle man eine Selbstklassifizierung der Anbieter erzwingen.&lt;/p&gt;
&lt;p&gt;Eine Reflektion über die Situation und eine Ursachenforschung nach diesem
Dilemma wird nirgendwo erwähnt. Das wäre aber nützlich:&lt;/p&gt;
&lt;p&gt;Das erklärte Ziel solcher Sperrsoftware sei es, die &amp;ldquo;von aus
jugendschützerischer Sicht ungeeigneten&amp;rdquo; Webseiten zu blockieren. Das ist
als Missionsstatement natürlich falsch, denn dieses Ziel ist einfach zu
erreichen:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Man sperrt einfach alle Internetseiten komplett.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Das korrekt formulierte Ziel ist es, die aus jugendschützerischer Sicht
&lt;strong&gt;ungeeigneten Webseiten zu sperren &lt;em&gt;und&lt;/em&gt; alle anderen zu erlauben&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Das wird auch weiter oben im Text zugegeben, denn dort wird unter anderem
beklagt, daß zu viele zulässige Inhalte blockiert würden. So formuliert ist
dieses Ziel aber weitaus schwieriger zu erreichen, weil man nun nicht mit
einer kleineren Zahl von jugendgefährdenden Webseiten zu tun hat, sondern
mit allen Webseiten, die es gibt. Insbesondere muß man nun Aussagen über
nicht bewertete Webseiten machen.&lt;/p&gt;
&lt;p&gt;Bei Filmen und Videospielen ist das einfach - ein Film oder ein Videospiel
ohne Bewertung wird behandelt wie &amp;lsquo;frei ab 18&amp;rsquo;. Damit ist der Fall dort
erledigt, denn ein Film oder ein Videospiel zu publizieren ist ein
aufwendiger Akt und der Herausgeber des Mediums hat damit ein Interesse
daran, sein Werk nicht nur bewerten zu lassen, sondern auch eine möglichst
niedrige Bewertung zu erzielen, damit die Reichweite und damit die
erzielbaren Gewinne möglichst maximal sind. Es gibt nur sehr wenige Filme
und Videospiele, die nicht eine Jugendschutzbewertung haben.&lt;/p&gt;
&lt;p&gt;Im Internet ist das anders: Im Internet kennt man sehr viel mehr Autoren und
Werke, und die Kosten für die Erzeugung einer beliebigen Website sind
minimal. Wenn Arbeitszeit kostenlos ist, das Werk also als Hobby erstellt
wird, sind die Kosten für das Werk sogar Null. Damit fällt die Motivation
für eine Reichweitenmaximierung weg:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Im Internet will ein Herausgeber nicht so viele Personen als möglich
erreichen, sondern die richtigen: Gleichgesinnte oder Fans.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nur bei großen, kommerziellen Sites sind auch Kunden die Zielgruppe. Darum
ist die Motivation sein Werk bewerten zu lassen im Internet sehr viel
geringer - &amp;lsquo;Mir doch egal, ob Jugendliche oder Kinder auf meine Site
zugreifen können&amp;rsquo; ist keine so ungewöhnliche Formulierung.&lt;/p&gt;
&lt;p&gt;Selbst wenn jemand seine Site selbst bewertet oder bewerten läßt besteht das
Problem, welche Bewertung man denn vergibt. Denn wenn man eine Site zu hoch
bewertet - frei ab 18, obwohl sie frei ab 12 wäre - ist das folgenlos.
Bewertet man sie anders herum falsch - frei ab 12, obwohl sie frei ab 18
wäre - ist das ein Problem. Als Hobbyist oder engagierte Privatperson ist
man also nur dann auf der sicheren Seite, wenn man die Altersfreigabe für
seine Site eher zu hoch ansetzt.&lt;/p&gt;
&lt;p&gt;Die höchste Einstufung - frei ab 18 - bekommt man aber sowieso, wenn man gar
nichts tut und seine Site nicht selbst bewertet. Warum also überhaupt etwas
tun und ein rechtliches Risiko eingehen?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Die Folge ist, daß ein Klassifikationssystem für den Jugendschutz bei
Webseiten nicht greift.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Versuche hat es viele gegeben, aber im Allgemeinen sind diese nicht
erfolgreich gewesen in dem Sinne, daß sie eine Abdeckung hergestellt hätten.
Einige kommerzielle Sites haben sich selbst bewertet oder bewerten lassen,
aber die Masse der Sites eben aus den dargelegten Gründen nicht. Damit tritt
bei einer Sperrung unbewerteter Sites in einem Filter noch immer die
Situation aus dem Anfang ein - alle Sites sind gesperrt und der Jugendschutz
ist hergestellt, indem man Kinder und Jugendliche aus dem Internet fernhält.
Allenfalls ist ihnen ein Kindernet spezieller freigegebener, kommerzieller
Sites zugänglich (&amp;lsquo;Walled garden&amp;rsquo;). Das ist kaum geeignet, die von Erziehern
gewünschte Medienkompetenz zu erzeugen.&lt;/p&gt;
&lt;p&gt;Also die Experimente mit automatisierten Bewertungen nach formalen,
syntaktischen Kritieren wie Wortfilter oder Rosa-Pixel-Zähler. Dazu heißt es
in dem Artikel:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Wege der Fülle unzulässiger Inhalte im Internet kämen dabei neben
redaktionellen auch automatische Klassifizierungsverfahren zum Einsatz.
Diese sollten die Jugendschutzproblematik von Webseiten &amp;ldquo;an Hand
bestimmter Muster erkennen&amp;rdquo;. Falsche Einordnungen seien beim derzeitigen
Stand der Technik aber nicht zu vermeiden.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Das ist wenig überraschend. Die Klassifizierung einer Site nach
Jugendgefährdung ist am Ende eben keine syntaktische, sondern eine
semantische und moralische - es kommt nicht auf die verwendeten Worte an,
sondern was mit ihnen gesagt wird und wie das zu bewerten ist. Würden solche
automatisierten Filter tatsächlich zuverlässig funktionieren, hätten wir
eine Maschine gebaut, die in der Lage ist, Texte zu verstehen und auf der
Grundlage ihres Wissens von der Welt moralische Urteile über diese Texte
fällen kann.&lt;/p&gt;
&lt;p&gt;Wir hätten nicht nur das Problem der Maschinenintelligenz, sondern auch das
&lt;a href=&#34;http://blog.fefe.de/?ts=b486a79a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Problem der Maschinenmoral&lt;/a&gt;

 gelöst und
könnten als schöpferische Rasse beruhigt abtreten, weil wir den Funken des
Geistes an eine uns nachfolgende Form der Existenz abgegeben haben.&lt;/p&gt;
&lt;p&gt;Die Debatte über den Jugendschutz im Internet wird jedenfalls keinen
Millimeter von der Stelle kommen, solange die kommerziellen Verhältnisse im
Netz und wie die sich von denen in anderen Medien unterscheiden nicht
einbezogen werden. Sie wird auch nicht von der Stelle kommen, solange nicht
zugegeben und akzeptiert wird, daß Automatisierung in dieser Frage ein
sinnloses Unterfangen ist.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Es ist noch lange nicht vorbei.</title>
      <link>https://blog.koehntopp.info/2009/06/19/es-ist-noch-lange-nicht-vorbei.html</link>
      <pubDate>Fri, 19 Jun 2009 14:46:41 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2009/06/19/es-ist-noch-lange-nicht-vorbei.html</guid>
      <description>&lt;p&gt;So.&lt;/p&gt;
&lt;p&gt;Gestern ist es dann beschlossen worden - das
&lt;a href=&#34;http://www.spiegel.de/netzwelt/web/0,1518,631299,00.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zugangserschwerungsgesetz&lt;/a&gt;

.
Die Abstimmung war namentlich, auf Antrag der Grünen.
389 Abgeordnete dafür - ein CDUler, 3 SPDler dagegen, der Rest dafür, alle von der FDP und Links dagegen, einige Grüne haben gekniffen und mit Enthaltung gestimmt.
Auf &lt;a href=&#34;http://www.abgeordnetenwatch.de/internet_sperren-636-180----abst_ent.html#abst_verhalten&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Abgeordnetenwatch&lt;/a&gt;

 kann man nachsehen, wer genau was getan hat.&lt;/p&gt;
&lt;p&gt;Das Gesetz ist von der großen Koalition gegen den Rat von Experten, unter Ignoranz einer Rekordpetition mit
134014 Mitzeichnern und wahrscheinlich unter Missachtung der Verfassung noch vor der Sommerpause durchgeprügelt worden.
Gerade unter den im Internet aktiven SPD-Mitgliedern ist es dabei zu einer Folge von
&lt;a href=&#34;http://www.bjoern-boehning.de/2009/06/16/offener-brief-an-die-mitglieder-der-spd-bundestagsfraktion/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;offenen&lt;/a&gt;


&lt;a href=&#34;http://www.spiegel.de/netzwelt/web/0,1518,631159,00.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Briefen&lt;/a&gt;

 gekommen, und der
&lt;a href=&#34;http://netzpolitik.org/2009/online-beirat-der-spd-gegen-zensurgesetz/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Online-Rat&lt;/a&gt;


der SPD hat sich von dem Gesetz distanziert und seine Arbeit vorerst eingestellt.&lt;/p&gt;
&lt;p&gt;Die sachlichen und fachlichen Bedenken, die im Rahmen der politischen Diskussion genannt worden sind, sind im Gesetzestext bestenfalls pro-forma, aber de-facto gar nicht berücksichtigt worden.
Effektiv etabliert das Gesetz eine Zensurinfrastruktur in Deutschland, und öffnet weiteren Begehrlichkeiten Tür und Tor.
Das passiert dann auch umgehend:
Nicht nur will Thomas Strobel, CDU-Generalsekretär von BaWü, Abgeordneter und Schäuble-Schwiegersohn, eine
&lt;a href=&#34;http://www.heise.de/newsticker/CDU-Politiker-prueft-Websperren-fuer-Gewaltspiele-ernsthaft--/meldung/140763&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ausweitung der Sperren auf Computerspiele&lt;/a&gt;

,
sondern parallel dazu kommen Meldungen über
&lt;a href=&#34;http://www.nerdcore.de/wp/2009/06/18/samtliche-osterreichischen-gameshops-sollen-indiziert-werden/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Druck der bayrischen Kommission für Jugendschutz der Landesmedien auf Onlineshops in Österreich&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Es ist also
&lt;a href=&#34;http://www.heise.de/newsticker/Proteste-gegen-Gesetz-zu-Web-Sperren-reissen-nicht-ab--/meldung/140791&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nichts vorbei&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Was also ist die Bilanz bisher?&lt;/p&gt;
&lt;p&gt;Die ganze Aktion hat zu einer beispiellosen Politisierung von Menschen mit Lebensmittelpunkt im IT-Bereich geführt:&lt;/p&gt;
&lt;p&gt;Die ganze Affäre sollte auch dem letzten Geek und Websurfer klargemacht haben, daß es nicht mit Demonstrationen und dem Unterzeichnen von Petitionen getan ist.
Diese werden bestenfalls zur Kenntnis genommen, dann aber effektiv ignoriert und es wird weitergemacht wie bisher.
Das Bild, das Politiker vom &amp;lsquo;gemeinen Menschen auf der Straße&amp;rsquo;, von &amp;lsquo;Otto Normalverbraucher&amp;rsquo; haben, beinhaltet kein Counterstrike, keine DSL-Modems und auch keine nennenswerten IT-Kenntnisse.
Diese Fehlannahme zieht sich mehr oder minder stark durch alle existierenden politischen Parteien, mit Ausnahme der Piratenpartei und Teilen der Grünen.&lt;/p&gt;
&lt;p&gt;Der Effekt der Politisierung ist nicht nur in den Blogbeiträgen der Blogs erkennbar, die ich subscribed habe, sondern auch real messbar - das Treffen der Berliner Piraten letzten Dienstag war um etwa den Faktor 5 bis 8 größer als das Treffen vor vier Wochen.&lt;/p&gt;
&lt;p&gt;Der Umgang dieser Menschen mit den Fakten in einer politischen Diskussion unterscheidet sich auch sehr von dem, was man bisher so gewohnt war.
Die normalen Instrumente der Volksbeeinflussung - Zeitungsartikel, Lobbygruppen und andere Marionetten haben versucht, das übliche Theater aufzuführen, aber der Zusammenschluss von Menschen im Netz (
&lt;a href=&#34;http://de.wikipedia.org/wiki/Crowdsourcing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crowdsourcing&lt;/a&gt;

) hat hier Zusammenhänge aufgedeckt und Gegenaktionen generiert, die die Poltik so nicht gewohnt war.&lt;/p&gt;
&lt;p&gt;So wurde im Rahmen der Diskussion die suspekte
&lt;a href=&#34;http://de.wikipedia.org/wiki/Deutsche_Kinderhilfe#Debatte_um_Sperrung_von_Internetseiten&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deutsche Kinderhilfe&lt;/a&gt;


als gesteuerte Hetzorganisation CDU-naher Kreise aufgedeckt, und die
&lt;a href=&#34;http://www.carechild.de/news/politik/internetzensur_getuerkte_umfrage_der_deutsche_kinderhilfe_e.v._widerlegt_582_1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;durch manipulative Fragestellungen erzielten Umfrageergebnisse der DKH&lt;/a&gt;


mit einer Gegenumfrage widerlegt.
Die Organisation ist für Propagandazwecke nun verbrannt - das Netz wird sich an Namen und Personen bei Bedarf erinnern.&lt;/p&gt;
&lt;p&gt;Aber auch andere Behauptungen und Tricksereien, die im Zusammenhang mit dieser Debatte immer wieder verwendet worden sind, sind durch Verwendung frei zugänglicher Quellen aufgedeckt worden:
Die Behauptung, das BKA könne Webseiten nicht wie der AK Zensur durch Anschreiben der Provider sperren lassen hat sich als
&lt;a href=&#34;http://blog.odem.org/2009/06/bka-abuse-mails.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;falsch herausgestellt&lt;/a&gt;

,
die von der Bundesregierung behaupteten Sachverhalte haben nach
&lt;a href=&#34;http://blog.odem.org/2009/06/bundesregierung-keine-kenntnis.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;einer kleinen Anfrage&lt;/a&gt;


der FDP keine faktische Basis und die als Beispiel genannten ausländischen Sperrlisten haben nach
&lt;a href=&#34;http://blog.odem.org/2009/05/islam-website-aus-deutschland-auf-sperr-liste.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eingehender Untersuchung&lt;/a&gt;


eine erbärmliche Qualität.&lt;/p&gt;
&lt;p&gt;Vor allen Dingen hat sich aber gezeigt, wie gefährlich die gegenwärtige Regierungskoalition der Partei der Über-60-Jährigen Internetausdrucker und der rückgratlosen Verräter ist, wenn man sie denn machen lässt - das kann man vielleicht als größten Erfolg der Sache mitnehmen.
134014 aktivierte politische Personen, alle von ihnen Multiplikatoren.
Aber das sind mit Sicherheit noch nicht alle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rating does not work</title>
      <link>https://blog.koehntopp.info/1999/05/01/rating-does-not-work.html</link>
      <pubDate>Sun, 02 May 1999 09:00:00 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/1999/05/01/rating-does-not-work.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Version 1.3 (Revised 29-Sep-1999, Updates from Seth Finkelstein)&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;rating-does-not-work&#34;&gt;
    &lt;a href=&#34;#rating-does-not-work&#34;&gt;
	Rating does not work
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h4 id=&#34;by-kristian-and-marit-köhntopp&#34;&gt;
    &lt;a href=&#34;#by-kristian-and-marit-k%c3%b6hntopp&#34;&gt;
	by Kristian and Marit Köhntopp
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;Content rating models such as PICS have been proposed as a
solution to the problem of unwanted, harmful or prohibited
content on the Internet. This document contains a number of
Theses which support the claim that any Internet Content Rating
and Selection (ICR&amp;amp;S) scheme including PICS cannot work as
advertised.&lt;/p&gt;
&lt;p&gt;To our knowledge, most of the problems and objections here have
not been addressed by PICS or any other ICR&amp;amp;S scheme.&lt;/p&gt;
&lt;h2 id=&#34;identifying-the-parties-involved&#34;&gt;
    &lt;a href=&#34;#identifying-the-parties-involved&#34;&gt;
	Identifying the parties involved
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;This section tries to identify the parties involved in the
process of running and rating the web and their roles (see below
to understand why we concentrate on the web). In small
installations, a single person may impersonate multiple roles.&lt;/p&gt;
&lt;h3 id=&#34;server-side-roles&#34;&gt;
    &lt;a href=&#34;#server-side-roles&#34;&gt;
	Server side roles
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;content provider&lt;/em&gt; is the role which is responsible for all
content of a document. Often the content provider is the creator
of a document, but on the Internet it is common that a content
provider only provides means to create content, and does not
actually create the content on a site. Examples are discussion
boards, search engines, live video feeds, and similar
installations. Depending on the size of this content, it is
entirely possible that the content provider does not have direct
knowledge of all content on a site and that much content on a
site is not reviewed nor endorsed by a content provider.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;presence provider&lt;/em&gt; or &lt;em&gt;web hoster&lt;/em&gt; provides the means to
serve this content to the Internet by running the machines, the
server software, and maintaining a network connection.&lt;/p&gt;
&lt;h3 id=&#34;recipient-side-roles&#34;&gt;
    &lt;a href=&#34;#recipient-side-roles&#34;&gt;
	Recipient side roles
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;An &lt;em&gt;access provider&lt;/em&gt; runs the systems and network connections
for the recipient of content. For small office and home use,
this is currently often a dial-up service, a proxy server, and
similar hard- and software.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;recipient&lt;/em&gt; is either a person to be protected against
harmful content, or an adult, which still should be able to
access harmful, but not prohibited, content. The recipient&amp;rsquo;s hard-
and software is maintained by &lt;em&gt;system services&lt;/em&gt; which is a
separate department in a school or library situation, in an
Internet Cafe, or within a company. The recipient&amp;rsquo;s system may be
a single system or a network of systems with proxy servers and
intranet servers.&lt;/p&gt;
&lt;h3 id=&#34;internet-content-rating-and-selection-icrs-roles&#34;&gt;
    &lt;a href=&#34;#internet-content-rating-and-selection-icrs-roles&#34;&gt;
	Internet Content Rating and Selection (ICR&amp;amp;S) roles
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Developers of rating systems&lt;/em&gt; define the dimensions of a rating
system and create rules how to apply values along these
dimensions to content. They promote their rating systems so that
they become popular and are widely used.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;rating service&lt;/em&gt; will apply the rating system and the rules
that come with it to create ratings. These ratings, an
identifier for the rated content, a date, an identifier for the
rating source, and additional information (i.e. a checksum
against the rated content and a digital signature) are collected
to form a content label.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Content filter vendors&lt;/em&gt; create software which can regulate
access to content, depending on local settings (filtering rules)
and content labels.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Content filter control&lt;/em&gt; is often exercised by the party who
controls a machine, that is, the adult party in a household,
the dean of a school, the directorate of a library, and so on.
These filter settings are then &lt;em&gt;deployed&lt;/em&gt;, often by system
services mentioned above, sometimes by an access provider
located upstream.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Attackers&lt;/em&gt; may be content providers, recipients, or other
parties who want to communicate outside of the control of a
filtering system.&lt;/p&gt;
&lt;h3 id=&#34;methods-for-content-selection&#34;&gt;
    &lt;a href=&#34;#methods-for-content-selection&#34;&gt;
	Methods for content selection
    &lt;/a&gt;
&lt;/h3&gt;
&lt;h4 id=&#34;principle-of-operation&#34;&gt;
    &lt;a href=&#34;#principle-of-operation&#34;&gt;
	Principle of Operation
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The basic idea behind Internet Content Rating and Selection is
to attach a kind of machine-readable description, called a
Content Label, to all Internet Content. The Content Label
contains a set of ratings which make up a formal description of
the rated content in a formally specified system of ratings.
Finally, the recipient has to have a filtering mechanism before
or on the recipients machine which allows or intercepts
reception and display of requested content depending on the
Content Label and some local configuration.&lt;/p&gt;
&lt;h4 id=&#34;taxonomy-of-rating-systems-by-source-of-rating&#34;&gt;
    &lt;a href=&#34;#taxonomy-of-rating-systems-by-source-of-rating&#34;&gt;
	Taxonomy of Rating Systems by Source of Rating
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The Content Labels may be provided by different parties. In
Third Party Rating, a party that is neither the recipient nor the
sender creates content labels and distributes them via a Label
Bureau. Third Party Rating requires a method to uniquely
identify content components, and Third Party Rating cannot be
finer grained than this identification system. Currently, all
identification systems are URL-based which implies that all
Content Labels refer to either URLs or coarser grained objects
(such as subtrees of a web server or an entire site).&lt;/p&gt;
&lt;p&gt;In Second Party Rating, the recipient provides ratings and
shares them with other recipients. This is sometimes referred to
as a Community Rating process. Since the sharing of ratings
again involves a Label Bureau, for the purpose of this
discussion Third Party Rating and Second Party Rating can be
treated alike.&lt;/p&gt;
&lt;p&gt;First Party Rating is different because here the sender
provides a Content Label with the content itself. Usually, this
label is embedded into the content or sent with the content. A
Label Bureau is not needed in this context.&lt;/p&gt;
&lt;h4 id=&#34;taxonomy-of-selection-mechanisms-by-point-of-interception&#34;&gt;
    &lt;a href=&#34;#taxonomy-of-selection-mechanisms-by-point-of-interception&#34;&gt;
	Taxonomy of selection mechanisms by point of interception
    &lt;/a&gt;
&lt;/h4&gt;
&lt;p&gt;The selection process at the recipients end can either be
implemented directly on the machine of the recipient, or it can
be part of a proxy solution upstream of the recipients computer.
In the latter scenario, the selection process will not happen on
a machine controlled by the recipient and it is much more
difficult to manipulate by the recipient. A proxy-based
selection requires that the recipient is forced to use this
particular proxy to be able to access content at all (otherwise
the recipient could elect not to use a proxy at all or to use a
different proxy) and that the content can be identified and read
by the proxy.&lt;/p&gt;
&lt;h2 id=&#34;theses&#34;&gt;
    &lt;a href=&#34;#theses&#34;&gt;
	Theses
    &lt;/a&gt;
&lt;/h2&gt;
&lt;h3 id=&#34;internet-content-rating-and-selection-applies-only-to-the-web&#34;&gt;
    &lt;a href=&#34;#internet-content-rating-and-selection-applies-only-to-the-web&#34;&gt;
	Internet Content Rating and Selection applies only to the Web
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Internet Content Rating and Selection does apply properly only
to the web, because of the little degree of interactivity and
the large size of the communicated objects in the web. More
interactive services or services with smaller objects are
less likely to adopt such a system for content control with
success. For example, USENET newsgroups are highly interactive
and very fast communication channels with only little structure.
The focus on discussion and contents, and the style of such
discussions may change very quickly.&lt;/p&gt;
&lt;p&gt;USENET articles are authored on the fly. Often they contain no
keywords, subject lines of little use, or are inappropriately
addressed. It is very unlikely that authors of USENET articles
will take the time required to do proper First Party Rating for
their articles, even if current USENET access programs offered
such a feature.&lt;/p&gt;
&lt;p&gt;Chatrooms and the Internet Relay Chat consist of even faster
communication and no structure at all. IRC channels are often
created on the fly and, unlike USENET, communication on IRC is not
stored but only passed through by the servers. Also, the basic
unit of communication in IRC is a single line of text which is
much too small to rate properly. An IRC channel at any point in
time is a very complex web of rapidly changing and overlapping
individual and nonindividual communications that make up the
overall tone and content of the channel.&lt;/p&gt;
&lt;p&gt;Also, the public discussions in USENET newsgroups or IRC
channels are only the publicly visible part of a much larger
communication process which involves private communication by
mailing lists, private e-mail, server based message
communication, and direct client-client communication. Often the
public communication channel is only used to meet other persons
with similar interests, and then a more secluded communication
channel is established.&lt;/p&gt;
&lt;p&gt;Because of these properties of the more interactive
communication mechanisms, Internet Content Rating and Selection
will be ineffective in these type of media.&lt;/p&gt;
&lt;h3 id=&#34;labeling-content-that-is-not-harmful-nor-prohibited-is-a-requirement-but-cannot-be-enforced&#34;&gt;
    &lt;a href=&#34;#labeling-content-that-is-not-harmful-nor-prohibited-is-a-requirement-but-cannot-be-enforced&#34;&gt;
	Labeling content that is not harmful nor prohibited is a requirement but cannot be enforced
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The ultimate goal of Internet Content Rating and Selection is to
make harmful content inaccessible to minors and make prohibited
content inaccessible to all recipients on the Internet.
Basically, it would be sufficient to label all harmful and
prohibited content accordingly, so that it can be recognized and
intercepted. For First Party Rating, this requires the
cooperation of the provider of this content, so that the Label is
being delivered with the content itself. For Third Party Rating,
cooperation of the content provider would simplify the process
enormously, for example by providing stable identifiers for the
content or by organizing the content in a way that makes it
easier accessible to quick and accurate rating.&lt;/p&gt;
&lt;p&gt;It can be safely assumed that this kind of cooperation will not
be available in many cases and that it specifically will not be
available in the most severe cases where the content provider
places content on the web with a malign purpose.&lt;/p&gt;
&lt;p&gt;Thus, it is insufficient to block pages that are rated as
containing harmful or prohibited content. Instead, all unrated
pages must be blocked as well, so that the pages of
non-cooperating content providers will be made inaccessible. In
this case, the rating of harmful and prohibited content becomes a
moot point because such content will be blocked automatically.
The Internet as viewed from behind a filter will be immediately
clean in such a scenario because it will initially contain no
content at all. Clearly, this is not very attractive and most of
the targeted audience for content filtering services will not
tolerate such filters if large portions of harmless or valuable
content will be made unavailable to them by the content filter.&lt;/p&gt;
&lt;p&gt;For a Content Rating Solution, it becomes a requirement to
provide Content Labels for non-objectionable content, so that at
least some pages will be available to those persons behind the
selection filter. Thus, all burden and cost of content rating,
labelling, and label distribution is placed on the providers of
perfectly legal, and in most cases, valueable content.&lt;/p&gt;
&lt;p&gt;This situation is not different from, for example, the movie and
video industry where a film without a rating is automatically
rated as not suitable for minors (at least this is the case e.g.
in Germany and the United States). Unlike the movie industry,
many content providers have little or no incentive to have their
content rated because in many cases they do not sell content or
do not cater specifically to a younger audience. Specifically,
we can expect the large commercial websites positioned towards a
younger audience to provide content labels on a voluntary basis,
while most private content and content not specifically geared
towards a young audience will not have labels at all.&lt;/p&gt;
&lt;p&gt;Consequently, it may be necessary to enforce the provision of
labels with content to make a sufficiently large portion of the
Internet available to minors. Some content providers will
probably try to evade such a requirement by providing a &amp;ldquo;safe&amp;rdquo;
default rating, such as &amp;ldquo;harmful content, not suitable for
minors&amp;rdquo;, because they do not want to do the work to properly
evaluate and individually label their content. Others will do
this because they are insecure about the correct rating for
their content, and will rate their content more harmful as it
actually is, just to be legally safe. For a requirement to
provide labels to be effective, it may be necessary to treat the
provision of a too high label just like the provision as a label
that is too low.&lt;/p&gt;
&lt;p&gt;This turns the situation perfectly upside down: To protect
against harmful and prohibited content, all work and all legal
liability is at the side of the well-behaved members of the
community, while it is technically completely unnecessary for
the providers of harmful content to do anything.&lt;/p&gt;
&lt;p&gt;In some countries, rating your own content cannot be legally
enforced (see below).&lt;/p&gt;
&lt;h3 id=&#34;establishing-a-metric-invites-a-dysfunction&#34;&gt;
    &lt;a href=&#34;#establishing-a-metric-invites-a-dysfunction&#34;&gt;
	Establishing a metric invites a dysfunction
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;A rating system for content is essentially a metric. The metric
may have one (&amp;ldquo;suitable for age x&amp;rdquo;) or multiple dimensions
(&amp;ldquo;contains sex x1, nudidity x2, violence x3 and language x4&amp;rdquo;),
and within one dimension it may be non-ordered (&amp;ldquo;contains any of
the following: smoking, gambling, drug abuse, violence as a
method of conflict resolution&amp;rdquo;), ordered (&amp;ldquo;a violence rating of
3 means that there is more violence in a particular content than
in a content with rating 2&amp;rdquo;), with discreet or continous values.&lt;/p&gt;
&lt;p&gt;A rating system is a cultural code, too, because with the
dimensions and values provided with any such metric comes a
decription on how to interpret and apply them. As a cultural
code, a rating system cannot be objective or valid outside a
specific culture. Specifying the dimensions of the rating
system, for example, defines which issues can be addressed by a
particular rating system. Issues and values outside of the
dimensions of the rating system cannot be addressed, and are
therefore inaccessible to reflective discussion within the space
of the rating system. For the purpose of the rating system, such
issues and values essentially do not exist.&lt;/p&gt;
&lt;p&gt;Values within the dimensions of the rating systems can be used
to define proximity relationship if these values are ordered.
Many people tend to think of content that is in close proximity
as being similar, being of similar value, or promoting similar
values. Some content providers insist that their content is not
to be rated with some content rating systems because rating them
with that particular system would place them into the proximity
of other content they do not like, and with which they do not
want to be lumped together [1][2]. For example, both hardcore
pornographic bondage content and a documentation about torture
methods in the holocaust would receive very similar content
ratings within the RSACi rating system. The RSACi system is too
coarse and has no appropriate dimensions to differentiate
between these two types of content. More complex rating systems
raise ease-of-use issues in First Party Rating situations,
though. Also, more context sensitive rating systems raise other
issues, too (see below).&lt;/p&gt;
&lt;p&gt;Establishing a metric in a social context and granting rewards
under this metric tends to create dysfunctional social systems.
For example, measuring the efficiency of programmers by
measuring the lines of code produced by them tends to work in
favour of code that has been produced by cutting and pasting
large segments of code. Such code is generally large,
ineffective, and expensive to maintain. Thus, while the metric
provides useful information when used short-term, it tends to
work destructively when used for longer periods of time (Tom
DeMarco, &amp;ldquo;Why does software cost so much?&amp;rdquo;, Essay 2).
Essentially, degradation begins when the metric is used for a
period long enough to allow for feedback loops.&lt;/p&gt;
&lt;p&gt;A classic dysfunctional metric that can be observed on the web
is rating the efficiency of a banner ad on a web page by
counting hits to that banner ad. Using this metric for a longer
time tends to encourage people to put content on their pages
that creates page impressions and to load many banner ads on
such pages. The result is your average free porn page. It also
encourages spamming search engines and the network with ads for
a particular page to increase page impressions. The ultimate
dysfunctional perversion is to load the page with JavaScript
code that opens further pages with banner ads when the user
tries to leave or close the page. While the banner ads are not
recognized by the user, at best, and create a negative image for
the product advertised, at worst, such pages do generate lots of
hits on a counter and are therefore favoured by the metric.&lt;/p&gt;
&lt;p&gt;Because cultural and moral values cannot be expressed and
measured directly like volts and ohms, any such metric will show
dysfunctional behaviour and finally invalidate itself when used
for a longer time. Obvious examples are things like exempting
news sites from the requirement to rate content to relieve them
from the burden to provide ratings for rapidly changing pages -
this will provoke providers of content that rates bad under any
given rating system to present their content in the format of a
news site to get the bonus of exemption. Similarly, exempting
web discussion forums from a requirement to provide ratings will
make badly rated sites to adapt and to chose a forum-like
format.&lt;/p&gt;
&lt;p&gt;Because of the inability to address cultural or moral values
objectively and outside of the context of a particular culture
or moral system, it would be only logical and very tempting to
create context sensitive rating systems. Context sensitivity
here goes two ways: it may rate a specific content component
within the presentation context, and it may rate specific content
within a specific cultural context.&lt;/p&gt;
&lt;p&gt;For example, singular pornographic images may rate bad in a
certain system, but a photomosaic(tm) of girlie-power icon Lara
Croft consisting of lots of such images may rate good within the
same system because of artistic value and the message promoted
by this artwork. So while the individual photo may still rate
bad, in this particular context of presentation it will rate
good. Also, a photo of James Dean leaning against his car and
smoking a cigarette may rate good in some cultural contexts by
showing a celebrity in a pop-art context, and bad in others as
promoting environmentally bad modes of transport and nicotine
drug abuse, depending on the priority of values of the culture
perceiving the image. These priorities may change within the
same culture or even the same recipient, depending on fashion or
even personal mood.&lt;/p&gt;
&lt;p&gt;What is more, only the process of filtering content which may
appear as rating bad in a given context may actually create
objectionable content in another context. For example, by
suppressing all images which rate bad in one context there may
be created a pattern that conveys a message of objectionable
content [3].&lt;/p&gt;
&lt;p&gt;So while context specific labelling is seductive as a way out of
the dysfunctionality problem, it is also error prone,
unenforceable (Would you please try to rate your web pages
within the cultural context of the Amish People, the values of
the current Nipponese, Spanish and Scandinavic societies?) and
favouring one specific cultural context is of course an act of
culture imperialism. It is also a value rating (&amp;ldquo;The context
rating on your web page/for our web page in your rating service
implies that you have authority to decide what
Christian/Scientologian/Buddhist/&amp;hellip; values are and that our
page is bad according to what you assert these values are.&amp;rdquo;) with all
problems that come with such ratings, including a ton of
liability issues.&lt;/p&gt;
&lt;h3 id=&#34;translating-from-one-metric-into-another-does-not-work&#34;&gt;
    &lt;a href=&#34;#translating-from-one-metric-into-another-does-not-work&#34;&gt;
	Translating from one metric into another does not work
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Different metrics have different underlying cultural and moral
value systems and different assumptions for judgement. Unlike
algebraic spaces, the spaces created by such metrics cannot be
mapped onto each other without loss (sometimes they cannot be
mapped at all). Certain dimensions may not exist in the target
metric and must be emulated. For example, it is impossible to
translate the one-dimensional Video Standards Council metric for
video films (&amp;ldquo;general viewing&amp;rdquo;, &amp;ldquo;PG&amp;rdquo;, &amp;ldquo;R&amp;rdquo;, &amp;hellip;) into the RSACi
(integer numbers between 0 and 4 in each of the categories of
Sex, Nudidity, Violence, and Language), even though the target
systems seems to be more expressive, having more dimensions and
values.&lt;/p&gt;
&lt;p&gt;Some proposals offer functionality that can be used to bundle
presets in different rating systems into a single profile. For
example, the PICSRules extension to the PICS system allows a
user to define a single profile that contains an arbitrary
number of selective criteria applied to different PICS compliant
content ratings systems.&lt;/p&gt;
&lt;p&gt;A user of such a PICSRule may be able to view content that rates
this-or-that under SafeSurf ratings or such-and-such under RSACi
ratings. Using such a system may create the impression that the
this-or-that SafeSurf rating and the such-and-such RSACi rating
are equivalent and that it is therefore possible to map one
system onto the other. This is a thouroughly false impression.&lt;/p&gt;
&lt;p&gt;What does work (in PICSRules) is to bundle arbitrary selective
preferences into a profile, but this profile is in general (and
probably in practice in most cases) not consistent or
well-defined. Consider content that has been rated under two
different rating systems and a majority of reviewers agreed in
both cases that these ratings are correctly applied to this
particular content. Assume further a recipient that is asked to
define a filtering profile for his or her child in both of the
rating systems reflecting the personal cultural values that this
child should be able to expose itself to. Unless the page has
a marginal rating (i.e. totally harmless or totally
unacceptable), it will be common that the page will be rated
accessible under one rating system, but inaccessible under the
other, i.e. the ratings do not functionally map onto each other
because of the different implied cultural values within the
metric itself.&lt;/p&gt;
&lt;h3 id=&#34;e-commerce-and-icrs-are-natural-adversaries&#34;&gt;
    &lt;a href=&#34;#e-commerce-and-icrs-are-natural-adversaries&#34;&gt;
	E-commerce and ICR&amp;amp;S are natural adversaries
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The introduction of the Internet marks the ultimative shortening
of the communication pipeline, completely industrializing the
process of communication. Historically, the number of people and
institutions involved in the production and reproduction of a
specific publication has continually decreased. While many
people had to copy each page of a book manually in medival
times, the introduction of the printing press has dramatically
simplified the process. The advent of DTP technology has further
eliminated persons and institutions from this process by cutting
out the typographer, the layouter, and the editor. Xerox
technology has cut out printers for small editions.&lt;/p&gt;
&lt;p&gt;On the Internet, all persons have been cut out except for the
sender and the recipient. Production, reproduction and
distribution of content are automated or controlled by either
party. In many cases, content location has been automated, too,
by using search engines, portal sites, web rings, or bookmark
lists. In some cases, even content processing has been automated
where automatic translation services, summary generator services,
or XML postprocessing are already deployed, thus limiting the
personal involvement of the receiver as well. Also, in cases
where content is being produced automatically, such as in
catalog systems, database driven web shops, or in community
content systems like slashdot.org, the involvement of the sender
in content creation is limited, too.&lt;/p&gt;
&lt;p&gt;This does not mean that the absolute number of people involved
in the creating or processing of content has decreased. In
fact, there are many people needed to keep the Internet running
and to update web content. But these people are no longer
involved in a single specific project (working as craftsmen),
instead they keep running a generalized infrastructure which is
used to transport and produce many, many different works (they
are working as industrial workers).&lt;/p&gt;
&lt;p&gt;E-commerce directly benefits from this, shortening supply and
retail chains to a length of 1, or where processing is
completely automated, even to a length of 0. E-commerce requires
that concealed, tamperproof 1:1 communication is possible, i.e.
that the infrastructure can be used to transport certain
transactional data, but without the ability to gain knowledge of
the actual transactional content, and without the ability to
change that content.&lt;/p&gt;
&lt;p&gt;This is essentially the opposite of the requirements for ICR&amp;amp;S,
because ICR&amp;amp;S is all about gaining knowledge about the
transported content and from case to case tampering with it
(i.e. replacing the original content with a &amp;ldquo;this content is
inaccessible&amp;rdquo; message). You cannot build secure e-commerce on
any network that is capable of ICR&amp;amp;S and you cannot build
functioning ICR&amp;amp;S on any network that provides secure e-commerce
services - see below.&lt;/p&gt;
&lt;h3 id=&#34;proxy-based-icrs-cannot-work-in-an-e-commerce-enabled-environment&#34;&gt;
    &lt;a href=&#34;#proxy-based-icrs-cannot-work-in-an-e-commerce-enabled-environment&#34;&gt;
	Proxy-based ICR&amp;amp;S cannot work in an E-commerce enabled environment
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;In an installation where E-commerce is possible, it is
impossible to successfully deploy proxy-based ICR&amp;amp;S, because at
any time harmful or prohibited content can arrive in the form of
E-commerce transactions, i.e. serving porn pages from an SSL
server. The proxy cannot detect labels within such a connection
because the entire connection is a military-grade encrypted,
digitally signed, tamperproof connection pipe from within the
browser program into the remote web server. Improvements in
E-commerce, i.e. the wide deployment of S/WAN, IPsec and other
services, will only worsen this situation.&lt;/p&gt;
&lt;h3 id=&#34;recipient-based-icrs-can-only-work-in-a-cooperative-setting&#34;&gt;
    &lt;a href=&#34;#recipient-based-icrs-can-only-work-in-a-cooperative-setting&#34;&gt;
	Recipient-based ICR&amp;amp;S can only work in a cooperative setting
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Because most current recipient platforms have no (Win 95, Win 98)
or insufficient (Windows NT) local security, and because the
recipient platform is generally under physical control of the
recipient, there is essentially no way to keep the recipient
from tampering with the installation of the selection
mechanism.&lt;/p&gt;
&lt;p&gt;Most local content filters can be easily deactivated by setting
a few registry keys, rewriting a line in an *.ini file, or by
copying some original operating system files that have been
replaced by the filter back into the system. The process only
has to be reenginieered once and can then be automated,
requiring no expertise at all from the user of such an automated
attack tool.&lt;/p&gt;
&lt;h3 id=&#34;third-party-rating-cannot-be-based-on-urls&#34;&gt;
    &lt;a href=&#34;#third-party-rating-cannot-be-based-on-urls&#34;&gt;
	Third Party Rating cannot be based on URLs
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;All widely deployed systems for ICR&amp;amp;S are currently using URLs
to identify content and to tie their ratings to such content.
This approach is basically broken because URLs do not map to
content, not even in the case of static content.&lt;/p&gt;
&lt;p&gt;For static pages, current webservers offer a lot of facilities
to negotiate the actual content which is being served in response
to a specific URL. In particular, serving language specific
content is very popular. For example, the homepages of
multinational projects (like the Debian Linux project,
&lt;a href=&#34;http://www.debian.org&#34;&gt;&lt;a href=&#34;http://www.debian.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.debian.org&lt;/a&gt;

&lt;/a&gt;) are negotiated based on the language
preferences that were expressed with a HTTP request. Also, many
pages serve different content, depending on the IP-address or
domain the request originated from or customize their content
depending on the current time [4].&lt;/p&gt;
&lt;p&gt;The problem worsens when it comes to dynamically generated
pages, where the actual webpage which the client receives never
exists on the server, but is created just as it is requested.
The contents of such a page may change from one request to the
next, even if all other parameters are identical. The server may
take any parameters into account when creating the page,
including internal state (memory of previous requests). Because
internal state is kept on the server only, it is impossible to
fully describe all request parameters needed to recreate a
specific content without thorough knowledge of the application
running on that particular server.&lt;/p&gt;
&lt;p&gt;But even if we have perfectly static, non-negotiated content,
URLs are inadequate to address content. URLs describe storage
display objects such as images and HTML pages, but content can
be smaller or larger than such pages.&lt;/p&gt;
&lt;p&gt;For example, the start page of any portal, news site or
discussion forum contains many small, unrelated articles which
are presented in overview form. Each individual article is a
semantic unit with different properties regarding a rating
system, but with URLs we can only address the whole page and
assign a rating to the entire page.&lt;/p&gt;
&lt;p&gt;Conversely, a page or a site may be pieced together from
individual documents which form a greater semantic unit that
deserves a certain rating only when viewed as a whole. This may
be true, for example, for an AIDS information site or a holocaust
memorial site which may contain texts and images that deserve a
very different rating when taken out of their original context.&lt;/p&gt;
&lt;p&gt;HTML provides no mechanism to address subentities of a page or
to address pages collectively. Some extentions to the XML
specification will slightly improve this situation.&lt;/p&gt;
&lt;h3 id=&#34;third-party-rating-cannot-keep-up&#34;&gt;
    &lt;a href=&#34;#third-party-rating-cannot-keep-up&#34;&gt;
	Third Party Rating cannot keep up
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Third Party Rating is based on the assumption that a single
database can list ratings for external pages, so that a
recipient with an enabled filter can cover a large enough
portion of the Internet for the net to become useful. Search
engines work under a similar assumption, only they can
automatically process and store pages, whereas proper content
rating, being a process that involves moral and cultural
evaluation and decision making, requires manual intervention.
But a recent survey of search engines found that they cover only
a small percentage of the web, ranging from 10% to 35% of all
pages [5]. The survey also observed a strong growth in the
general size of the web.&lt;/p&gt;
&lt;p&gt;The problem is worsened for both ICR&amp;amp;S systems and search
engines because there is no mechanism for web pages to notify
indexing and rating services of a change. Web sites in general
do not know which other services keep pointers to them and need
to be notified of updates. Also, there is no mechanism to bind
content identities to certain versions of that content, i.e.
there is no way to work a modification date and/or a content
checksum into a URL which designates certain content.&lt;/p&gt;
&lt;p&gt;Third Party Rating is also impossible for content that is
available only after passing a password protection (closed user
groups, [5] talks about a &amp;ldquo;publicly indexable Web&amp;rdquo;). Some closed
user groups are not so closed after all, though: With a simple
registration, the protected area opens up. In such cases, the
password protection essentially keeps all automated content
processors and some casual browsers outside.&lt;/p&gt;
&lt;h3 id=&#34;third-party-rating-creates-privacy-issues&#34;&gt;
    &lt;a href=&#34;#third-party-rating-creates-privacy-issues&#34;&gt;
	Third Party Rating creates privacy issues
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Third Party Rating raises the issue of label distribution
without cooperation of the content provider, leading directly to
the creation of Label Bureaus which can distribute labels for
any content, independently from the distribution of the original
content. Connection between the content which has been rated and
the label is being made via some content identifier, currently
usually URLs. Currently, in some ICR&amp;amp;S systems such as PICS,
there are simple provisions to test if the content that has been
rated and the content that is actually served are still
identical. Such a test may be a check for the creation date of
the content or the distribution of a MD5 checksum for the
content with the label. Usually, these provisions are optional
and in many existing implementations they are not being used,
leaving the system without a check for label validity (This
should really be another headline, &amp;ldquo;Current implementations
generally suck&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;To get labels from a Label Bureau, the client system has to ask
the Label Bureau each time a piece of content is being
requested. Because it can be expected that the Label Bureaus
provides its services for money, we can assume that each of
these requests is identified and authenticated, so that the Label
Bureau can charge for its services. Label Bureaus will therefore
automatically get large and detailed trails of all requests a
certain user creates while surfing the web, creating a large
user profile of (identity, time, URL) triples.&lt;/p&gt;
&lt;h3 id=&#34;third-party-rating-has-no-standard-complaints-procedure&#34;&gt;
    &lt;a href=&#34;#third-party-rating-has-no-standard-complaints-procedure&#34;&gt;
	Third Party Rating has no standard complaints procedure
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;In Third Pary Rating, some group essentially applies a set of
ratings to web content which directly influences the reach this
content will have. Current implementations, such as PICS
compliant systems, define how such a rating may be applied to web
pages technically, but they define no standard procedures for
rating services and labelling bureaus at all.&lt;/p&gt;
&lt;p&gt;In current implementations, there is no standard procedure with
which a content provider is being notified that content has been
rated or on which grounds these ratings have been established.
In fact, some (usually propietary, non-PICS) rating services do
not expose their rating criteria for public inspection or even
encrypt their ratings in trying to hide which services they
disapprove of [6]. These services often argue that this
procedure is necessary so that their rating service cannot be
inverted, i.e. turned into a search engine for objectionable
content. Decryption of such rating files invariably showed
questionable or overly broad ratings, though. For example, in
such rating files it is common to find blocking entries for
websites that are critic of ICR&amp;amp;S or of this particular rating
service. Also, there are often very vague and general blocking
entries to be found, for example wildcard blocks for anything
that has the letters &amp;ldquo;xxx&amp;rdquo; or &amp;ldquo;sex&amp;rdquo; in an URL [7].&lt;/p&gt;
&lt;p&gt;Even if a content provider is being notfied that some content
has been rated, there is no standard complaints procedure with
which a content provider can go against a rating that he feels
to be inadequate. Also, the whole rating process is
intransparent and inaccessible to revision: there are no
standard provisions that enable any involved party to detect why
false ratings have been created: Was it a true false rating, a
storage problem, a transmission problem, or a misconfiguration?
On the other hand, false filtering can have substantial
financial impact or can be equivalent to libel.&lt;/p&gt;
&lt;h3 id=&#34;first-party-rating-cannot-be-enforced&#34;&gt;
    &lt;a href=&#34;#first-party-rating-cannot-be-enforced&#34;&gt;
	First Party Rating cannot be enforced
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;In the United States, certain First Amendment rights allow a
content provider to not rate own content. Similar rights
exist in other legislations.&lt;/p&gt;
&lt;p&gt;But blocking unrated content unconditionally is open to
unexplored civil damages issues.&lt;/p&gt;
&lt;h3 id=&#34;first-party-rating-does-not-scale-down-the-problem-enough&#34;&gt;
    &lt;a href=&#34;#first-party-rating-does-not-scale-down-the-problem-enough&#34;&gt;
	First Party Rating does not scale down the problem enough
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;First Party Rating is basically a way to scale down the problem
of Third Party Rating by one or two orders of magnitude.&lt;/p&gt;
&lt;p&gt;Third Party Rating cannot keep up with the change of the web
because of the sheer number of pages and because there is no way
for content providers to communicate changes to Third Parties
(see above).&lt;/p&gt;
&lt;p&gt;First Party Rating puts the burden of rating content onto the
content providers themselves which is good because it will
automatically solve the problem of communicating changes. First
Party Ratings must be controlled and validated, though, because
a First Party will rate with a bias to promote own interests.&lt;/p&gt;
&lt;p&gt;Thus, First Party Rating can be viewed as a mechanism to scale
down the rating problem. Instead of n pages of content that have
to be rated, a supervising authority now has the problem of
controlling the correctness of ratings provided by m rating
providers. We can only guess the relation of n:m, but we assume
it to be in the range of approximately 100. m would still be a
multi-million number.&lt;/p&gt;
&lt;h3 id=&#34;labels-need-to-be-tamperproof-and-tamperproof-labels-are-expensive&#34;&gt;
    &lt;a href=&#34;#labels-need-to-be-tamperproof-and-tamperproof-labels-are-expensive&#34;&gt;
	Labels need to be tamperproof and tamperproof labels are expensive
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Labels need to be tamperproof for two reasons. The first is
LabelWasher, an imaginary sister program to WebWasher [8].
While WebWasher, JunkBuster and similar programs filter content
to remove banner ad pages and malicious JavaScript code for
advertisement free surfing, replacing the removed content with
harmless dummy content, LabelWasher would do the same with
content labels. That is, LabelWasher would remove content labels
from incoming content and replace these labels with fake standard
labels which rate this content as harmless.&lt;/p&gt;
&lt;p&gt;The second reason for tamperproof, digitally signed labels is
that the central authority controlling all First Party Raters
has to have an instrument to put pressure on First Parties that
do not rate according to the rating guidelines. The central
authority would revoke the certificate needed to generate
digitally signed labels from such parties, rendering all labels
generated by them invalid.&lt;/p&gt;
&lt;p&gt;Generating and administering a multi-million number of digital
signatures is expensive, even if such signatures are low
security (unfit to sign monetary transactions).
Someone has to provide a database of all certificates
issued, to verify identities of applications so that banned
First Parties cannot apply again for a new certificate, and to
perform all other administrative duties that come with running a
certificate authority. Even if the cost for an individual
certificate can be kept low, the other factor in the equation is
still a multi-million number.a&lt;/p&gt;
&lt;h3 id=&#34;wildcard-labels-cannot-be-checksummed&#34;&gt;
    &lt;a href=&#34;#wildcard-labels-cannot-be-checksummed&#34;&gt;
	Wildcard labels cannot be checksummed
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;A content checksum always applies to a distinct piece of
content. A wildcard label such as &amp;ldquo;all content below
&lt;a href=&#34;http://www.site.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.site.de/&lt;/a&gt;

*&amp;rdquo; applies to an arbitrary number of pages
with arbitrary content below a certain base URL. There is no way
to calculate a checksum on such content, greatly diminishing the
value of a tamperproof label: Without checksums and timestamps,
it is impossible to determine which specific content the
label was applied to.&lt;/p&gt;
&lt;h3 id=&#34;content-rating-cannot-keep-up-with-dynamic-content-creation&#34;&gt;
    &lt;a href=&#34;#content-rating-cannot-keep-up-with-dynamic-content-creation&#34;&gt;
	Content rating cannot keep up with dynamic content creation
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Dynamic content creation just gets faster and is often a
parallel process. Examples for parallel content creation are
discussion forum sites such as Slashdot
(&lt;a href=&#34;http://slashdot.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://slashdot.org&lt;/a&gt;

), news sites such as CNN or Reuters, or
catalogue and bidding systems such as eBay. Examples for fast
content creation are the many live feeds for multimedia data
into the Internet, such as live cameras (&lt;a href=&#34;http://jennicam.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://jennicam.org&lt;/a&gt;

)
and live audio feeds.&lt;/p&gt;
&lt;p&gt;It is impossible for these sites to rate their content, even
with a general rating that applies to the whole site, because
the content on the sites changes much faster than even First
Party Raters can react and because in this case the First Party
sometimes does not even have full control over the content on
their own site.&lt;/p&gt;
&lt;p&gt;On the other hand, exemption from rating for such sites will
quickly generate dysfunctional behaviour and it will also
violate the principle of equal treatment.&lt;/p&gt;
&lt;h3 id=&#34;dynamically-creating-content-labels-is-expensive-in-current-implementations&#34;&gt;
    &lt;a href=&#34;#dynamically-creating-content-labels-is-expensive-in-current-implementations&#34;&gt;
	Dynamically creating content labels is expensive in current implementations
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The Multipurpose Internet Media Enhancements (MIME) standard
goes at great length to allow single pass implementation for
reading and writing content. This is necessary so that dynamic
content generators can read and write multimedia files, which
are often very large, without buffering.&lt;/p&gt;
&lt;p&gt;Current implementations of ICR&amp;amp;S systems ignore this
requirement. They require content labels to be sent /before/ the
actual content within the HTTP header, or to be part of the HTML
document header. If the content label has to include a content
checksum and a digital signature or even if it is just being
generated dynamically, the label can only be generated after the
actual content has been written. Content generation now becomes
a two pass process, in which the content generator first writes
out the actual content, creating the content checksum and the
digital signature, and then begins sending content label and
checksum first, then the actual content.&lt;/p&gt;
&lt;p&gt;Buffer sizes for a busy site can easily become gigantic. For
example, the Slashdot site generates much content dynamically at
request time. A Slashdot page can easily be as large as 200 KB,
depending on the number of discussion entries on such a page.
Assuming ISDN transfer speeds, sending such a page consumes
approximately 25 seconds. Slashdot can easily have 100 to 200
requests per second, or 2500 to 5000 simultaneous connections.
Simple multiplication shows that this will consume between 500
and 1000 MB of buffer space in the form of either RAM or
harddisk bandwith (the problem with disk buffers is often not
space, but read/write capacity). For Slashdot, dynamic content
with digitally signed content labels translates easily into
twice the hardware it has now.&lt;/p&gt;
&lt;p&gt;Streaming media is potentially infinite in length, so
checksumming becomes a much more complicated process because
checksums can only be calculated for chunks of data and must be
embedded into a multimedia stream. This requires that the
multimedia format used anticipates the need for such a feature
or must be redefined (i.e. existing software must be rewritten).
Another problem occurs with compound content in which some
components are optional. Conventional checksums don&amp;rsquo;t work in
this situation.&lt;/p&gt;
&lt;p&gt;Finally, sending Content Labels after the content is not a good
solution performancewise, either: It increases latency on the
client side (that is, the PICS designers put the label before
the content for a reason). When a client downloads content from
the web, it has to decide whether to display the content or not.
The client can only decide this after it has seen the label for
that content. If sending the label is being delayed until after
the actual content has been sent, building the display will
substantially slow down because the client has to hold back
content until it has seen the label for it. Incremental building
of a display, as it is customary in current browsers, is out of
the question in such cases. Besides, it will be frustrating and
expensive for users if their client downloads a large file, only
to decide to throw it away after the download has been completed
due to the label for that content.&lt;/p&gt;
&lt;h3 id=&#34;icrs-systems-may-make-error-diagnosis-more-complicated-and-will-decrease-performance&#34;&gt;
    &lt;a href=&#34;#icrs-systems-may-make-error-diagnosis-more-complicated-and-will-decrease-performance&#34;&gt;
	ICR&amp;amp;S systems may make error diagnosis more complicated and will decrease performance
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;The filtering component of an ICR&amp;amp;S system will most definitely
add more components to an already overly complex platform.
Adding such a filtering component will make debugging more
complicated, even more so if the filtering component is designed
to operate in stealth mode. In such cases it will become very
difficult for support services to determine if a user
encountered a true error or if a filtering component intercepted
a download.&lt;/p&gt;
&lt;p&gt;In the case of third party rating, the label bureau is a single
point of failure: without access to the label bureau, no access
to the network will be granted. The label bureau may also become
a performance bottleneck.&lt;/p&gt;
&lt;p&gt;Design changes at the local platform are necessary to enable
mixed use (filtering and non-filtering) of that platform. For
example, private web caches have to be redesigned. All current
browsers have such caches and they are generally accessible via
the filesystem with typically no access control. As a result, it
is currently possible for somebody to access information
directly in the web cache, which would not be available via a
web browser due to it&amp;rsquo;s content label. Also, to associate
certain access rights with certain users, it is necessary to
identify that user. That is, user authentication (a login prompt)
becomes mandatory on systems where ICR&amp;amp;S is being deployed.&lt;/p&gt;
&lt;h3 id=&#34;false-application&#34;&gt;
    &lt;a href=&#34;#false-application&#34;&gt;
	False application
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Problems exist at the filtering end of an ICR&amp;amp;S system, too. For
example, on systems that see mixed use by minors and adults, it
is highly probable that the adult user will not see indicators
that an ICR&amp;amp;S system is active, and will get only limited access
to web ressources. Alternatively, that person may perhaps see
indicators showing that access is limited but is unable to turn
the filtering system off because the password is not available
to that person, or because the system is to difficult to figure
out for that particular person.&lt;/p&gt;
&lt;p&gt;In many jurisdictions (e.g. in Germany) making use of a
constitutional right so difficult that persons will no longer
make use of this particular right is equivalent to illegally
limiting that right. This implies that the filtering component
of an ICR&amp;amp;S system must clearly signal its presence to the user
and must clearly advertise instructions on how it can be turned
off.&lt;/p&gt;
&lt;p&gt;Also, ICR&amp;amp;S that are difficult to turn off are unlikely to be
accepted by users on systems that see mixed use. Things that
become inconvenient are simply deinstalled.&lt;/p&gt;
&lt;h3 id=&#34;false-positives-destroy-trust-in-icrs-and-in-the-internet&#34;&gt;
    &lt;a href=&#34;#false-positives-destroy-trust-in-icrs-and-in-the-internet&#34;&gt;
	False positives destroy trust in ICR&amp;amp;S and in the Internet
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;For an ICR&amp;amp;S system to be effective and trustworthy, it has to
give access to a large number of pages, and it has to have a
very low number of false positives. That is, it must not block
pages which are essentially harmless due to wildcard labels to
falsely applied labels. This implies that a large number of
ratings must be created, and that these ratings should rather be
too low than too high. It is highly unlikely (at least it seems so
to the author) that any of this will be the case in the current
hysteria and with the current legal situation.&lt;/p&gt;
&lt;p&gt;A high number of false positives will not only create the
impression of an unreliable and untrustworthy ICR&amp;amp;S system, but
it will also undermine trust into the Internet as a reliable
platform for communication of political ideas and social
processes. If ICR&amp;amp;S systems are being publicly perceived
primarily as a tool to leverage political or commerical
interests, their value as a tool for the protection of minors is
gone. This implies that ICR&amp;amp;S systems must have some mechanism
to defend themselves against such an attack.&lt;/p&gt;
&lt;h2 id=&#34;if-we-deploy-now-anyway-what-do-we-get&#34;&gt;
    &lt;a href=&#34;#if-we-deploy-now-anyway-what-do-we-get&#34;&gt;
	If we deploy now anyway, what do we get?
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Summarizing the problems mentioned above inherent to ICR&amp;amp;S in
general, and to current implementations such as PICS compliant
add-ons to browsers, we can say that we cannot safely deploy an
ICR&amp;amp;S systems on a wide scale and get anything remotely
resembling protection of minors. Apart from technical issues,
which are surprisingly hard to solve for a problem that seems
to be trivial when approached first time, there are even more
legal and management issues to solve before ICR&amp;amp;S systems can be
deployed successfully. Most of these problems have not yet been
tackled, some even have been left out deliberately up to now. Even
if all the issues mentioned in this paper had been addressed
by some system, the values of such a system will be
questionable: It certainly is possible to deploy ICR&amp;amp;S systems
which filter /something/ for /some/ people, but it highly
unlikely that these systems will be effective, that is, that
they filter /most things/ /correctly/ for /most people/.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;[1]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.msen.com/~weinberg/rating.htm&#34;&gt;&lt;a href=&#34;http://www.msen.com/~weinberg/rating.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.msen.com/~weinberg/rating.htm&lt;/a&gt;

&lt;/a&gt;, &amp;ldquo;Rating the
Internet&amp;rdquo;:
&lt;p&gt;&amp;lsquo;Jonathan Wallace, thus, in an article called &amp;ldquo;Why I Will
Not Rate My Site&amp;rdquo; asks how he is to rate &amp;ldquo;An Auschwitz
Alphabet&amp;rdquo;, his powerful and deeply chilling work of
reportage on the Holocaust. The work contains descriptions
of violence done to camp inmates&amp;rsquo; sexual organs. A
self-rating system, Wallace fears, would likely force him to
choose between the unsatisfactory alternatives of labeling
his work as suitable for all ages, on the one hand, or
&amp;ldquo;lump[ing it] together with the Hot Nude Woman page&amp;rdquo; on the
other. It seems to me that at least some of the rating
services problems&amp;rsquo; in assigning ratings to individual
documents are inherent. It is the nature of the process that
no ratings can classify documents in a perfectly
satisfactory manner, and this theoretical inadequacy has
important real-world consequences.&amp;rsquo;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[2]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.dcia.com/cyberbur.html&#34;&gt;&lt;a href=&#34;http://www.dcia.com/cyberbur.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.dcia.com/cyberbur.html&lt;/a&gt;

&lt;/a&gt;, &amp;ldquo;Fahrenheit 451.2: Is
Cyberspace Burning?&amp;rdquo;:
&lt;p&gt;&amp;lsquo;Kiyoshi Kuromiya, founder and sole operator of Critical
Path Aids Project, has a web site that includes safer sex
information written in street language with explicit
diagrams, in order to reach the widest possible audience.
Kuromiya doesn&amp;rsquo;t want to apply the rating &amp;ldquo;crude&amp;rdquo; or
&amp;ldquo;explicit&amp;rdquo; to his speech, but if he doesn&amp;rsquo;t, his site will
be blocked as an unrated site. If he does rate, his speech
will be lumped in with &amp;ldquo;pornography&amp;rdquo; and blocked from view.
Under either choice, Kuromiya has been effectively blocked
from reaching a large portion of his intended audience ­
teenage Internet users ­ as well as adults. [ &amp;hellip; ] Kuromiya
could distribute the same material in print form on any
street corner or in any bookstore without worrying about
having to rate it. In fact, a number of Supreme Court cases
have established that the First Amendment does not allow
government to compel speakers to say something they don&amp;rsquo;t
want to say - and that includes pejorative ratings.&amp;rsquo;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[3] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.mit.edu/activities/safe/labelling/0198f1.html&#34;&gt;&lt;a href=&#34;http://www.mit.edu/activities/safe/labelling/0198f1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.mit.edu/activities/safe/labelling/0198f1.html&lt;/a&gt;

&lt;/a&gt;
where Lars Kongshem quotes a case where the program
CYBERsitter suppresses the word &amp;ldquo;homosexual&amp;rdquo; on a screen
display. Thus, the sentence &amp;ldquo;The Catholic church is opposed
to all homosexual marriages.&amp;rdquo; is shown as &amp;ldquo;The Catholic
church is opposed to all marriages.&amp;rdquo; on screen.&lt;/dd&gt;
&lt;dt&gt;[4] :&lt;/dt&gt;
&lt;dd&gt;Documentation for the Apache Web Server, mod_negotation
Module, &lt;a href=&#34;http://www.apache.org/manual/mod_negotation.html&#34;&gt;&lt;a href=&#34;http://www.apache.org/manual/mod_negotation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.apache.org/manual/mod_negotation.html&lt;/a&gt;

&lt;/a&gt;,
mod_mime Module, &lt;a href=&#34;http://www.apache.org/manual/mod_mime.html&#34;&gt;&lt;a href=&#34;http://www.apache.org/manual/mod_mime.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.apache.org/manual/mod_mime.html&lt;/a&gt;

&lt;/a&gt;.
&lt;p&gt;Both modules enable the server to deliver different static
pages for the same URL, depending on other information that
is part of the browsers request and that is /not/ part of
the URL. It is the URL though, which ties a thrid party
rating to a specific page.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[5] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.neci.nj.nec.com/homepages/lawrence/websize.html&#34;&gt;&lt;a href=&#34;http://www.neci.nj.nec.com/homepages/lawrence/websize.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.neci.nj.nec.com/homepages/lawrence/websize.html&lt;/a&gt;

&lt;/a&gt;
&lt;p&gt;&amp;ldquo;An estimated lower bound on the size of the indexable Web
is 320 million pages.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;The coverage of the major Web search engines investigated varies
by an order of magnitude (variation will differ for different queries, e.g.
more popular queries).&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;The major Web search engines index only a fraction of the
total number of documents on the Web. No engines indexes
more than about one third of the &amp;ldquo;publicly indexable Web&amp;rdquo;.&amp;rdquo;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[6] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://cgi.pathfinder.com/netly/spoofcentral/censored/index.html&#34;&gt;&lt;a href=&#34;http://cgi.pathfinder.com/netly/spoofcentral/censored/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://cgi.pathfinder.com/netly/spoofcentral/censored/index.html&lt;/a&gt;

&lt;/a&gt;
The Censorware Search Engine was helpful to check blacklists
in commercial products which do not expose their blocking
criteria. Seth Finkelstein reported this URL as being
&amp;ldquo;gone and never coming back. The person who ran it
lost the trust of almost everyone who does censorware-analysis work.&amp;rdquo;.
Some vendors provide similar services on their
websites, e.g. &lt;a href=&#34;http://www.cyberpatrol.com/cybernot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.cyberpatrol.com/cybernot/&lt;/a&gt;

 for
CyberPatrol.&lt;/dd&gt;
&lt;dt&gt;[7] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://catless.ncl.ac.uk/Risks/18.07.html#subj3&#34;&gt;&lt;a href=&#34;http://catless.ncl.ac.uk/Risks/18.07.html#subj3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://catless.ncl.ac.uk/Risks/18.07.html#subj3&lt;/a&gt;

&lt;/a&gt;, Clive
Feather reported comp.risks digest 18.07 of 17-Apr-1996 that
AOL blocks the name of the small british town &amp;ldquo;Scunthorpe&amp;rdquo;,
forcing inhabitants of that town to register as being from
&amp;ldquo;Sconthorpe&amp;rdquo;
&lt;p&gt;&lt;a href=&#34;http://www.liii.com/~just4fun/news/article1.htm&#34;&gt;&lt;a href=&#34;http://www.liii.com/~just4fun/news/article1.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.liii.com/~just4fun/news/article1.htm&lt;/a&gt;

&lt;/a&gt; reports
an incident where material of writer Anne Sexton is being
blocked, because her name matches the string &amp;ldquo;sex&amp;rdquo;.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[8] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.siemens.de/servers/wwash/wwash_us.htm&#34;&gt;&lt;a href=&#34;http://www.siemens.de/servers/wwash/wwash_us.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.siemens.de/servers/wwash/wwash_us.htm&lt;/a&gt;

&lt;/a&gt;
&lt;p&gt;&amp;ldquo;WebWasher® is a browser add-on that accelerates the
navigation on the Web. The software runs on PCs or
servers. [It r]emoves advertising on Web pages
while you surf, Filters pop-up windows, animated
images, referer.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.anonymizer.com/&#34;&gt;&lt;a href=&#34;http://www.anonymizer.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.anonymizer.com/&lt;/a&gt;

&lt;/a&gt; offers services like&lt;/p&gt;
  &lt;ul&gt;
  &lt;li&gt;
  Anonymizer URL Encryption - Beta: Extra Protection for the
  connection between your computer and our servers
  &lt;li&gt;Anonymizer Window Washer by Webroot: Preserve your privacy &amp;
  hide your tracks! Cleans your browser history and more...
  &lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;[9] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://censorware.org/reports/&#34;&gt;&lt;a href=&#34;http://censorware.org/reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://censorware.org/reports/&lt;/a&gt;

&lt;/a&gt;
and &lt;a href=&#34;http://www.peacefire.org/&#34;&gt;&lt;a href=&#34;http://www.peacefire.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.peacefire.org/&lt;/a&gt;

&lt;/a&gt;
contain a lot of information on conduct of Rating Services
and Label Bureaus in general.&lt;/dd&gt;
&lt;dt&gt;[10]:&lt;/dt&gt;
&lt;dd&gt;A. A. Pitman, Scientific and Technological Options
Assessment (STOA): &amp;ldquo;Feasibility of censoring and jamming
pornography and racism in informatics, Draft Final Report,
PE 166 658, Luxemburg, May 1997.
&lt;p&gt;Some parts quoted in
&lt;a href=&#34;http://www.inet-one.com/cypherpunks/dir.97.08.28-97.09.03/msg00149.html&#34;&gt;&lt;a href=&#34;http://www.inet-one.com/cypherpunks/dir.97.08.28-97.09.03/msg00149.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.inet-one.com/cypherpunks/dir.97.08.28-97.09.03/msg00149.html&lt;/a&gt;

&lt;/a&gt;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[11] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.research.att.com/projects/tech4kids/&#34;&gt;&lt;a href=&#34;http://www.research.att.com/projects/tech4kids/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.research.att.com/projects/tech4kids/&lt;/a&gt;

&lt;/a&gt;
&lt;p&gt;Lorrie Faith Cranor, Paul Resnick, Danielle Gallo:
&amp;ldquo;Technology Inventory: A Catalog of Tools that Support Parents&amp;rsquo;
Ability to Choose Online Content Appropriate for their Children&amp;rdquo;,
December 1997, revised September 1998&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[12] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.usembassy-china.gov/english/sandt/Inetcawb.htm&#34;&gt;&lt;a href=&#34;http://www.usembassy-china.gov/english/sandt/Inetcawb.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.usembassy-china.gov/english/sandt/Inetcawb.htm&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Political Security: A Closed or an Open Internet - The Great
Red Firewall of China&amp;rdquo;, Brian Ristuccia, 31-Jul-1998:&lt;/dd&gt;
&lt;dt&gt;[13] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.freshmeat.net/appindex/1998/07/31/901899756.html&#34;&gt;&lt;a href=&#34;http://www.freshmeat.net/appindex/1998/07/31/901899756.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.freshmeat.net/appindex/1998/07/31/901899756.html&lt;/a&gt;

&lt;/a&gt;
&lt;p&gt;&amp;ldquo;Anti-Filtering-Proxy-Proxy: httpd-afpp is designed to
defeat the site-blocking fuctionality of censorware and
filtering-proxies. The user first visits a site running the
Anti-Filtering-Proxy-Proxy. Assuming this site is not
blocked by the local filtering-proxy or censorware, the
user is then free to browse any other web sites free of
filtering-proxy or censorware restrictions.&amp;rdquo;,&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[14] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.noie.gov.au/reports/blocking.html&#34;&gt;&lt;a href=&#34;http://www.noie.gov.au/reports/blocking.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.noie.gov.au/reports/blocking.html&lt;/a&gt;

&lt;/a&gt;
&lt;p&gt;Philip McCrea, Bob Smart, Mark Andrews: Blocking Content on
the Internet: a Technical Perspective; Australia, June
1998,&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[15] :&lt;/dt&gt;
&lt;dd&gt;Gerry Miller, Gerri Sinclair, David Sutherland, Julie
Zilber: Regulation of the Internet - A Technological
Perspective; Canada, March 1999&lt;/dd&gt;
&lt;dt&gt;[16] :&lt;/dt&gt;
&lt;dd&gt;Technical Framework and Background:&lt;br&gt;
&lt;br&gt;
&lt;a href=&#34;http://w3c.org/PICS&#34;&gt;&lt;a href=&#34;http://w3c.org/PICS/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://w3c.org/PICS/&lt;/a&gt;

&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://w3c.org/RDF/&#34;&gt;&lt;a href=&#34;http://w3c.org/RDF/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://w3c.org/RDF/&lt;/a&gt;

&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://w3c.org/DSig/&#34;&gt;&lt;a href=&#34;http://w3c.org/DSig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://w3c.org/DSig/&lt;/a&gt;

&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://w3c.org/P3P/&#34;&gt;&lt;a href=&#34;http://w3c.org/P3P/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://w3c.org/P3P/&lt;/a&gt;

&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://mephisto.inf.tu-dresden.de/RESEARCH/ssonet/ssonet_eng.html&#34;&gt;&lt;a href=&#34;http://mephisto.inf.tu-dresden.de/RESEARCH/ssonet/ssonet_eng.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://mephisto.inf.tu-dresden.de/RESEARCH/ssonet/ssonet_eng.html&lt;/a&gt;

&lt;/a&gt;&lt;/dd&gt;
&lt;dt&gt;[17] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.iid.de/iukdg/carnegie_e.html&#34;&gt;&lt;a href=&#34;http://www.iid.de/iukdg/carnegie_e.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.iid.de/iukdg/carnegie_e.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Misuse of International Data Networks&amp;rdquo;
&lt;p&gt;Report submitted by the  Expert Group to G8 Ministers and
Chief Advisors of Science and Technology (Carnegie Group)&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[18] :&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www2.echo.lu/legal/en/internet/communic.html&#34;&gt;&lt;a href=&#34;http://www2.echo.lu/legal/en/internet/communic.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www2.echo.lu/legal/en/internet/communic.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Illegal and harmful content on the Internet&amp;rdquo;
&lt;p&gt;&lt;a href=&#34;http://www2.echo.lu/legal/en/internet/wp2en.html&#34;&gt;&lt;a href=&#34;http://www2.echo.lu/legal/en/internet/wp2en.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www2.echo.lu/legal/en/internet/wp2en.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Illegal and harmful content on the Internet
Interim report on Initiatives in EU Member States with
respect to Combating&amp;rdquo;, Version 7, (June 4, 1997)
&lt;a href=&#34;http://www2.echo.lu/legal/de/internet/resolde.html&#34;&gt;&lt;a href=&#34;http://www2.echo.lu/legal/de/internet/resolde.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www2.echo.lu/legal/de/internet/resolde.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;ENTSCHLIESSUNG DES RATES ZU ILLEGALEN UND SCHÄDLICHEN
INHALTEN IM INTERNET&amp;rdquo;&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;[19]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.securitysearch.net/search/papers/bsaprobs.htm&#34;&gt;&lt;a href=&#34;http://www.securitysearch.net/search/papers/bsaprobs.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.securitysearch.net/search/papers/bsaprobs.htm&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Key Legal and Technical Problems with the Broadcasting
Services Amendment (Online Services) Bill 1999&amp;rdquo; (Australia)
&lt;a href=&#34;http://www.gtlaw.com.au/pubs/newdarkage.html&#34;&gt;&lt;a href=&#34;http://www.gtlaw.com.au/pubs/newdarkage.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.gtlaw.com.au/pubs/newdarkage.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Censorship and Amendments to the Broadcasting Services
Act&amp;rdquo; (Australia, April 1999)&lt;/dd&gt;
&lt;dt&gt;[20]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.aclu.org/issues/cyber/burning.html&#34;&gt;&lt;a href=&#34;http://www.aclu.org/issues/cyber/burning.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.aclu.org/issues/cyber/burning.html&lt;/a&gt;

&lt;/a&gt;
&amp;ldquo;Fahrenheit 451.2: Is Cyberspace Burning?  How Rating and
Blocking Proposals May Torch Free Speech on the Internet&amp;rdquo;&lt;/dd&gt;
&lt;dt&gt;[21]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.internetwatch.org.uk/&#34;&gt;&lt;a href=&#34;http://www.internetwatch.org.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.internetwatch.org.uk/&lt;/a&gt;

&lt;/a&gt; &amp;ldquo;The Internet Watch
Foundation (IWF) was launched in late September 1996o
address the problem of illegal material on the Internet,
with particular reference to child pornography.&amp;rdquo;&lt;/dd&gt;
&lt;dt&gt;[22]:&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&#34;http://www.koehntopp.de/kris/artikel/blocking/index.en.html&#34;&gt;&lt;a href=&#34;http://www.koehntopp.de/kris/artikel/blocking/index.en.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.koehntopp.de/kris/artikel/blocking/index.en.html&lt;/a&gt;

&lt;/a&gt;
Kristian Köhntopp, Marit Köhntopp, Martin Seeger: &amp;ldquo;Blocking
of Material on the Internet: Questions and Answers - A systematic
analysis of the &amp;ldquo;censorship debate&amp;rdquo;; Kiel, Germany, May 1997
&lt;p&gt;The article discusses non-PICS methods of blocking content
and why they do create even more harm than PICS. It serves
as an introduction to this article.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
</description>
    </item>
    
    <item>
      <title>Sperrungen im Internet - Eine systematische Aufarbeitung der Zensurdiskussion</title>
      <link>https://blog.koehntopp.info/1997/05/14/sperrungen-im-internet.html</link>
      <pubDate>Wed, 14 May 1997 16:15:56 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/1997/05/14/sperrungen-im-internet.html</guid>
      <description>&lt;h1 id=&#34;zusammenfassung&#34;&gt;
    &lt;a href=&#34;#zusammenfassung&#34;&gt;
	Zusammenfassung
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Wie alle anderen Medien wird auch das Internet zur Verbreitung von beispielsweise rechtsradikalen oder kinderpornographischen Informationen mißbraucht. Dies hat in letzter Zeit den Ruf nach einem staatlichen Eingriff laut werden lassen, um zentrale Sperrungen bestimmter Inhalte zu erreichen.&lt;/p&gt;
&lt;p&gt;Die Autoren halten einen solchen Schritt fuer nicht angemessen. Zum einen haben bisher alle technischen Ansätze zur Realisierung versagt. Strukturelle überlegungen lassen vermuten, daß dies auch in Zukunft der Fall sein wird. Auf der anderen Seite haben Sperren stets Auswirkungen auch auf Bereiche, deren Sperrung nicht beabsichtigt ist. Diese Nebenwirkungen sind um so schwerwiegender, je wirksamer die Sperren sein sollen.&lt;/p&gt;
&lt;p&gt;Dezentrale Lösungsansaetze können dem Nutzer die Möglichkeit geben, im eigenen Bereich selbstverantwortlich Inhalte zu filtern. Bewertungen von Inhalten durch nichtstaatliche Organisationen können dazu führen, daß der Bewertungsmechanismus zur Durchsetzung fragwürdiger Interessen mißbraucht wird. Um diesem Risiko entgegenzuwirken, ist es unverzichtbar, daß nicht nur die Bewertungsmaßstäbe, sondern auch die Bewertungen selbst vollständig offengelegt werden.&lt;/p&gt;
&lt;p&gt;Jede Art von staatlicher Regulierung treibt die Kosten in die Höhe. Es ist abzusehen, daß der Versuch, Inhalte im Internet zu bewerten, sehr personalintensiv sein wird. Bereits heute sind die Kommunikationskosten am Standort Deutschland wesentlich höher als bei konkurrierenden Nationen wie den USA. Regulierungen können daher zu einem Standortnachteil führen.&lt;/p&gt;
&lt;h1 id=&#34;was-soll-mit-einer-sperrung-erreicht-werden&#34;&gt;
    &lt;a href=&#34;#was-soll-mit-einer-sperrung-erreicht-werden&#34;&gt;
	Was soll mit einer Sperrung erreicht werden?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Bevor man über technische Maßnahmen zur Sperrung von Inhalten im Internet und die Chancen ihrer Realisierung reden kann, muß man sich darüber klar werden, welche Ziele man mit einer solchen Sperrung erreichen möchte.&lt;/p&gt;
&lt;p&gt;Mögliche Ziele sind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Law Enforcement:&lt;/strong&gt; Man möchte verhindern, daß nach den Kriterien einer nationalen oder regionalen Rechtsordnung strafrechtlich relevantes Material für die Subjekte dieser Rechtsordnung erreichbar ist bzw. von ihnen veröffentlicht werden kann, und zwar auch dann, wenn der Ort der Veröffentlichung außerhalb des Durchsetzungsbereiches dieser Rechtsordnung liegt. Traumziel wäre es, das Begehen solcher Straftaten technisch unmöglich zu machen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indecency:&lt;/strong&gt; In den USA wurde mit dem &lt;em&gt;communication decency act&lt;/em&gt; (&lt;em&gt;CDA&lt;/em&gt;) in seinen verschiedenen Formulierungen und Gesetzesvorlagen versucht, eine noch weitergehende Regelung zu etablieren: Es sollte verboten werden, Material über Datennetze zugänglich zu machen, das &lt;em&gt;indecent&lt;/em&gt; ist, d.h. nach den Grundsätzen der jeweils herrschenden Moraldefinition ungehörig, obszön oder in anderer Weise störend (zu Free Speech siehe z.B. &lt;a href=&#34;http://www.eff.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Electronic Frontier Foundation&lt;/a&gt;

 EFF).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jugendschutz:&lt;/strong&gt; Nur Minderjährigen (Kindern und Jugendlichen) soll der Zugang zu bestimmten Materialien verwehrt werden, während Volljährigen weiterhin die gesamten Inhalte des Internet zugänglich bleiben sollen.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rating:&lt;/strong&gt; Für jeden Teilnehmer im Netz soll weiterhin frei definierbar sein, welches Material empfangen/nicht empfangen werden soll, aber es soll eine Bewertungsstruktur geschaffen werden, die es jedem Konsumenten in  eigener Verantwortung ermöglicht, seine Präferenzen anzugeben (kein Sex/viel Sex, keine Gewalt/Blood and Splatter, politisch links/politisch rechts, konform mit den Vorstellungen der katholischen Kirche/islamisch korrekt) und nur noch den Ausschnitt aus dem Internet wahrzunehmen, der diesen selbstgewählten Filter passieren kann.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nichtregulation:&lt;/strong&gt; Jeder Netzteilnehmer soll freien Zugriff auf alle angebotene Information haben. Sogar die Existenz von Bewertungskriterien Dritter wird als schädlich angesehen und die Bildung einer Bewertungsinfrastruktur nicht gefördert bzw. sogar behindert.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;welche-dienste-werden-betrachtet&#34;&gt;
    &lt;a href=&#34;#welche-dienste-werden-betrachtet&#34;&gt;
	Welche Dienste werden betrachtet?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Unter der Bezeichnung &lt;em&gt;Inhalte im Internet&lt;/em&gt; wird in der Regel eine ganze Reihe von Diensten subsumiert, die technisch vollkommen unterschiedlich realisiert werden und administrativ zu großen Teilen disjunkte Strukturen aufweisen. Allen Diensten ist lediglich gemeinsam, dass ihnen das Datenübertragungsprotokoll TCP/IP zugrunde liegt.&lt;/p&gt;
&lt;p&gt;Man muß mindestens die beiden folgenden Dienste unterscheiden:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WWW, World Wide Web:&lt;/strong&gt; Das World Wide Web ist der graphisch ansprechendste Dienst des Internet. Es handelt sich um Server, die auf die Anfrage eines Benutzers Seiten beliebigen Inhaltes an das Darstellungsprogramm (&lt;em&gt;Browser&lt;/em&gt;) auf seinem Rechner ausliefern. Der Zugriff auf diese Seiten erfolgt in der Regel mit Hilfe des HyperText Transport Protocol (&lt;em&gt;HTTP&lt;/em&gt;). Dieses Protokoll erfordert keine Identifizierung oder Authentisierung des Abrufers und des Anbieters; die Daten werden im Klartext und nicht fälschungssicher übermittelt.&lt;/p&gt;
&lt;p&gt;Eine optional einsetzbare Modifikation von HTTP übermittelt
Anfragen und Antworten mit Hilfe des Verschlüsselungsverfahrens &lt;em&gt;Secure Socket Layer&lt;/em&gt; (&lt;em&gt;SSL&lt;/em&gt;). Bei diesem Verfahren muß sich mindestens der Anbieter gegenüber dem Abrufer identifizieren. Weiterhin ist sichergestellt, daß die Verbindung nicht im Klartext abhörbar ist (Dritten wird nicht bekannt, welche Anfragen gestellt wurden oder welche Inhalte die ausgelieferten Seiten haben) und daß Inhalte nicht durch Dritte während der übertragung unerkannt verfälscht werden können.&lt;/p&gt;
&lt;p&gt;Die abgerufenen Seiten bestehen aus Formatierungsanweisungen der &lt;em&gt;HyperText Markup Language&lt;/em&gt; (&lt;em&gt;HTML&lt;/em&gt;) und optional weiteren Bild-, Ton- oder Videodaten. Bei kleineren Servern liegen die abrufbaren Seiten häufig statisch als vorgefertigte und unverändert ausgelieferte Dateien auf der Festplatte vor.&lt;/p&gt;
&lt;p&gt;Größere Server erzeugen die Seiten jedoch oftmals dynamisch in Abhängigkeit von der Identität des Abrufers, seiner Netzadresse, seiner bevorzugten Landessprache (im Browser konfigurierbar), dem vom Abrufer verwendeten Browsertyp, der Uhrzeit des Abrufs oder anderen Kriterien, die frei progammierbar sind. Es ist also nicht sichergestellt, daß zwei aufeinanderfolgende Abfragen derselben Seite identische Antworten ergeben.&lt;/p&gt;
&lt;p&gt;Falls die Seiten aus einer Datenbank dynamisch erzeugt werden, kann sich der Datenbestand des Webservers durch die Updates der Datenbank ständig aendern. Dies ist zum Beispiel der Fall bei Katalogsystemen fuer Onlinehandel (Preis- und Produktupdates, Änderungen im Lagerbestand mit Auswirkungen auf die Lieferbarkeit usw.), bei Nachrichtenagenturen mit Anschluß an Presse- und Tickerdienste und bei Webverzeichnissen und Suchmaschinen, die einen Volltextindex für Seiten generieren und eine Recherche nach Inhalten erlauben.&lt;/p&gt;
&lt;p&gt;Grundsätzlich ist der Datenbestand im Web als höchst dynamisch anzusehen: Neue Versionen von Seiten lassen sich zu sehr geringen Kosten erzeugen und in Verkehr bringen. Der elektronische Charakter des Mediums im Zusammenhang mit der zentralen Datenhaltung (es sind keine verteilten Kopien einer Seite auf Stand zu bringen) begünstigen weiterhin eine sehr hohe Auflagenfrequenz.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;USENET News:&lt;/strong&gt; Das USENET ist ein verteiltes System vom Diskussionsforen (&lt;em&gt;Newsgroups&lt;/em&gt;). Es handelt sich um ein teilweise zusammenhängendes Netz von Servern, von denen jeder eine Auswahl von Artikeln zum Abruf bereithält. Die Artikel sind in der Regel in thematisch gegliederten Diskussionsforen in der Reihenfolge des Eingangs abgelegt. Leser können eine Verbindung zum netztopologisch am günstigsten gelegenen Server aufbauen und Artikel nach Diskussionsforen und Eingangsdatum selektiert abrufen.&lt;/p&gt;
&lt;p&gt;Leser können grundsätzlich auf jeden gelesenen Artikel
antworten (&lt;em&gt;to follow up on an article&lt;/em&gt;) oder unabhängig
eigene Artikel auf dem Server ablegen (&lt;em&gt;posten&lt;/em&gt;, von engl. &lt;em&gt;to post a notice&lt;/em&gt;). Der Server wird dann seine Nachbarserver darüber informieren, daß er einen neuen Artikel vorrätig hat, und den Artikel ggf. an seine Nachbarserver replizieren (&lt;em&gt;to feed an article to a neighboring system&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Diese verbreiten den Artikel dann wieder an ihre Nachbarn usw. (&lt;em&gt;flood fill algorithm of USENET&lt;/em&gt;). Nach einigen Stunden existieren Hunderttausende von Kopien dieses Artikels auf der gesamten Welt. Die Vernetzung der Server ist hochredundant; Unterbrechungen in Serverstrecken haben in der Regel keine oder nur lokal meßbare Auswirkungen auf Verfügbarkeit oder Transportgeschwindigkeit der Artikel.&lt;/p&gt;
&lt;p&gt;Um Platz zu gewinnen, werden die jeweils ältesten Artikel nach einiger Zeit gelöscht. Die genaue Zeitspanne bis zur Löschung hängt von der  individuellen Konfiguration des Servers und seiner Platzsituation ab, liegt aber in der Regel nicht über 14 Tagen. Es existieren jedoch auch einige Newsarchive, die Diskussionen über mehrere Jahre hinweg abspeichern und diesen Datenbestand durch weitgehende Recherchemöglichkeiten erschliessen (z.B.  &lt;a href=&#34;http://www.dejanews.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DejaNews&lt;/a&gt;

, &lt;a href=&#34;http://www.altavista.digital.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AltaVista&lt;/a&gt;

 im Newsmodus).&lt;/p&gt;
&lt;p&gt;Dadurch, daß jeder Leser auf beliebige Artikel direkt und ohne redaktionelle Bearbeitung antworten kann, entspinnen sich in der Regel unmoderierte, öffentliche Diskussionen zu allen möglichen Themen. Ein Großteil der Diskussionsforen wird global ausgetauscht. Daher ist die Zusammensetzung der Diskussionsrunden zufällig und international.&lt;/p&gt;
&lt;p&gt;Die Kommunikation zwischen Leser und Server sowie die Kommunikation zwischen den Servern erfolgt in der Regel unverschlüsselt und ohne Identifizierung und Authentisierung der Leser oder der Autoren von Artikeln. Die Fälschung von Absenderadresse oder Herkunftspfad eines Artikels ist trivial und in einigen Diskussionsforen sogar üblich. Es existieren Konverter von E-Mail nach USENET News und Anonymous- sowie Pseudonymous-Server, die zum Teil mit kryptographisch starken Methoden die Identität des Absenders sowie seinen Aufenthaltsort im Netz zu verschleiern suchen. Einige Newsserver lassen Lese- und Schreibzugriff von jedermann und ohne Authentisierung zu (&lt;em&gt;open servers&lt;/em&gt;); es ist Sache des Veröffentlichenden, seine Identität in einem Artikel offenzulegen oder nicht.&lt;/p&gt;
&lt;p&gt;Die Entscheidung über die von einem Server angebotenen Diskussionsforen obliegt in der Regel jedem einzelnen Serverbetreiber. Teilweise existieren Kataloge von offiziellen Newsgroups, diese sind jedoch in der Regel weder vollständig noch für irgendwen verbindlich. Name oder überschrift einer Newsgroup haben nur den Charakter von Empfehlungen. Thematisch falsch eingeordnete Artikel (&lt;em&gt;off topic postings&lt;/em&gt;) oder bewußt massenhaft in alle Newsgroups verbreitete Artikel (&lt;em&gt;spam&lt;/em&gt;) machen einen festen Anteil aller Artikel aus.&lt;/p&gt;
&lt;p&gt;Die Dienste &lt;strong&gt;IRC&lt;/strong&gt; (&lt;strong&gt;Internet Relay Chat&lt;/strong&gt;) und &lt;em&gt;E-Mail&lt;/em&gt; (Private elektronische Post sowie halböffentliche Mailinglists als Diskussionsforen) wären ebenfalls zu betrachten, sollen hier aber im Interesse einer kompakten Darstellung nicht diskutiert werden, da sie weniger im Rampenlicht der öffentlichen Diskussion stehen. Die genannten Argumente gelten aber in ähnlicher Form auch dort. Es existieren weitere Dienste, die fuer die öffentliche Kommunikation in der Regel von geringerer Bedeutung sind (&lt;em&gt;telnet&lt;/em&gt;) oder deren Diskussion keine neuen Aspekte zu Tage foerdern wuerde (&lt;em&gt;ftp&lt;/em&gt;, siehe &lt;em&gt;http&lt;/em&gt;).&lt;/p&gt;
&lt;h1 id=&#34;wie-koennen-zu-sperrende-inhalte-identifiziert-werden&#34;&gt;
    &lt;a href=&#34;#wie-koennen-zu-sperrende-inhalte-identifiziert-werden&#34;&gt;
	Wie koennen zu sperrende Inhalte identifiziert werden?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Um Inhalte zuverlässig sperren zu können, ist es notwendig, diese Inhalte in irgendeiner Form zu identifizieren. Diese Identifizierung kann von unterschiedlicher Auflösung sein.&lt;/p&gt;
&lt;p&gt;Auf der Basis von IP-Adressen kann ein einzelner Rechner identifiziert werden. Ein solcher Rechner erbringt jedoch in der Regel eine Vielzahl von Diensten für mehrere unterschiedliche Anbieter. Webserver von IP-Providern bringen unter einer IP-Adresse teilweise die Angebote von Tausenden Inhaltsanbietern ins Netz, Rechner von Kleinprovidern bieten teilweise alle Dienste des Providers unter einer IP-Nummer an. Eine Sperrung von IP-Nummern trifft also außer den zu sperrenden Inhalten meist auch eine große Menge von Inhalten und Diensten, deren Sperrung nicht beabsichtigt ist.&lt;/p&gt;
&lt;p&gt;Mit entsprechendem Mehraufwand können dienstspezifische Kennzeichen von einzelnen Einheiten des Angebotes identifiziert werden. Im World Wide Web ist dies der Name einer Seite (ihr &lt;em&gt;Universal Resource Locator&lt;/em&gt;, &lt;em&gt;URL&lt;/em&gt;), in den USENET News erfolgt die Identifizierung über die Message-ID einer einzelnen Nachricht oder den Namen einer Newsgroup. Für neu entstehende Dienste müssen dienstspezifische Methoden zur Identifikation einzelner Einheiten neu gefunden werden.&lt;/p&gt;
&lt;p&gt;Die zu bewertenden Datenmengen sind riesig: Die Suchmaschine &lt;a href=&#34;http://www.altavista.digital.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Altavista&lt;/a&gt;

 hatte im Mai
1996 schon 30 Millionen Webseiten in ihrer Volltextdatenbank
gespeichert; im April 1997 betrug das Newsaufkommen mehr als 72
Gigabyte für etwa 5,4 Millionen Artikel (Statistik von Eunet
Deutschland GmbH aus &lt;a href=&#34;news:de.admin.lists&#34;&gt;de.admin.lists&lt;/a&gt;

 vom 01.05.97).&lt;/p&gt;
&lt;p&gt;Es bleibt das Problem, zu sperrende Inhalte aus der Menge aller Inhalte zu isolieren. Hier gibt es nur zwei grundsätzlich verschiedene Systeme:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Die automatische Bewertung von Inhalten auf der Basis formaler Merkmale wie etwa dem Vorhandensein bestimmter Schlüsselworte.&lt;/li&gt;
&lt;li&gt;Die manuelle Bewertung von Inhalten durch den Anbieter oder Dritte nach bestimmten Kriterienkatalogen (&lt;em&gt;rating&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Verfahren zur automatischen Bewertung von Inhalten aufgrund von Schlüsselworten scheitern bei Komponenten, die keinen Text enthalten (Audiodateien, Bilder oder Animationen) schon im Ansatz.&lt;/p&gt;
&lt;p&gt;Einige Online-Dienste (Prodigy, AOL) haben versucht, Diskussionen in dem IRC-Dienst ähnlichen Chaträumen aufgrund des Gebrauchs bestimmter Schlüsselworte bewerten zu lassen; die Ergebnisse waren wenig befriedigend. Einerseits waren normale Diskussionen über bestimmte Themen nicht mehr möglich:&lt;/p&gt;
&lt;p&gt;Eine Sperrung des Wortes &lt;em&gt;suck&lt;/em&gt; erschwerte den Meinungsaustausch zu Staubsaugern in einem Haushaltsforum, eine Sperrung des Wortes &lt;em&gt;breast&lt;/em&gt; behinderte Diskussionen über Brustkrebs oder Kochrezepte (Hühnerbrust), und die Webseiten von Frau Cindy Tittle Moore (&lt;a href=&#34;mailto:tittle@netcom.com&#34;&gt;tittle@netcom.com&lt;/a&gt;

) wurden durch das Programm Cybersitter wegen ihres Namens gesperrt.&lt;/p&gt;
&lt;p&gt;Andererseits veränderte die eigentliche Zielgruppe einfach ihr Vokabular, so daß die Sperrung auf diese Zielgruppe keine nennenswerte Auswirkung hatte. Auch andere automatisierbare Bewertungsmethoden vermögen nicht die Semantik der Inhalte zu erkennen. Wer solche formalen Sperrkriterien kennt, kann leicht die Darstellung seiner Informationen je nach Bedarf an diese Kriterien anpassen, ohne die inhaltliche Aussage zu verändern.&lt;/p&gt;
&lt;p&gt;Das Kindersicherungsprogramm Cybersitter ist beispielsweise in der
Lage, als offensive eingestufte Worte aus Webseiten
herauszuschneiden. Durch geschickte Formulierung sind so Aussagen in ihr Gegenteil verkehrbar, wenn sie unter Cybersitter betrachtet werden (Nachricht von Bennett Haselton auf der Mailingliste
&lt;a href=&#34;mailto:fight-censorship@vorlon.mit.edu&#34;&gt;fight-censorship@vorlon.mit.edu&lt;/a&gt;

, Message-ID: &lt;a href=&#34;mailto:01IAZF6R8I0I8XKGCV@ctrvax.Vanderbilt.Edu&#34;&gt;01IAZF6R8I0I8XKGCV@ctrvax.Vanderbilt.Edu&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Verfahren und Standards zur Bewertung von Inhalten durch den Anbieter oder Dritte liegen für den Bereich des World Wide Web bereits vor, das System &lt;a href=&#34;http://www.w3.org/pub/WWW/PICS/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PICS&lt;/a&gt;

 (Platform for Internet Content Selection) ist dabei zur Zeit führend. PICS erlaubt die Installation frei definierbarer Bewertungsmaßstäbe mit einer beliebig feinen Auflösung.&lt;/p&gt;
&lt;p&gt;Bewertungen von URLs koennen von den Anbietern selbst oder durch Dritte erfolgen. Gängige Bewertungsmaßstäbe sind dabei etwa Gewalt, Sex oder unanständige Sprache, die Abstufungen reichen von digitalen 0-1-Skalen bis zu sehr fein abgestuften Systemen. Die Auswertung von PICS-Einstufungen kann entweder im Clientprogramm des Anwenders erfolgen (dies wird zur Zeit vom Microsoft Internet Explorer unterstützt) oder auf Routern auf dem Weg zum Empfänger (dies geschieht zur Zeit nicht).&lt;/p&gt;
&lt;p&gt;Das Hauptproblem bei der manuellen Bewertung von Inhalten ist die große Menge der anfallenden neuen oder veränderten Seiten. Der Betreiber des Nachrichtenservers &lt;a href=&#34;http://www.msnbc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.msnbc.com&lt;/a&gt;

 (Joint-Venture von NBC und Microsoft) hat die Bewertung seiner Beiträge auf der Basis des von Microsoft geförderten Bewertungsschemas RSACi für PICS eingestellt, da die Bewertung einzelner Beiträge zu aufwendig war und eine Pauschalbewertung des Servers nach den Regeln von PICS den Server fuer Minderjährige unzugänglich gemacht haette (Briefwechsel zwischen Irene Graham, Michael Sims, Stephen Balkam (RSAC Ratingaufsicht) und Danielle Bachelder (MSNBC Systembetrieb), zitiert in &lt;a href=&#34;mailto:3339dd1a.500215@mail.thehub.com.au&#34;&gt;3339dd1a.500215@mail.thehub.com.au&lt;/a&gt;

 und &lt;a href=&#34;mailto:199703191314.IAA03203@arutam.inch.com&#34;&gt;199703191314.IAA03203@arutam.inch.com&lt;/a&gt;

 auf derselben
Mailingliste).&lt;/p&gt;
&lt;p&gt;Hinzu kommt, dass die Webseite abhängig vom Kontext des Abrufes  unterschiedlich aussehen kann, so daß eine Bewertung nach dem PICS-System problematisch wäre. Gerade diejenigen Seiten, die die interaktive Komponente des Internet ausnutzen, könnten so wegen ihrer dynamischen Generierung aus der Bewertung herausfallen und würden damit in entsprechend konfigurierten Browsern und Suchmaschinen nicht mehr dargestellt.&lt;/p&gt;
&lt;p&gt;Die Bewertung von Angeboten erfolgt im Rahmen von PICS derzeit durch private Organisationen. Die Möglichkeiten des Widerspruchs gegen eine bestimmte Einstufung sind dabei begrenzt. Insbesondere ist es für einen Bürger schwierig, ein korrektes Rating einzufordern, wenn die Ratingorganisation in einem fremden Land sitzt. Im Prinzip liegt hier dasselbe Problem vor, das sich zur Zeit bei der Strafverfolgung ausländischer illegaler Angebote stellt, nur daß die Ressourcen und Beweislasten nun andersherum verteilt sind:&lt;/p&gt;
&lt;p&gt;Ein Anbieter muß nun bei falscher Einstufung beweisen, dass sein Angebot legal ist, und er muß dazu den schwierigen Weg der Durchsetzung von Ansprüchen im Ausland gehen. Im Vergleich zu einer Staatsanwaltschaft ist ein Anbieter von Webseiten dafür im Durchschnitt schlechter ausgebildet,  und ihm stehen weniger Ressourcen zur Verfügung.&lt;/p&gt;
&lt;p&gt;Weiterhin orientieren sich die Ratingorganisationen an Werten und kulturellen Maßstäben ihrer Nation. Die übernahme ausländischer Bewertungen für deutsche Benutzer ist daher problematisch. Da jedoch keine deutsche Zugriffssoftware existiert, werden meist nur ausländische (speziell US-amerikanische) Ratingsysteme unterstützt.&lt;/p&gt;
&lt;p&gt;Die meisten Ratingorganisationen dokumentieren ihre Ratings nicht oder nur sehr ungern. Zum Teil erfolgt noch nicht einmal eine Benachrichtigung des Bewerteten über die Bewertung seines Angebotes. Vollständige Verzeichnisse aller vergebenen Ratings werden meist mit der Begründung unter Verschluss gehalten, daß diese Verzeichnisse als Kataloge fuer Schmutz und Schund mißbraucht werden könnten. Bei den Programmen, die die Bewertungen von Webseiten Dritter nicht online beziehen, sondern als Datei auf der lokalen Festplatte installiert haben, ist diese Liste grundsätzlich verschlüsselt - und meistens auch veraltet. Auch gegenüber dem Benutzer solcher Software ist damit nicht offengelegt, welche Angebote ihm nicht mehr zugänglich sind.&lt;/p&gt;
&lt;p&gt;Inzwischen existieren (illegal) entschlüsselte Versionen der Sperrlisten aller Hersteller von Programmen mit statischer, in Dateien gelieferter Sperrliste. Die Auswertung der Sperrungen hat bei allen Herstellern eine klare politische Agenda und persönliche Feindschaften dokumentiert.&lt;/p&gt;
&lt;p&gt;Beispielsweise wurden vielfach Angebote von &lt;em&gt;womens organizations&lt;/em&gt;, Informationsangebote über Abtreibung und Angebote schwuler und lesbischer Gruppen zensiert. Es ist weiterhin üblich, Webseiten in die Sperrlisten aufzunehmen, die den Hersteller des Sperrprogramms kritisieren, die Sperrliste offenlegen oder allgemein gegen Rating argumentieren. Beim Hersteller des Programms Cybersitter geht dies so weit, daß bei installiertem Cybersitter alle Seiten nicht mehr abrufbar sind, in denen die Namen von Kritikern seines Programms erwähnt werden.&lt;/p&gt;
&lt;h1 id=&#34;mit-welchen-mitteln-kann-eine-sperrung-erreicht-werden&#34;&gt;
    &lt;a href=&#34;#mit-welchen-mitteln-kann-eine-sperrung-erreicht-werden&#34;&gt;
	Mit welchen Mitteln kann eine Sperrung erreicht werden?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Sperrungen können auf unterschiedlichen Ebenen der Kommunikation ansetzen:&lt;/p&gt;
&lt;p&gt;Um erfolgreich zu kommunizieren, müssen beide Kommunikationspartner eine physikalische Verbindung zueinander aufbauen. Dies kann eine Standleitung, eine Telefonleitung, eine Richtfunkstrecke oder eine andere Kommunikationsform sein. Eine normalerweise nicht praktikable Möglichkeit der Sperrung besteht darin, diese physikalische Kommunikation zu verhindern, indem man etwa einen Telefonanschluss sperrt oder bestimmte Telefonnummern nicht erreichbar schaltet, Standleitungen unterbricht oder Störsender in Richtfunkstrecken einbringt. Das Opfer der Sperrung verliert damit in der Regel alle seine Kommunikationsmöglichkeiten.&lt;/p&gt;
&lt;p&gt;Im Internet wird meist keine homogene physikalische Verbindung verwendet, sondern diese Verbindung wird aus Teilstücken unterschiedlicher Technologie zusammengestückelt. An den übergangspunkten zwischen den Teilstücken befindet sich ein Router, der IP-Pakete von einem Teilstück zum nächsten hinueberhievt.&lt;/p&gt;
&lt;p&gt;Die Funktionalität des Routers wird dabei von den Adressen in den einzelnen IP-Paketen und seinen Routingtabellen gesteuert. In den Routingtabellen ist eingetragen, in welche Richtung der Router Pakete mit einer gegebenen Zieladresse weiterzuleiten hat. Die klassische Dienstleistung eines Providers besteht darin, einen übergang zwischen einer Wählverbindung (Privatkunden) oder einer regionalen Standleitung (Firmenkunden) und einer oder mehreren Standleitungen in das Ausland zu bieten. Dem Provider ist dabei nicht bekannt, welche Dienste der Kunde in Anspruch nimmt oder welche Daten abgerufen werden.&lt;/p&gt;
&lt;p&gt;Sperrungen können hier über Eingriffe in die Routingtabellen von Routern vorgenommen werden. Es ist beispielsweise leicht möglich, alle Pakete an bestimmte Zieladressen am Router verwerfen zu lassen (eine Route zu &lt;em&gt;erden&lt;/em&gt;). Mit diesem Verfahren werden ganze Rechner unerreichbar: Bei der durch den DFN-Verein praktizierten Sperrung des Rechners mit dem Namen &lt;a href=&#34;http://www.xs4all.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.xs4all.com&lt;/a&gt;

 waren auf diese Weise die Webseiten von mehr als 6000 Anbietern nicht mehr abrufbar, es konnte keine Mail auf der Maschine &lt;a href=&#34;https://www.xs4all.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.xs4all.com&lt;/a&gt;

 eingeliefert werden, und auch alle andere Kommunikation des DFN-Vereins mit dieser Maschine wurde unterbunden.&lt;/p&gt;
&lt;p&gt;Die Auswahl eines Dienstes erfolgt im TCP/IP-Protokoll in der Regel durch die Angabe einer TCP-Portnummer. Mit Hilfe dieser Portnummer könnte eine selektivere Sperrung eines Dienstes erfolgen. Beispielsweise sind einige Router in der Lage, nach entsprechender Konfiguration TCP-Verkehr fuer den Port 80 (HTTP) zu einer Zieladresse zu sperren, Verkehr auf Port 25 (Mail) zu derselben Adresse aber zu gestatten.&lt;/p&gt;
&lt;p&gt;Mit Hilfe eines Vermittlungsrechners (&lt;em&gt;proxy&lt;/em&gt;) oder anderer Firewallsoftware, denen die im Netzmodell höher liegenden Ebenen zugänglich sind, kann eine selektive Sperrung auf der Ebene von Dienstelementen (einzelnen Seiten, einzelnen Nachrichten) erreicht werden. Die Firewallsoftware muß herbei jedoch fuer jeden Dienst (WWW, News, Mail, IRC etc.) angepaßt werden.&lt;/p&gt;
&lt;p&gt;Solche Systeme sind in der Regel sehr aufwendig im Betrieb, da sie für die nutzenden Clients die volle Leistung aller durch den Client in Anspruch genommenen Dienste simulieren müssen. Mit steigender Zahl von Clients skalieren sich diese Systeme ausgesprochen schlecht. Trotzdem setzen einige totalitäre Staaten auf dieses System, um das Eindringen mißliebiger Inhalte in das Land zu erschweren: In China, Singapur und in den Golfstaaten läuft sämtliche Kommunikation mit dem Ausland durch staatlich betriebene Firewalls.&lt;/p&gt;
&lt;p&gt;Sperrung von IP-Adressen und der Einsatz von Firewalls ist unter bestimmten Voraussetzungen kombinierbar, dadurch ist eine Entlastung der  Firewallmaschine möglich: Anstatt die Route zu einer zu sperrenden Maschine zu erden, läßt man alle Routen zur zu sperrenden Maschine auf einen Firewall zeigen, der dann die Dienste der zu sperrenden Maschine überwacht.&lt;/p&gt;
&lt;p&gt;Diese Lösung ist je nach Art der zu sperrenden und zu simulierenden Dienste sehr aufwendig zu konfigurieren und zu warten. Zum einen setzt sie einen zentralen übergangspunkt zwischen dem zu kontrollierenden deutschen Netz und dem Rest der Welt voraus. Zum anderen handelt es sich bei diesem Verfahren um einen klassischen &lt;em&gt;Man in the middle&lt;/em&gt; Angriff. Dadurch versagt das Verfahren bei aller stark verschlüsselten Kommunikation, die  unempfindlich gegen solche Angriffe ist.&lt;/p&gt;
&lt;p&gt;Grundsätzlich sind die Auswirkungen von Filtermechanismen auf die Systemleistung um so höher, je feiner die Granularität der Sperrungen ist und je größer die Liste der zu sperrenden Informationsquellen ist. Systeme wie PICS lassen sich nicht effizient an zentralen Stellen im Netz etablieren, sondern können nur dezentral funktionieren. Alle bisher diskutierten Verfahren der Sperrung setzen auf dritten Maschinen zwischen dem Anbieter der zu sperrenden Information und dem Abrufer an. Denkbar wäre auch eine Sperrung beim Anbieter der Information sowie eine Sperrung beim Abrufer. Dies setzt jedoch eine Kooperation des Anbieters bzw. Abrufers voraus.&lt;/p&gt;
&lt;p&gt;Eine Sperrung beim Anbieter würde bedeuten, daß der Anbieter die zu sperrenden Inhalte entweder niemandem anbietet oder daß er sie nur bestimmten Personen nicht anbietet. Ein personenselektives Anbieten von Inhalten setzt selbst bei Kooperation des Anbieters voraus, daß der Anbieter den Abrufer einer Information zweifelsfrei identifizieren kann und daß ihm genaue und juristisch hieb- und stichfeste Entscheidungstabellen vorgelegt werden, die es ihm erlauben, automatisch zu entscheiden, wem er welche Inhalte ausliefern darf.&lt;/p&gt;
&lt;p&gt;Ein Identifikationsmechanismus, der das Geforderte leistet, existiert derzeit nicht einmal im Ansatz und ist auch nicht in absehbarer Zeit realisierbar. Insbesondere kann nicht aus der IP-Adresse oder dem Rechnernamen eines Absenders auf seine Identität oder seinen physikalischen Aufenthalt geschlossen werden: Deutsche Kunden von amerikanischen Online-Diensten erscheinen im Netz als aus den Vereinigten Staaten kommend. Ähnliches gilt für Mitarbeiter multinationaler Konzerne.&lt;/p&gt;
&lt;p&gt;Eine Sperrung beim Abrufer würde bedeuten, daß die angebotenen Inhalte nach bestimmten Bewertungskriterien ausgezeichnet sind (&lt;em&gt;rating&lt;/em&gt;, z.B. nach PICS) und daß der Abrufer selbst seine Software so konfiguriert, daß Seiten mit bestimmten Ratings nicht mehr abgerufen werden können. Eine Kooperation des Anbieters wäre hier wünschenswert, ist aber nicht notwendig, da die Bewertungen auch von Servern Dritter geliefert werden können.&lt;/p&gt;
&lt;h1 id=&#34;auf-welche-weise-koennen-sperrungen-unterlaufen-werden&#34;&gt;
    &lt;a href=&#34;#auf-welche-weise-koennen-sperrungen-unterlaufen-werden&#34;&gt;
	Auf welche Weise koennen Sperrungen unterlaufen werden?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Für den Nutzer stellt sich eine Sperrung von Inhalten als Betriebsstörung dar. Er wird nach Wegen suchen, die ordnungsgemäße Funktion des Netzes wiederherzustellen, d.h. die Sperrung zu unterlaufen. Diese Motivation ist um so größer, je stärker sich der Benutzer durch die Sperrung behindert fühlt.&lt;/p&gt;
&lt;p&gt;Bei einer Sperrung der physikalischen Kommunikation ist dies nur durch einen Wechsel des Mediums möglich: Wenn etwa ein Störsender in Betrieb genommen wird, wird man versuchen, auf das Telefonnetz auszuweichen und umgekehrt.&lt;/p&gt;
&lt;p&gt;Bei einer Sperrung von bestimmten IP-Adressen stehen dem Benutzer mehrere Möglichkeiten offen, die Störung zu umgehen. Alle laufen darauf hinaus, den sperrenden Router vollständig zu umgehen (siehe auch &lt;a href=&#34;http://www.fitug.de/ulf/zensur/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ulf Moeller&lt;/a&gt;

, Internet-Zensur:
Routingsperren umgehen):&lt;/p&gt;
&lt;p&gt;Der Benutzer wechselt den Internet-Anbieter, notfalls wird er Kunde bei einem ausländischen Provider. Er baut eine Telefonverbindung oder Standleitung zu diesem Provider auf und wickelt seine Kommunikation über diesen nichtsperrenden Provider ab. Der sperrende Router des lokalen Providers wird nicht mehr verwendet, die Sperre ist wirkungslos.&lt;/p&gt;
&lt;p&gt;Diese Situation tritt automatisch ein, wenn der Nutzer Mitarbeiter eines (multinationalen) Konzerns mit einem eigenen Konzernverbundnetz ist, das an mehreren Stellen (im Ausland) mit dem Internet verbunden ist.&lt;/p&gt;
&lt;p&gt;Der Benutzer wird Kunde bei einem zweiten, nichtsperrenden Internet-Anbieter, notfalls im Ausland. Er baut eine TCP/IP-Verbindung zu diesem Provider auf und läßt seine Anwendungen auf dem entfernten Rechner, ggf. im Ausland, ablaufen.&lt;/p&gt;
&lt;p&gt;Es gibt inzwischen eine Reihe von Providern, die solche Angebote
routinemäßig anbieten. Die Palette reicht dabei von der
Bereitstellung einzelner Dienste (Postboxen fuer E-Mail (z.B. &lt;a href=&#34;http://www.pobox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pobox.com&lt;/a&gt;

), Webservices (z.B. &lt;a href=&#34;http://www.geocities.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;geocities.com&lt;/a&gt;

) usw.) bis zu kompletten Exil-Logins (z.B. &lt;a href=&#34;http://www.c2.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;c2.org&lt;/a&gt;

, &lt;a href=&#34;http://www.acm.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;acm.org&lt;/a&gt;

, &lt;a href=&#34;http://www.xs4all.nl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xs4all.nl&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Der sperrende Router des lokalen Providers sieht keine Kommunikation mit einer gesperrten Adresse, sondern nur Kommunikation mit dem entfernten Provider. Die Zugriffe auf die gesperrten Adressen erfolgen von dort, also erst hinter dem sperrenden Router. Die Sperre durch den Router wird wirkungslos.&lt;/p&gt;
&lt;p&gt;Der Benutzer wird Kunde bei einem zweiten, nichtsperrenden Internet-Anbieter, notfalls im Ausland. Er baut eine Mobile-IP-Verbindung zu diesem Provider auf, d.h. seine IP-Pakete werden in anderen IP-Paketen verpackt zum zweiten Internet-Anbieter geschickt, dort ausgepackt und eingespielt. Optional kann die Kommunikation zum zweiten Provider verschlüsselt erfolgen.&lt;/p&gt;
&lt;p&gt;In Linux müssen dazu die folgenden beiden Kommandos gegeben
werden:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Aktivierung des Interface &lt;code&gt;tunl0&lt;/code&gt; zum entfernten
Anbieter &lt;code&gt;myriad.ml.org&lt;/code&gt;: `ifconfig tunl0 (your.ip.address) pointopoint
myriad.ml.org&lt;/li&gt;
&lt;li&gt;Legen einer Route zu &lt;code&gt;www.xs4all.nl&lt;/code&gt; über &lt;code&gt;tunl0&lt;/code&gt; &lt;code&gt;route add www.xs4all.nl tunl0&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Für einen Beobachter erscheint der Nutzer als normaler Kunde des zweiten IP-Providers. Der sperrende Router des lokalen Providers sieht nur eine Verbindung zum entfernten zweiten Provider. Die Sperre ist wirkungslos. Mobile-IP ist ein Routineangebot fuer IP-Provider, die Geschäftskunden betreuen.&lt;/p&gt;
&lt;p&gt;Der Anbieter der gesperrten Information kann Abrufer unterstützen, indem er ebenfalls versucht, die Sperre zu unterlaufen. Im Falle der Sperrung des Rechners &lt;code&gt;www.xs4all.nl&lt;/code&gt; hat der gesperrte Anbieter die Internet-Adresse seines Rechners alle paar Minuten verändert. Sperrungen einer einzelnen Adresse wurden dadurch wirkungslos, statt dessen mußten ganze Teilnetze gesperrt werden (die Sperrung wurde noch unspezifischer, es wurden als Nebenwirkung noch mehr unbeteiligte Anbieter mitgesperrt).&lt;/p&gt;
&lt;p&gt;Während die bisher diskutierten Möglichkeiten des Unterlaufens von Sperrungen unabhängig vom gesperrten Dienst waren, sind die folgenden Moeglichkeiten dienstspezifisch:&lt;/p&gt;
&lt;h2 id=&#34;www&#34;&gt;
    &lt;a href=&#34;#www&#34;&gt;
	WWW
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Ähnlich der erwähnten Veränderung der IP-Nummer eines Serverrechners kann  auch die Adresse eines Angebotes auf einem Server automatisch verändert werden. Eine automatische Sperrung einzelner Angebote würde dadurch unterlaufen werden, und man müßte wieder den gesamten Rechner pauschal sperren. Dort greifen dann wieder die Methoden zum Unterlaufen einer Komplettsperrung.&lt;/p&gt;
&lt;p&gt;Wenn zu einem Angebot eine Suchmaschine existiert, mit der alle Seiten eines Angebotes nach bestimmten Begriffen durchsucht werden können, ist eine einzelne Seite praktisch unter beliebig vielen Adressen zu bekommen (nämlich allen Begriffen, die den Text in der Suchmaschine finden). Eine Sperrung müßte hier zusätzlich den Zugriff auf die Suchmaschine verhindern.&lt;/p&gt;
&lt;p&gt;Das Verfahren des indirekten Zugriffs, wie es unter Mobile-IP diskutiert wurde, läßt sich mit Veränderungen auch für WWW einsetzen: Mit Hilfe eines entfernten Webservers, der Zugriffe im Auftrag Dritter abwickelt (&lt;em&gt;Proxy-Server&lt;/em&gt;), ist ein indirekter Abruf der Seite möglich. Da Proxy-Server mit Zwischenspeicher zur Beschleunigung von Zugriffen üblich sind, ist es in der Regel kein Problem, einen solchen dritten Server zu finden. Im Rahmen der Zensurdiskussion der letzten Monate sind mittlerweile im In- und Ausland auch schon Proxy-Server für solche Umgehungen explizit eingerichtet worden (etwa am MIT fuer chinesische Staatsbürger, die die Zensur im eigenen Land unterlaufen möchten).&lt;/p&gt;
&lt;p&gt;Bei verschlüsselter Kommunikation (etwa mit dem in allen gängigen Browsern eingebauten SSL-Support) entsteht ein nicht mehr in Echtzeit einsehbarer und nicht einfach verfälschbarer Kanal zwischen Server und Client. Für Dritte ist nicht erkennbar, welche Seiten abgerufen werden und welche Informationen sie enthalten.&lt;/p&gt;
&lt;h2 id=&#34;news&#34;&gt;
    &lt;a href=&#34;#news&#34;&gt;
	News
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Artikel in den USENET News liegen in zahlreichen Kopien auf Tausenden von Servern überall auf der Welt vor. Löschungen (&lt;em&gt;Cancel&lt;/em&gt;) werden von vielen dieser Server nicht mehr ausgeführt, nachdem es seit einigen Jahren immer wieder zu gefälschten Löschaufforderungen von Saboteuren kam. Die großen Archive fuer USENET News (DejaNews und AltaVista) führen grundsätzlich keine Löschungen aus. Über Archivanfragen ist es daher in der Regel möglich, auch auf ältere und lokal nicht mehr verfügbare Texte zuzugreifen. Dabei gilt wie bei Suchmaschinen für Webseiten (siehe oben): Artikel sind nicht nur unter einer festen Bezeichnung abrufbar, sondern werden auch zu beliebigen im Artikel enthaltenen Stichworten gefunden.&lt;/p&gt;
&lt;p&gt;Im Rahmen einer Untersuchung der bayrischen Staatsanwaltschaft wurde der Betreiber Compuserve aufgefordert, einige Newsgroups grundsätzlich nicht mehr bereitzustellen, da bei ihnen davon auszugehen sei, dass diese in Deutschland strafrechtlich relevante Inhalte enthielten. Die Leser dieser Gruppen beziehen diese jetzt direkt von anderen, nicht gesperrten Newsservern. Ausserdem gehen die Autoren von Artikeln für solche schlecht verbreiteten Newsgroups immer mehr dazu über, ihre Artikel zusätzlich in andere, thematisch unpassende, aber besser verbreitete Gruppen zu setzen.&lt;/p&gt;
&lt;p&gt;So kam es zum Beispiel anläßlich der Sperrung des Servers &lt;code&gt;www.xs4all.nl&lt;/code&gt; wegen des Angebotes der verbotenen Zeitschrift Radikal, Ausgabe 154 zweimal zu je einem Posting der Komplettausgabe der Radikal in den Diskussionsforen de.soc.zensur (Diskussion über Zensur und Inhaltskontrolle) und
de.org.politik.spd (Forum des virtuellen Ortsverbandes der SPD).&lt;/p&gt;
&lt;p&gt;Da die Neueinrichtung von Newsgroups technisch automatisiert werden kann, kommt es vielfach zur Neueinrichtung schlecht verbreiteter Gruppen unter neuem Namen oder zum Angebot bekannter Gruppen unter Aliasnamen. So wurde die Gruppe de.talk.sex (Diskussionsforum über Sexualität) an einer deutschen Universität mehrere Jahre lang unter dem Namen de.soc.verkehr geführt, nachdem dort entschieden worden war, keine Gruppen mehr anzubieten, deren Bezeichnung den Begriff sex enthält.&lt;/p&gt;
&lt;h1 id=&#34;andere-effekte-von-sperrungsversuchen&#34;&gt;
    &lt;a href=&#34;#andere-effekte-von-sperrungsversuchen&#34;&gt;
	Andere Effekte von Sperrungsversuchen
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Jede Sperre kann unterlaufen werden, indem die gesperrte Information vielfach repliziert wird. Dann ist jedes Vorkommen dieser Information gesondert zu sperren. Dadurch werden die unangenehmen Nebenwirkungen der Sperrung vervielfacht, bis die Kosten fuer die Sperrung ihren Nutzen übersteigen. Im Falle der Sperrung von &lt;a href=&#34;https://www.xs4all.nl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.xs4all.nl&lt;/a&gt;

 wegen des Angebotes der verbotenen Radikal 154 existierten innerhalb kürzester Zeit über 40 Kopien der gesperrten Information. Die 6000 aus technischen Gründen mitgesperrten Anbieter wurden jedoch nicht repliziert. Bezüglich der angestrebten Wirkung wurde also eher das Gegenteil erreicht, während viele Anbieter durch die unbeabsichtigten Nebenwirkungen Verluste hinnehmen mußten.&lt;/p&gt;
&lt;p&gt;Mit Hilfe der USENET News ist diese Replikation tausendfach automatisiert und mit minimalem Aufwand vorzunehmen. Aus diesem Grunde kam es nach der Sperrung von xs4all auch zu einer Verbreitung der Webseiten der Radikal in den News (die Webseiten der anderen 6000 Kunden von xs4all wurden nicht in die News eingespielt).&lt;/p&gt;
&lt;p&gt;Alle Kommunikation mit Hilfe des TCP/IP-Protokolls ist konstruktionsbedingt eine individuelle Ende-zu-Ende-Kommunikation zwischen zwei Partnern. Selbst bei Betrachtung des Dienstes ist nicht erkennbar, ob die abgerufenen Informationen privater Natur sind (es ist möglich und für viele Anwender auch notwendig, ihre persönliche Post per WWW zu lesen) oder ob es sich um öffentliche Information handelt. Derartige Information kann sogar gemischt auf einer Webseite auftreten. Es ist zweifelhaft, inwieweit eine Kontrolle solcher Verbindungen durch unspezifisches Abhören (ohne richterlichen Beschluß) gestattet ist, selbst wenn dieses Abhören durch einen Roboter geschieht, der auf Schlüsselworte oder Ratings reagiert.&lt;/p&gt;
&lt;p&gt;Nicht nur vom Standpunkt der Kontrolle der Bewerter, sondern auch vom Standpunkt des technischen Netzbetriebes ist eine Offenlegung aller Sperrungen unbedingt notwendig. Wenn Sperrungen von Rechnern oder einzelnen Angeboten massenhaft umgesetzt werden, ist für den einzelnen Systembetreiber genau wie für den einzelnen Anwender nämlich nicht mehr entscheidbar, ob eine technische Störung vorliegt, die zu beheben ist, oder ob eine inhaltlich begründete Sperrung vorgenommen wurde. Damit wird einer zuverlässigen Fehleranalyse durch die Betreiber von Netzen oder einzelnen Maschinen jede Grundlage entzogen, da aus dem Vorliegen einer Störung keine sichere Verhaltensvorschrift zu ihrer Behebung abgeleitet werden kann. Andererseits können offengelegte Sperrlisten natuerlich leicht als Kataloge fuer sexuell explizite oder gewalttätige Angebote mißbraucht werden. Eine Sperrung wäre dann eine Art Qualitaetssiegel. Offengelegte Sperrungen sind mit entsprechend modifizierten Programmen außerdem automatisiert umgehbar.&lt;/p&gt;
&lt;h1 id=&#34;modifikation-des-internet&#34;&gt;
    &lt;a href=&#34;#modifikation-des-internet&#34;&gt;
	Modifikation des Internet
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In dem heutigen Internet können Sperren nach den obigen Ausführungen also nicht oder nur mit unvertretbar hohen Kosten und Nebenwirkungen realisiert werden. Daraus ergibt sich die Frage, inwieweit das Internet modifiziert werden müßte, um effizientes Sperren von Inhalten zu erlauben.&lt;/p&gt;
&lt;p&gt;Prinzipiell bieten Firewallsysteme (die von Unternehmen eingesetzt werden, um ihr Netz gegen unbefugtes Eindringen aus dem Internet zu schützen) einen Ansatz, effektive Sperren aufzubauen. Durch die Philosophie, nur solchen Daten das Passieren der Barriere zu gestatten, denen es explizit gestattet wurde, erzwingt man das Einhalten von Richtlinien.&lt;/p&gt;
&lt;p&gt;Ähnliche Richtlinien müßten fuer die Nutzung der Internet-Dienste durch die Benutzer aufgestellt und ihre Einhaltung erzwungen werden. Dies kann durch die Verwendung der Firewalltechnologie als Barriere zwischen den Anwendern und dem Internet oder durch die Verwendung proprietärer Protokolle erzwungen werden. Entscheidend ist, daß Teilnehmer im Netz ausschließlich identifizierbar agieren koennen, daß nur freigegebene Dienste, Protokolle und Datenformate verwendet werden, daß die Verwendung kryptographischer Verfahren verboten wird und daß sämtliche Aktivitäten protokolliert werden. Durch diese Massnahmen soll sichergestellt werden, daß der Benutzer einer Sperre nicht mehr ausweichen kann durch Wechsel der Identität, des Protokolls oder durch Verschleierung der Daten.&lt;/p&gt;
&lt;p&gt;Unabhängig von der Frage, ob ein solches Verfahren mit einem demokratischen Rechtsstaat vereinbar wäre, gibt es auch wirtschaftliche und technische Gründe, die dagegen sprechen: Ein solches Netz wäre zentralistisch gesteuert und könnte nur unter großem Zeit- und Kostenaufwand an veränderte Anforderungen angepaßt werden. Sämtliche Online-Dienste haben dieses Modell auf Druck ihrer kommerziellen Benutzer aufgegeben. Der administrative Overhead einer solchen Lösung auf nationaler Ebene wäre gewaltig. Ausserdem wuerde jede Beschraenkung kryptographischer Verfahren eine Nutzung des Internet zur Übermittlung sensitiver Informationen beeinträchtigen.&lt;/p&gt;
&lt;p&gt;Insgesamt könnte ein solches Modell katastrophale Standortnachteile mit sich bringen. Kommunikation ist eine Ressource, die in ihrer Bedeutung den Arbeitskräften oder der Verkehrsinfrastruktur in keiner Weise nachsteht. Auf der anderen Seite kann man, wie sich am Beispiel China zeigen läßt, selbst auf diese Art die Verbreitung unerwünschter Inhalte nur begrenzt unterbinden, denn für jede der oben genannten Massnahmen existieren wiederum Gegenmaßnahmen.&lt;/p&gt;
&lt;h1 id=&#34;bewertung&#34;&gt;
    &lt;a href=&#34;#bewertung&#34;&gt;
	Bewertung
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Eine zentrale Sperre von Inhalten im Internet läßt sich technisch nicht paßgenau vornehmen, ließe sich von den Benutzern bei Bedarf umgehen und wäre mit hohen Kosten verbunden (siehe auch Heimo Ponnath: &lt;a href=&#34;http://bda.netuse.de/bda/jp/home/heimo.ponnath/articles/SiN.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pornographie im Internet&lt;/a&gt;

? Dichtung und Wahrheit, inside online 2/3 1996). Bedingt durch die globalen Datennetze zeigt sich hier der Paradigmenwechsel in den Aufgaben des Staates durch die Informationsgesellschaft, wie Alexander Rossnagel beschreibt (Alexander Rossnagel: Globale Datennetze: Ohnmacht des Staates - Selbstschutz der Buerger, ZRP 1997, Heft 1, 26-30). Die Ohnmachtserfahrung des Staates in der globalisierten Welt bedeutet jedoch nicht gleichzeitig eine Kapitulation vor den neuen Gefahren, sondern die modernen Informationstechnologien bergen vielfältige Möglichkeiten, daß der Bürger sich selbst schützen kann. Daraus erwächst die Verpflichtung für den Staat, Strukturen zu schaffen, die seine Bürger befähigen, ihre Interessen in der Welt der Netze selbstbestimmt zu schützen.&lt;/p&gt;
&lt;p&gt;Hier bietet also die dezentrale Kontrolle und Filterung durch den Benutzer einen Lösungsansatz. Dazu müssen jedoch die Bewertungen durch Dritte (etwa nach dem PICS-System) transparent und nachvollziehbar sein. Beispielhafte Filterkonfigurationen können von einer Vielzahl von Interessengruppen vorgeschlagen werden; der Benutzer muß jedoch die Möglichkeit haben, seine eigene Konfiguration individuell vorzunehmen oder anzupassen.&lt;/p&gt;
&lt;p&gt;Ein universelles Rating wie PICS ist mit erhöhtem Zeitaufwand und zusätzlichen Kosten verbunden. Eine Reihe von Anbietern wird daher darauf verzichten. Den Ratingorganisationen kommt ein hohes Maß an Verantwortung zu, da jede Vorbewertung bereits zur Meinungsbildung der potentiellen Abrufer beiträgt und da absichtliche oder unabsichtliche Fehlbewertungen großen Schaden anrichten können. Geht es lediglich um die Gewährleistung eines Jugendschutzes im Internet, wäre es sehr viel billiger und unkritischer, wenn die Anbieter auf freiwilliger Basis ihre kindgerechten Materialien kennzeichneten und spezielle Kinderbrowser ähnlich dem TV-Kinderkanal nur solche Angebote darstellten (siehe &lt;a href=&#34;http://www.thehub.com/~orene/liberty/label.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;he Net Labelling Delusion: Protection or Oppression&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Die Erfahrungen in den USA zeigen, daß Organisationen das Instrument der Bewertung von Inhalten für die Durchsetzung ihrer eigenen politischen Ziele unter dem Deckmantel des Jugendschutzes oder der Aufrechterhaltung der öffentlichen Moral mißbrauchen. Es ist zu verhindern, daß die Definition moralischer und gesellschaftlicher Werte in den Aufgabenbereich privater Organisationen übertragen wird. Durch eine Offenlegung der Bewertungsmaßstäbe und aller Bewertungen kann diese Gefahr des Mißbrauchs reduziert werden.&lt;/p&gt;
&lt;h1 id=&#34;danksagung&#34;&gt;
    &lt;a href=&#34;#danksagung&#34;&gt;
	Danksagung
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Wir danken Hannes Federrath und Andreas Pfitzmann von der Technischen Universitaet Dresden für zahlreiche Anregungen und Diskussionen, die zur Entstehung dieses Textes beigetragen haben.&lt;/p&gt;
&lt;h1 id=&#34;die-autoren&#34;&gt;
    &lt;a href=&#34;#die-autoren&#34;&gt;
	Die Autoren
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;mailto:kris@koehntopp.de&#34;&gt;Kristian Köhntopp&lt;/a&gt; ist Diplominformatiker und arbeitet als freiberuflicher Consultant fuer heterogene Datennetze und Rechnersicherheit.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto:marit@koehntopp.de&#34;&gt;Marit Köhntopp&lt;/a&gt; ist Diplominformatikerin und arbeitet beim Landesbeauftragten für den Datenschutz Schleswig-Holstein als Referentin in den Bereichen &amp;ldquo;Neue Medien und Informationstechnologien&amp;rdquo; sowie &amp;ldquo;Technikfolgenabschätzung&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto:ms@netuse.de&#34;&gt;Martin Seeger&lt;/a&gt; ist Diplominformatiker und Geschäftsführer der &lt;a href=&#34;http://www.netuse.de&#34;&gt;NetUSE ommunikationstechnologie GmbH&lt;/a&gt;. Das Unternehmen beschäftigt sich mit der Internet-/Intranet-Technologie und der Sicherheit von Rechnern in Netzen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

