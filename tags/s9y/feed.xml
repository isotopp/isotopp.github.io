<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>s9y on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/s9y.html</link>
    <description>Recent content in s9y on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 16 Jan 2022 08:24:03 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/s9y/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Statifizierung für S9Y - eine Blaupause</title>
      <link>https://blog.koehntopp.info/2010/05/11/statifizierung-fuer-s9y-eine-blaupause.html</link>
      <pubDate>Tue, 11 May 2010 08:54:12 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2010/05/11/statifizierung-fuer-s9y-eine-blaupause.html</guid>
      <description>&lt;p&gt;An anderer Stelle gab es in einem komplett anderen Kontext eine Diskussion
(&lt;a href=&#34;http://mysqldump.azundris.com/archives/36-Serving-Images-From-A-Database.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1&lt;/a&gt;

,
&lt;a href=&#34;http://mysqldump.azundris.com/archives/37-Serving-Images-from-a-File-System.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2&lt;/a&gt;

,
&lt;a href=&#34;http://mysqldump.azundris.com/archives/59-Statification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3&lt;/a&gt;

) in der es
auch schon mal um die Statifizierung von Seiten ging.&lt;/p&gt;
&lt;p&gt;In dem
&lt;a href=&#34;http://mysqldump.azundris.com/archives/36-Serving-Images-From-A-Database.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ersten&lt;/a&gt;


Artikel ging es mir darum zu verdeutlichen, wie viel Mehrarbeit die
Auslieferung einer Seite ist, wenn sie durch den Codepath des Webservers
erfolgt statt durch den Fastpath - und das Beispiel bezieht sich noch auf
die Auslieferung einer Bilddatei, also nur das Schaufeln von Daten statt die
Seite zu berechnen. Sheeri war damals der Ansicht, daß das ein Problem mit
dem Dateisystem gäbe, aber das ist tatsächlich nur der Fall, wenn man ein
veraltetes Dateisystem verwendet, das Verzeichnisse als lineare Listen
ablegt.&lt;/p&gt;
&lt;p&gt;In dem
&lt;a href=&#34;http://mysqldump.azundris.com/archives/37-Serving-Images-from-a-File-System.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zweiten&lt;/a&gt;


Artikel benchmarke ich das Verhalten von Reiserfs 3.6, aber xfs und sogar
ext3 mit DIR_INDEX sollten sich vergleichbar verhalten.&lt;/p&gt;
&lt;p&gt;Der &lt;a href=&#34;http://mysqldump.azundris.com/archives/59-Statification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dritte&lt;/a&gt;


Artikel erklärt dann Statifizierung von - im Beispiel - Bilddateien durch
404-Handler. Diese Methode ist auch auf das Blog anwendbar.&lt;/p&gt;
&lt;p&gt;Das Blog &amp;lsquo;leidet&amp;rsquo; dabei darunter, daß auf einer Seite als Speichereinheit
eine Menge von Elementen zu sehen sind, die alle eine unterschiedliche
Lebensdauer haben. Daher müßten bei der Änderung eines Seitenelementes alle
Seiten invalidiert werden, in denen das Seitenelement vorkommt. Das ist
nicht effizient.&lt;/p&gt;
&lt;p&gt;Der erste Schritt muß daher darin bestehen, die Seite in ihre Elemente zu
zerschneiden und die Seitenelemente einzeln in separaten Dateien zu cachen.&lt;/p&gt;
&lt;h3 id=&#34;zusammensetzen-im-client&#34;&gt;
    &lt;a href=&#34;#zusammensetzen-im-client&#34;&gt;
	Zusammensetzen im Client
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das bedeutet aber, daß die Seite bei der Auslieferung zusammengesetzt werden
muß. Wenn man dabei das Zusammensetzen der Seite im Webserver vermeiden
will, dann muß das im Client passieren. Der am wenigsten aufwendige Fall ist
dabei die Verwendung von IFrames, so wie schon jetzt auf der Startseite
dieses Blogs ein Google-Calendar von anderswo mit Hilfe eines IFrames
eingebunden wird.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iframe&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http:/www.google.com/calendar/embed?...&amp;#34;&lt;/span&gt; 
  &lt;span class=&#34;na&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;border-width:0&amp;#34;&lt;/span&gt; 
  &lt;span class=&#34;na&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;240&amp;#34;&lt;/span&gt; 
  &lt;span class=&#34;na&#34;&gt;height&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;280&amp;#34;&lt;/span&gt;
  &lt;span class=&#34;na&#34;&gt;frameborder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;
  &lt;span class=&#34;na&#34;&gt;scrolling&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;no&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iframe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das funktioniert mit dem Google Calender, weil die Größe des Elementes vorab
bekannt ist.&lt;/p&gt;
&lt;p&gt;Würde man im Falle von S9Y eigene Komponenten von sich selbst einbinden,
hätte man gerne ein IFrame- oder &amp;ldquo;Div src=&amp;quot;-Element ohne Größenangaben:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iframe&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;http://blog.koehntopp.de/statify/latest_comments.html&amp;#39;&lt;/span&gt;
  &lt;span class=&#34;na&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iframe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Leider gibt es so etwas nicht, sodaß man auf andere, schlechtere Methoden
angewiesen ist, um die Seite zusammenzusetzen.&lt;/p&gt;
&lt;p&gt;Der Punkt am Ende ist jedoch: Die Datei /statify/latest_comments existiert
zunächst nicht.&lt;/p&gt;
&lt;h3 id=&#34;erzeugung-on-demand&#34;&gt;
    &lt;a href=&#34;#erzeugung-on-demand&#34;&gt;
	Erzeugung on-demand
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Dadurch kommt es zu einem 404-Error, der vom 404-Handler von Serendipity
abgefangen wird. Dort erkennt S9Y den Namen des Plugins, instantiiert das
gesamte S9Y Framework und ruft dann den Plugin-Handler innerhalb einer
&lt;a href=&#34;http://php.net/manual/en/function.ob-start.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ob_start()&lt;/a&gt;

 Umgebung auf
und läßt das Plugin normal ablaufen.&lt;/p&gt;
&lt;p&gt;Wenn das Plugin sich selbst als Cacheable ansieht (und das zu entscheiden
ist die Aufgabe jedes Plugins für sich alleine), dann holt es sich mit
&lt;a href=&#34;http://www.php.net/manual/en/function.ob-get-contents.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ob_get_contents()&lt;/a&gt;


seine Ausgabe und schreibt diese in die Datei
/statify/latest_comments.html. Dadurch werden nachfolgende
Requests auf diese Datei vom normalen Handler für statische Dateien
abgehandelt und der Code für das Plugin hat sich ein für alle Mal aus dem
Codepath entfernt - es wird nie wieder ausgeführt.&lt;/p&gt;
&lt;p&gt;Jedenfalls so lange, bis die Datei gelöscht wird - siehe unten.&lt;/p&gt;
&lt;h3 id=&#34;atomares-schreiben&#34;&gt;
    &lt;a href=&#34;#atomares-schreiben&#34;&gt;
	Atomares Schreiben
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Beim Schreiben der Datei muß man Vorsicht walten lassen. Es ist möglich, daß
zwei verschiedene Apache Worker Slaves zur selben Zeit dieselbe
/statify/latest_comments.html erzeugen. Es ist auch möglich, daß
weitere Apache Worker die /statify/latest_comments.html
ausliefern wollen, auch wenn sie noch gar nicht vollständig erzeugt ist.
Daher muß das Schreiben so erfolgen:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-php&#34; data-lang=&#34;php&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;?&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;php&lt;/span&gt;
  &lt;span class=&#34;nv&#34;&gt;$pid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;posix_getpid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
  &lt;span class=&#34;nv&#34;&gt;$filename&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;make_filename_from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/statify/latest_comments.html&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$pid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
  &lt;span class=&#34;nv&#34;&gt;$final_filename&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;make_filename_from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;/statify/latest_comments.html&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

  &lt;span class=&#34;nv&#34;&gt;$str&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ob_get_contents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;file_put_contents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
  &lt;span class=&#34;c1&#34;&gt;// Datei sichtbar machen
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;rename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$final_filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;cp&#34;&gt;?&amp;gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;expire&#34;&gt;
    &lt;a href=&#34;#expire&#34;&gt;
	Expire
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Das Plugin kann sich selbst in der S9Y-Callback-Architektur registrieren,
zum Beispiel kann es dafür sorgen, daß sein Expire-Hook aufgerufen wird,
wenn ein neuer Kommentar geposted wird. Der Expire-Hook würde dann
&amp;ldquo;/statify/latest_comments.html&amp;rdquo; löschen, die Datei aber nicht
neu erzeugen. Sie wird automatisch neu erzeugt, falls sie jemals neu
benötigt wird.&lt;/p&gt;
&lt;h3 id=&#34;was-cachen&#34;&gt;
    &lt;a href=&#34;#was-cachen&#34;&gt;
	Was cachen?
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Die Artikelseiten selbst können so auch gecached werden und für einige
Seiten - etwa die Startseite und die Artikel, die auf der Startseite
sichtbar sind - ist das auch viel wichtiger als für andere Seiten. Die Logik
für das Cachen von Artikeln kann entweder alle Artikel cachen, die jemals
aufgerufen worden sind, oder um Platz zu sparen die Caching-Entscheidung auf
den o.a. genannten Set einschränken.&lt;/p&gt;
&lt;p&gt;Eine andere Serie von Dateien, die dringend gecached werden muß, sind die
Dateien für die RSS-Feeds. Derzeit erlaubt S9Y den Abruf von RSS-Feeds über
Namen (index.rss2, atom.xml) und über Parameter (rss.php?&amp;hellip;&amp;amp;&amp;hellip;). Letzteres
ist nie cachebar und der Support dafür muß entfernt werden. Stattdessen
müssen die Parameter irgendwie in den Dateinamen der RSS-Datei integriert
werden, und die Anzahl der möglichen RSS-Feeds muß eingeschränkt werden.
Oder man ignoriert dieses Problem und es  reguliert sich darüber selbst, daß
bestimmte Feeds nie aufgerufen werden - es kommt auch nicht darauf an, daß
man alles cached, sondern daß man die Seiten statifiziert, die oft
aufgerufen werden.&lt;/p&gt;
&lt;p&gt;Für den Moment habe ich mir das schon einmal hingehackt: Laut Abrufstatistik
ist es so, daß 35% aller Zugriffe in mein Blog auf /feeds/index.rss2
erfolgen, 3% auf atom.xml und ein weiteres Prozent auf comments.rss2. Ein
Script wird jede Minute einmal ausgeführt:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;! /bin/bash --
&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;cd /home/www/servers/blog.koehntopp.de/pages
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;[ ! -d feeds ] &amp;amp;&amp;amp; mkdir feeds
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;cd feeds
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;if [ -f .lock ]
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;then
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;    pid=$(cat .lock)
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;    if kill -0 &amp;#34;$pid&amp;#34;
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;    then
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;        exit
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;    fi
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;fi
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;echo $$ &amp;gt; .lock
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;rm -f index.rss2
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;curl -o index.rss2 http://blog.koehntopp.de/feeds/index.rss2 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;rm -f atom.xml
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;curl -o atom.xml http://blog.koehntopp.de/feeds/atom.xml &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;rm -f comments.rss2
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;curl -o comments.rss2 http://blog.koehntopp.de/feeds/comments.rss2 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;rm -f .lock
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Dieses Script sorgt dafür, daß diese drei Dateien als minütlich neu erzeugte
statische Dateien vorliegen statt dynamisch n-fach parallel erzeugt zu
werden. Es hat die Last auf dem Server dramatisch gesenkt, auch wenn die
dahinter stehende Logik primitiv und leicht falsch ist. Mit dem
404-Handler-Framework von oben wären diese Dateien aber immer aktuell und
frisch, und ohne daß ein Cronjob notwendig wäre.&lt;/p&gt;
&lt;h3 id=&#34;was-nicht-cachen&#34;&gt;
    &lt;a href=&#34;#was-nicht-cachen&#34;&gt;
	Was nicht cachen?
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Wenn man in einer Artikelseite ist kommentiert, dann landet man in einem
interaktiven Teil des Blogs. Zugleich sollte diese Seite selbst aber
statisch sein.&lt;/p&gt;
&lt;p&gt;Daher ist es am günstigsten, wenn die Artikelseite /archives/2789-uuid.html
(statisch) das Kommentarformular so baut, daß es den Kommentar an die URL
/dynamic/2789-uuid.html übermittelt. Diese URL erzeugt dieselbe Seite, aber
dynamisch und ohne Cache. Dort kann dann die normale &amp;lsquo;Ihr Kommentar wurde
wegen Captcha/Duplizierung/Was-auch-mmer abgelehnt&amp;rsquo;-Schleife dynamisch
durchlaufen. Wenn der Kommenar endlich angenommen wurde, löscht die
dynamische Seite die statische Seite und redirected den Browser auf die
(jetzt nicht mehr existierende) statische Seite zurück. Dadurch wird sie
dann auch gleich neu und mit dem neuen Kommentar darin erzeugt.&lt;/p&gt;
&lt;p&gt;Auf diese Weise hat man nie Probleme damit, daß die wechselnden Begründungen
für die Ablehnung des Kommentares gecached werden.&lt;/p&gt;
&lt;p&gt;Das ist effizient unter der Annahme, daß weniger kommentiert als gelesen
wird.&lt;/p&gt;
&lt;p&gt;Garvin merkt noch an:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Solche Features wie &amp;ldquo;Leserechte auf Userbasis&amp;rdquo;, &amp;ldquo;Adminlinks für
Redakteure&amp;rdquo;, &amp;ldquo;Content-Negotiated-Language&amp;rdquo; wird man verlieren, auch das
Statistik-Tracking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Das ist in erster Näherung sicher wahr, aber wahrscheinlich auch für die
Masse der S9Y-Anwender und alle S9Y-Anwender mit Last wahrscheinlich egal.&lt;/p&gt;
&lt;p&gt;Nebenbei kann man
&lt;a href=&#34;http://httpd.apache.org/docs/2.0/content-negotiation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Content-Negotiated-Language&lt;/a&gt;


im Apache (und vielen anderen Webservern) im Fast-Path erledigen lassen und
mit den Gedanken aus
&lt;a href=&#34;http://redmine.lighttpd.net/wiki/1/Docs:ModSecDownload&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ModSecDownload&lt;/a&gt;


(für Lighttpd) oder
&lt;a href=&#34;http://code.google.com/p/mod-auth-token/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mod_auth_token&lt;/a&gt;

 (für Apache 2.x)
kann man im Nachgang auch Leserechte auf Userbasis und eventuell auch
Adminlinks für Redakteure mit statischen Dateien implementieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Webanwendungen und der FHS</title>
      <link>https://blog.koehntopp.info/2005/06/13/webanwendungen-und-der-fhs.html</link>
      <pubDate>Mon, 13 Jun 2005 10:47:50 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/06/13/webanwendungen-und-der-fhs.html</guid>
      <description>&lt;p&gt;Auf der S9Y Mailingliste fragte ein zukünftiger Paketmaintainer nach, ob er Serendipity für seine Distribution packen solle und wir ihn dabei unterstützten wollen. Abgesehen von allgemeinen Überlegungen die dagegen sprechen, gibt es noch andere Gründe, die das nicht wünschenswert machen.&lt;/p&gt;
&lt;p&gt;In den Bereich der allgemeinen Überlegungen fallen zum Beispiel die Releasezyklen von Distributionen: Sie sind in der Regel sehr viel länger als die von Webanwendungen wie Serendipity. Insbesondere sehr langwellige Distributionen wie Debian verteilen mit ihren Paketen Versionen der Software, die die Entwickler von S9Y nicht mehr unterstützen können und wollen.&lt;/p&gt;
&lt;p&gt;Auch ist fraglich, welchen Gewinn ein solches Package bringen soll. Eine Anwendung wie S9Y installiert sich mit Download-Auspacken-Anklicken sowieso schon selber und ist dabei dann an keinerlei externes Packaging oder fremde Zyklen gebunden. Eine Installation mit Betriebssystem-Packages bringt da nur Nachteile und fehlende Flexibilität. Zum Beispiel ist es so nicht leicht möglich, mehr als eine Version von S9Y an mehr als einer Location im System zu installieren, denn das Packagemanagement der üblichen Distributionen unterstützt weder konkurrente Installation unterschiedlicher Paketversionen noch sind verschiebliche Pakete mit durch den Anwender bestimmter Package-Root allgemein üblich.&lt;/p&gt;
&lt;p&gt;Aber das ist nur die Spitze des Eisberges. Checkt man sich einmal
&lt;a href=&#34;https://alioth.debian.org/projects/webapps-common/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;webapps-common&lt;/a&gt;

 aus und liest, was da drin steht - oder vielmehr nicht drin steht, sieht man, daß ein solches Packaging nur Nachteile haben kann:&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;21-web-applications-and-the-fhs&#34;&gt;
    &lt;a href=&#34;#21-web-applications-and-the-fhs&#34;&gt;
	2.1 Web applications and the FHS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Web applications should follow the same guidelines as any other software. most specifically, they should not make any assumption about how the administrator has arranged the file hierarchy outside of the FHS by placing files in non-standard places such as /var/www or /usr/local. Specifically, the following table should serve as guidelines for the location of files:&lt;/p&gt;
&lt;p&gt;| type of file                           | location                        |
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+
| static web pages                       | /usr/share/PACKAGE/www          |
| dynamically interpreted web pages      | /usr/share/PACKAGE/www          |
| persistent application data            | /var/lib/PACKAGE                |
| dynamcially executed web pages         | /usr/lib/cgi-bin/PACKAGE        |
| application-specific libraries         | /usr/share/PACKAGE/include      |
| site configuration                     | /etc/PACKAGE                    |
| locally modifiable/overridable content | /etc/PACKAGE/templates          |
| php libraries                          | /usr/share/php/PACKAGE          |
| rrd, mrtg and other database files     | see database application policy |&lt;/p&gt;
&lt;p&gt;Fußnoten weggelassen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Das ist so kraß konsequent an der Realität vorbei, daß es mir persönlich schon wieder Respekt abnötigt.&lt;/p&gt;
&lt;p&gt;Webanwendungen sind überall für Webhostingumgebungen entwickelt, denn dies ist bei weitem die verbreiteste Form des Deployments für Webanwendungen. Webhostingumgebungen werden aber in der Regel per Filetransfer in ein Verzeichnis unterhalb der DocumentRoot der Kundendomain beschickt. Sicherheitsmechanismen in Webhostingumgebungen berücksichtigen das: Mit chroot() oder Virtual Base Directory versuchen sie, den Kunden auf seinen Verzeichnisteilbaum zu beschränken. mit einer UID und GID pro Kunde oder pro Kundendomain versuchen sie, Betriebssystem-Zugriffsrechte als Hilfsmittel zur Kundentrennung zu benutzen.&lt;/p&gt;
&lt;p&gt;Eine Webapp-Policy, die das komplett ignoriert und Webanwendungen atomisiert, um ihre Trümmer dann einmal durch das Dateisystem zu zerstäuben hat so überhaupt nichts mit der Realität zu tun, daß man im ersten Augenblick nur sprachlos daneben stehen kann.&lt;/p&gt;
&lt;p&gt;Okay, hier ist also einmal ein Katalog von Anforderungen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Policy muß chroot/virtual base directory jails unterstützen&lt;/li&gt;
&lt;li&gt;Policy muß UID pro Domain/GID pro Kunde oder ähnliche Setups unterstützen, die auf Apache suexec oder PHP safe_mode basieren&lt;/li&gt;
&lt;li&gt;Policy muß erlauben, daß die Anwendung mehr als einmal pro physikalischem Rechner installiert wird&lt;/li&gt;
&lt;li&gt;Policy muß erlauben, daß die Anwendung in mehr als einer Version pro physikalischem Rechner installier wird.&lt;/li&gt;
&lt;li&gt;Policy muß dem Kunden erlauben, seine Installation per ftp/scp/rsync zu sichern und zu modifizieren. Versionsmanagement muß erkennen, ob die modifizierte Anwendung danach noch automatisiert updatebar ist und ggf. einen Mergeprozeß unterstützen.&lt;/li&gt;
&lt;li&gt;Policy muß die Installation mehrerer unterschiedlicher Webanwendungen pro Vhost in unterschiedliche Directories unterhalb der DocRoot eines VHosts unterstützen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die Policy muß also ein Framework liefern, mit dem man Vhosts schnell erzeugen kann, mit dem man in einem Vhosts Features wie modlogan, perl, python, php, chroot Jail und andere Eigenschaften enablen und disablen kann, und mit dem man pro VHost eine oder mehrere Anwendungen in unterschiedlichen Verzeichnissen installieren und möglicherweise sogar sicher aktualisieren kann. Dabei muß die Anwendung durch Kopie aus einem Shared Repository installiert werden können, durch Hardlink auf das Repository um Platz zu sparen oder sie muß, wenn die Anwendung das unterstützt, shared installs (PEAR, S9Y, &amp;hellip;) möglich machen.&lt;/p&gt;
&lt;p&gt;All das ist natürlich mit dem FHS komplett inkompatibel. Aber kompatibel mit den Anforderungen des Webgeschäfts, das nun einmal mit dem FHS erst einmal genau gar nix zu tun hat.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Abschied aus dem USENET</title>
      <link>https://blog.koehntopp.info/2005/02/15/abschied-aus-dem-usenet.html</link>
      <pubDate>Tue, 15 Feb 2005 20:08:30 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2005/02/15/abschied-aus-dem-usenet.html</guid>
      <description>&lt;p&gt;Das älteste Posting, das Google Groups von mir hat, ist
&lt;a href=&#34;http://groups-beta.google.com/group/sub.config/msg/1b2b1a01e36f92e9?dmode=source&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;von Mitte 1989&lt;/a&gt;

.
Ich schrieb damals als &lt;code&gt;kris@tpki.UUCP&lt;/code&gt; aka &lt;code&gt;...!mcshh!tpki!kris&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Für die mit der Gnade der späten Geburt gesegneten:
Damals hatten wir noch kein automatisches Routing und auch keine direkten Verbindungen wie im Internet.
Mail wurde über Modem-Links von System zu System weitergegeben.
Da wir kein automatisches Routing hatten, musste man mit dem sogenannten Bang-Path (wegen der Ausrufezeichen, Bang!) die Systeme angeben, über die die Nachricht transportiert wurde.
&lt;code&gt;...!mcshh!tpki!kris&lt;/code&gt; ist also der Pfad zu meiner Mailbox ab dem damals relativ bekannten System mcshh.&lt;/p&gt;
&lt;p&gt;Hostnamen waren weltweit eindeutig, da es noch keine Domains gab.&lt;/p&gt;
&lt;p&gt;Systeme mussten sogenannte Mapschnipsel veröffentlichen, in denen sie ihren Namen und ihre Verbindungen zu anderen Systemen bekannt gaben.
Ein Eintrag wie &lt;code&gt;oski  tpki(DAILY)&lt;/code&gt; deklarierte dann eine Verbindung zwischen den Systemen &lt;code&gt;oski&lt;/code&gt; und &lt;code&gt;tpki&lt;/code&gt;, die einmal pro Tag Mail abgeholt hat.&lt;/p&gt;
&lt;p&gt;Mit dem Programm &lt;code&gt;pathalias&lt;/code&gt; konnte man die Liste der Mapschnipsel nehmen und in Routingtabellen der Form &lt;code&gt;oski kriski!tpki!oski!%s&lt;/code&gt; umgewandelt werden.
Diese Tabellen stellten das Netz aus der Sicht des Absenders dar, sodass eine Mail an &lt;code&gt;olaf@oski&lt;/code&gt; automatisch in den Bang &lt;code&gt;kriski!tpki!oski!olaf&lt;/code&gt; umgewandelt werden konnte.&lt;/p&gt;
&lt;p&gt;Zusammen mit den Mails wurden über die Modemverbindungen damals auch die USENET News ausgetauscht.
Damals hatte man in der Regel einen lokalen News-Server auf seinem System laufen und die eingehenden News wurden eingelesen und auf dem lokalen News-Server bereitgestellt.
Abgehende Artikel wurden lokal auf dem eigenen System veröffentlicht und auf allen angeschlossenen Systemen verbreitet.
Weil jeder Artikel eine eindeutige ID hatte, konnte ein System erkennen, ob ihm ein Artikel mehrfach zugestellt wurde und Duplikate verwerfen.
Artikel haben sich so im &amp;ldquo;Flood-Fill Verfahren&amp;rdquo; im Netz ausgebreitet und waren in tausenden Kopien auf allen Servern verfügbar.&lt;/p&gt;
&lt;p&gt;Für mich waren USENET News und Mail damals der Einstieg ins Netz - lange vor Internet und drei Jahre vor der Erfindung von http.
Sie waren für mich auch lange Zeit das primäre Kommunikationsmedium und ich habe über die viele aufregende Personen kennengelernt - die Teilnehmer an der Silvesterfeier des Hohen Rathes der Dreizehn Weisen vom Feed werden sicherlich wissen, was ich meine.
Zu dieser Channelparty^W^Wdiesem Newsgrouptreffen von &lt;code&gt;de.talk.bizarre&lt;/code&gt; am 31.12. hatte ich rund 20 Leute nach Kiel eingeladen, die ich noch niemals vorher in Persona gesehen hatte und die sich auch untereinander dort größtenteils zum ersten Mal getroffen haben.
Das war eine wirklich gute Feier.&lt;/p&gt;
&lt;p&gt;Heute brät USENET meistenteils im eigenen Saft - die Diskussionen dort sind alt, ich habe sie in den vergangenen 16 Jahren meiner Anwesenheit dort viele Male gesehen.
Erst neulich habe ich mein Zugangspaßwort für &lt;code&gt;news.individual.net&lt;/code&gt; wiedergefunden und erstaunt gemerkt, daß ich es für zwei Monate verloren hatte - ich hatte nicht einmal bemerkt, daß es dem Reader aus der Konfiguration gerutscht war, weil ich ihn schlicht nie aufgerufen habe.&lt;/p&gt;
&lt;p&gt;Heute lese ich auf
&lt;a href=&#34;http://news.individual.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;news.individual.net&lt;/a&gt;

,
daß mein Zugang dort in Zukunft Geld kosten wird und eine Neuanmeldung erforderlich ist.
Der Betrag ist angenehm niedrig - 10 Euro pro Jahr (!).&lt;/p&gt;
&lt;p&gt;Dennoch habe ich beschlossen, daß der 31. März 2005 der letzte Tag meiner Anwesenheit in den USENET News sein wird - es ist die Mühe nicht mehr wert.&lt;/p&gt;
&lt;p&gt;Mein Reader ist inzwischen Akregator, und wer mit mir diskutieren will, der kann das in den Kommentaren meines Blogs tun oder mich trackbacken.
Blogs kann man haufenweise schnell und einfach bekommen - supersized.org ist möglicherweise nicht die schlechteste Wahl.&lt;/p&gt;
&lt;p&gt;In diesem Sinne: 16 Jahre sind genug. Lebewohl, USENET!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

