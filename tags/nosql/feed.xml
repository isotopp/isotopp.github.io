<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nosql on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/nosql.html</link>
    <description>Recent content in Nosql on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>kris-blog@koehntopp.de (Kristian Köhntopp)</managingEditor>

    
    <webMaster>kris-blog@koehntopp.de (Kristian Köhntopp)</webMaster>

    
    <lastBuildDate>Fri, 28 Feb 2025 13:35:54 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/nosql/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Zu Besuch bei Redis</title>
      <link>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</link>
      <pubDate>Sun, 23 Sep 2012 19:06:45 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/09/23/zu-besuch-bei-redis.html</guid>
      <description>&lt;p&gt;Hier ist eine wichtige Zahl: Ein Coredump von einem MySQL auf einer Maschine mit knapp unter 200 GB Speicher dauert 15 Minuten.
Auf SSD.
Auf eine Festplatte dauert der gleiche Coredump dann knapp über 30 Minuten.&lt;/p&gt;
&lt;p&gt;Warum ist das eine wichtige Zahl?&lt;/p&gt;
&lt;p&gt;SSD sind schnell.
Linear schreiben sie mehr als 200 MB pro Sekunde weg - ein ziemlich beeindruckendes Tempo, und noch dazu in einer Disziplin, wo sie nicht einmal optimal nutzbar sind.
Auch moderne Serverfestplatten sind schnell - beim linearen Schreiben immerhin knapp halb so schnell wie eine SSD, oder 100 MB pro Spindel linear.&lt;/p&gt;
&lt;p&gt;Aber moderne Maschinen haben halt auch eine sehr große Menge Speicher.
Und 200 GB bei 200 MB pro Sekunde sind halt dann eine Viertelstunde pro Full Dump oder Full Scan.&lt;/p&gt;
&lt;p&gt;In
&lt;a href=&#34;http://blog.ulf-wendel.de/2012/eine-reiche-nosql-anfragesprache/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eine reiche NoSQL-Anfragesprache&lt;/a&gt;


macht Ulf Wendel sich Gedanken über die Leistungsfähigkeit von Abfragesprachen für NoSQL-Datenbanken, und ob es darstellbare Gemeinsamkeiten gibt.&lt;/p&gt;
&lt;p&gt;Das ist eine gute Überlegung, aber meiner Meinung nach setzt es schon mindestens einen Schritt zu spät auf.
Zunächst will man sich Überlegen, ob man &amp;ldquo;seiner&amp;rdquo; NoSQL-Datenbank überhaupt Daten anvertrauen will.
Die meisten SQL-Datenbanken sind nämlich außergewöhnlich schlechte lokale Speicher.
Und das ist eine schlechte Ausgangsposition, denn alles, was mit horizontalem Scaleout und verteilten Datenbanken zu tun hat, setzt eine Schicht höher auf, und ist schlicht nicht gut tragfähig, wenn das Fundament schlecht ist.&lt;/p&gt;
&lt;p&gt;Hier ist &lt;a href=&#34;http://redis.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Redis&lt;/a&gt;

.
Redis ist ein Key-Value Store mit ein paar Extras, denn neben einem großen Hash mit Netzwerkinterface versteht es auch Strings, Listen (oder Stacks), Mengen und geordnete Mengen.
Redis realisiert Persistenz auf genau dieselbe Weise wie MySQL Cluster:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wann immer man möchte, erzeugt Redis einen
&lt;a href=&#34;http://redis.io/commands/bgsave&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;point-in-time snapshot&lt;/a&gt;

.
Darunter verstehen die Redis-Entwickler einen fork() des Servers, und dann im Kindprozess ein Abspeichern des gesamten Datenbereiches auf Platte -  also das Äquivalent eines Coredumps.&lt;br&gt;
Wichtig dabei auch: Overcommit auf   OS-Level erlauben, sonst darf man nur sein halbes RAM für Daten nutzen!&lt;/p&gt;
&lt;p&gt;Wir wissen nun schon, daß dieser Schreibprozess auf einer zeitgemäßen Maschine etwa 15 oder 30 Minuten dauern wird und dabei die Bandbreite der Festplatte vollständig belegen wird.
Im Falle eines Crashes hat man damit bei Recovery einen Stand, der bis zu 30 Minuten in der Vergangenheit liegt.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redis unterhält außerdem ein Append Only File (AOF), oder, wie man in Datenbanktermen sagen würde, ein Redo-Log.&lt;br&gt;
Es schreibt alle Änderungen an Daten in zeitlicher Reihenfolge mit.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ohne Kompaktierung würde eine Recovery unendlich lange dauern, da alle Veränderungen an den Daten durch ein Abspielen des AOF der Reihe nach nachvollzogen werden.&lt;/p&gt;
&lt;p&gt;Mit Kompaktierung - dem AOF Rewrite wie Redis dies nennt - werden doppelte Updates desselben Datensatzes zusammengefügt, sodass nur der letzte Schreibzugriff pro Datensatz gespeichert wird.&lt;/p&gt;
&lt;p&gt;AOF Rewrite skaliert sich auch nicht - jeder Postgres oder CouchDB DBA, der schon mal mit einem Postgres
&lt;a href=&#34;http://wiki.postgresql.org/wiki/VACUUM_FULL&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VACUUM FULL&lt;/a&gt;


oder eine
&lt;a href=&#34;http://wiki.apache.org/couchdb/Compaction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CouchDB Compaction&lt;/a&gt;


laufen hatte, kennt genau die Auswirkungen, die ein AOF Rewrite hat.&lt;/p&gt;
&lt;p&gt;Wie lösen traditionelle Datenbanken wie InnoDB das Problem?
Mit einem
&lt;a href=&#34;https://blog.koehntopp.info/2011/09/19/checkpoint-blues.html&#34;&gt;Checkpoint&lt;/a&gt;

.&lt;br&gt;
MySQL unterhält wie Redis ein Bild der aktuellen Daten auf der Platte - Redis in Form des point-in-time snapshot, MySQL in Form von InnoDB *.ibd-Files.&lt;/p&gt;
&lt;p&gt;Anders als Redis schreibt MySQL aber bei einem Checkpoint nicht die ganze Tabelle neu.
Stattdessen sind ibd-Dateien (und der Speicher) in Seiten von 16 KB unterteilt.&lt;/p&gt;
&lt;p&gt;Und statt eines AOF-Rewrite, bei dem das ganze Redo-Log neu geschrieben wird, schreibt MySQL für jeden Eintrag im Redo-Log die zugehörende Speicherseite auf die Platte - aber eben nur diese, und nicht die ganze Tabelle.
MySQL macht dies außerdem auf eine Weise, bei der Daten nicht verloren gehen können, selbst dann, wenn die Datenbank mitten im Schreiben einer 16 KB-Seite den Strom abgeschaltet bekommt:
Die Daten landen einmal im Doublewrite-Buffer, dann wird das Redo-Log aktualisiert und dann werden die
Daten im *.ibd-File aktualisiert.
Auf diese Weise, und mit den Prüfsummen in jeder Seite, kann MySQL die Datenbank sogar von halb geschriebenen Seiten sauber wieder herstellen.&lt;/p&gt;
&lt;p&gt;MySQL skaliert:
Von einer Datenbank mit MySQL 5.6.6 und mit 192 GB RAM und 200 Connections, die wie wild schreiben, bekommen wir eine Schreibrate von etwa 150 MB/sec netto auf zwei SSD.
Bedenkt man den Overhead mit dem Doublewrite-Buffer und dem Redo-Log ist das immens beeindruckend.&lt;/p&gt;
&lt;p&gt;Das bringt uns zum 2. Thema: Concurrency.&lt;br&gt;
MySQL InnoDB skaliert, in MySQL 5.6 skaliert es sogar ziemlich unglaublich:
Ein Cluster mit 96 Cores, der 192 Verbindungen in die Datenbank unterhält, deren einzige Aufgabe es ist,
&lt;a href=&#34;https://blog.koehntopp.info/2012/08/15/materialized-view.html&#34;&gt;Daten zu berechnen und zu schreiben&lt;/a&gt;

,
kommt mit der o.a.  Konfiguration auf die genannten 150 MB/sec, und nutzt  dabei - Threading sei Dank - die CPU-Kapazität der 12 physikalischen Cores (24 virtuellen Hyperthreading-Cores) der Datenbank gut aus.&lt;/p&gt;
&lt;p&gt;Ein
&lt;a href=&#34;http://www.enjoythearchitecture.com/redis-architecture&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Single Threading Design&lt;/a&gt;


erscheint mir in 2012 relativ hirntot, denn damit handelt man sich jede Menge
&lt;a href=&#34;http://redis.io/topics/latency&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Latenzprobleme&lt;/a&gt;


ein - und in 2012 ist es nun einmal unmöglich, Hardware mit nur einem Kern zu kaufen.&lt;br&gt;
Selbst Mobiltelefone sind inzwischen Quadcores.&lt;/p&gt;
&lt;p&gt;Abhilfe wäre eine Aufteilung des Servers, indem man ihn mit cgroups oder anderen Hilfsmitteln in z.B.  von einem 12-Core mit 192 GB in 12 Singlecores mit je 16 GB Speicher unterteilt.&lt;br&gt;
Jetzt bekommt man aber ein Problem mit der Adressierung - welche Daten bringe ich wo unter, und wie frage ich 12 Serverinstanzen parallel ab (oder ich frage 12-mal hintereinander nach meinen Daten, türme dann aber 12 Latenzen aufeinander).&lt;/p&gt;
&lt;p&gt;Und man bekommt ein Problem mit der Orchestrierung, denn jetzt habe ich 12 Instanzen auf derselben Hardware, die parallel point-in-time snapshots oder AOF schreiben müssen, und dabei um die vorhandene Disk Bandbreite konkurrieren.
Wenn sie jedoch jemals tun, werden unsere linearen Writes zu Seeks, und plötzlich wird unsere ehemals ach so schnelle Disk wirklich, wirklich langsam und unsere Latenzen explodieren wirklich.&lt;/p&gt;
&lt;p&gt;Als Anwendungsentwickler fragt man sich natürlich auch:
Was soll die Scheiße?
Also, warum soll ich mich als Anwendungsentwickler um so etwas kümmern?
Wieso ist der Server nicht in der Lage, sich um solche Details selber zu kümmern?
Und wieso ist dieses Problem der Orchestrierung nicht sowieso schon gelöst?&lt;/p&gt;
&lt;p&gt;Die Antwort auf die letzte Frage wird klar, wenn man sich die in
&lt;a href=&#34;http://redis.io/topics/latency&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;der Latency-Seite&lt;/a&gt;


die im Abschnitt &amp;ldquo;Fork time in different systems&amp;rdquo; genannten Systemgrößen einmal anschaut:
360 MB bis 7 GB.&lt;br&gt;
Zum Vergleich: Das kleinste erhältliche Mobiltelefon kommt in 2012 mit 8 GB Speicher.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.amazon.com/Transaction-Processing-Techniques-Management-ebook/dp/B007TM5KKM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Der Gray&lt;/a&gt;


ist teuer, Elsevier halt, aber nicht &lt;em&gt;so&lt;/em&gt; teuer.&lt;br&gt;
Und man bekommt 40 Jahre Erfahrungen mit Persistenz done right (and scaleable) für sein Geld.
InnoDB ist ziemlich genau eine Lehrbuchimplementierung des Gray.&lt;/p&gt;
&lt;p&gt;InnoDB hat Probleme, aber es hat sie an Stellen, an denen Redis noch nicht mal Code hat.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Zusammenfassung &#39;Schemaless&#39;</title>
      <link>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</link>
      <pubDate>Wed, 20 Apr 2011 15:01:54 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html</guid>
      <description>&lt;h2 id=&#34;die-antwort-alter-table-vs-schemaless&#34;&gt;
    &lt;a href=&#34;#die-antwort-alter-table-vs-schemaless&#34;&gt;
	Die Antwort: ALTER TABLE vs. Schemaless
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;ALTER TABLE in MySQL nervt. Das tut es in erster Linie, weil es die
Tabellen, die es verändert, mit einem exklusiven Lock (Write Lock) belegt,
während es die Änderung durchführt, und weil es die Änderung durch
Umkopieren der Daten und Indices durchführt, was bei einer großen
bestehenden Datenmenge doch recht lange dauern kann.&lt;/p&gt;
&lt;p&gt;Es gibt inzwischen eine
&lt;a href=&#34;http://dev.mysql.com/doc/innodb/1.1/en/innodb-create-index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Reihe von Verbesserungen&lt;/a&gt;


in MySQL 5.5, wenn InnoDB (inzwischen die Default Storage Engine) verwendet
wird. Diese Verbesserungen beziehen sich zum größten Teil auf das Erzeugen
und Löschen von Indices im Hintergrund, also ohne Lock und ohne den Betrieb
aufzuhalten.&lt;/p&gt;
&lt;p&gt;Auch für das Erzeugen und Löschen von Spalten oder das Ändern von Defaults
gibt es Lösungen, die in InnoDB jedoch noch nicht umgesetzt sind. Die
meisten dieser Lösungen basieren auf versionierten Tabellendefinitionen und
einem verzögerten Update der Zeilen der Tabelle.&lt;/p&gt;
&lt;p&gt;Das könnte so gehen: Jede Tabelle hat eine versteckte Spalte &amp;lsquo;version&amp;rsquo;, in
der die Schemaversion für diese Zeile gespeichert ist. Ein ALTER TABLE auf
eine Tabelle verändert an der Tabelle selbst erst einmal gar nichts, sondern
hinterlegt nur eine zusätzliche Version des Schemas in der .frm-Datei.&lt;/p&gt;
&lt;p&gt;Wird eine Zeile bearbeitet, wird das Schema für diese Zeile beim Lesen
aktualisiert und die Zeile dann später zurück geschrieben.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/lazy_schema_change.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Verzögerte Migration einer Tabelle von Schemaversion 1 auf Schemaversion 2.&lt;/p&gt;
&lt;p&gt;Im Beispiel wird das ursprüngliche&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;INTEGER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UNSIGNED&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AUTO_INCREMENT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;german&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;VARCHAR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ENGINE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;um ein späteres&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;ALTER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ADD&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COLUMN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;english&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;VARCHAR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ergänzt.&lt;/p&gt;
&lt;p&gt;Die ursprüngliche Tabellendefinition ist Version 1. Das ALTER TABLE, das die
Spalte &lt;tt&gt;english&lt;/tt&gt; zufügt ist Version 2. Das ALTER TABLE selbst macht
gar nichts, aber man kann erkennen, daß die Zeile mit der ID 2 schon
aktualisiert worden ist.&lt;/p&gt;
&lt;p&gt;In einer realen Implementierung ist diese Zeile eher repräsentativ für eine
ganze Speicherseite, also in InnoDB für alle Zeilen, die in derselben 16KB
Seite gespeichert werden. InnoDB macht allen I/O immer seitenweise und es
wäre nicht sehr ökonomisch, nur einzelne Zeilen zu ändern, wenn man gleich
eine ganze Seite  davon im Speicher hat. Außerdem könnte man auf diese Weise
die Schemaversion   per Seite statt per Row speichern, was noch einmal
Speicher spart. Es ist mir noch nicht ganz klar, ob man eine Seite unbedingt
immer beim in-den-Speicher-bringen aktualisieren will (aggressiver
Algorithmus), oder nur dann, wenn eine Seite sowieso auf Grund einer anderen
Operation modifiziert wird (zurückhaltender Algorithmus, der die
Aktualisierung nur dann durchführt, wenn die Seite auf Grund anderer
Operationen als dirty markiert wird).&lt;/p&gt;
&lt;p&gt;Auf diese Weise wird jedenfalls das ALTER TABLE ADD COLUMN und DROP COLUMN
sowie das MODIFY COLUMN selbst sehr schnell. Die eigentlichen Kosten fallen
dann im Hintergrund an, und zwar dann, wenn die Seite sowieso geändert wird
(zurückhaltener Algorithmus).&lt;/p&gt;
&lt;p&gt;Meine Anfrage in
&lt;a href=&#34;https://blog.koehntopp.info/2011/04/19/schemaless.html&#34;&gt;dem ersten Artikel&lt;/a&gt;


zum Thema brachte das Ergebnis, daß bei schemalosen Datenbanken die Optionen
ähnlich sind:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Man ignoriert das Problem.&lt;/li&gt;
&lt;li&gt;Man schreibt eine ALTER TABLE Prozedur.&lt;/li&gt;
&lt;li&gt;Man schreibt eine Migrationsprozedur, die dem lazy ALTER TABLE von oben entspricht.&lt;/li&gt;
&lt;li&gt;Man schreibt eine Migrationsprozedur, die dem lazy ALTER TABLE von oben entspricht,
verteilt den Code aber durch einen Haufen Stellen in der Anwendung.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Zu Option 1 erhielt ich dieses Anwendungsbeipiel:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ich hatte es erst letztens mit einer NoSQL-Datenbank, dass der Kunde noch
gerne ein Feld mehr wollte (Sortierung) und das Statement natürlich die
Sortierung benutzt hat. Eigentlich ganz schön, dass das so einfach ist.
Nun fand die DB aber plötzlich keine Datensätze mehr, die das Feld noch
nicht besaßen.Auf der einen Seite richtig, auf der anderen kommt da gerne
auch eine Migration auf einen zu, für einen einzigen neues Key. Aber damit
kann man leben und man fällt wahrscheinlich nur einmal drauf rein und
beachtet dies in der Entwicklung.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Leider erhielt ich auf meine Nachfrage, mit welcher technischen oder
organisatorischen Maßnahme das für die Zukunft geklärt wurde (&amp;lsquo;beachtet dies
in der Entwicklung&amp;rsquo;) keine Antwort.&lt;/p&gt;
&lt;p&gt;Zu Option 2 erhielt ich den folgenden Kommentar:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ich kann hier nur für Documentstore DBs sprechen. Fügten wir in der Form
ein weiteres Feld hinzu, musste ein Updateprogramm geschrieben werden,
dass die bereits vorhandenen Dokumente um dieses Feld erweiterte [&amp;hellip;],
sonst flog einem das ganze in Views um die Ohren oder die Dokumente
tauchten in den Views gar nicht erst auf, da das neue Feld als
Selektionskriterium verwendet wurde.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Dies entspricht weitgehend einem prozedural auscodierten ALTER TABLE.&lt;/p&gt;
&lt;p&gt;Zu Option 3 erhielt ich dieses Anwendungsbeispiel:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Umgesetzt habe ich das bisher, wie man es bei großen SQL-Datenbanken
letztendlich auch tun würde (wenn man die Tabelle nicht locken will):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Datensatz laden&lt;/li&gt;
&lt;li&gt;Gucken in welcher Version der Datensatz ist (bzw. ob Daten migriert werden müssen)&lt;/li&gt;
&lt;li&gt;Datensatz gegf. aktualisieren&lt;/li&gt;
&lt;li&gt;Datensatz speichern (oder warten bis der Datensatz eh gespeichert wird)&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;Ein weiterer Beitrag:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Als Anwendungsentwickler muss ich mich auf einmal in meinem Data
Abstraction Layer (DAL) um das Handling von Datensatz-bezogenen Versionen
kümmern und dort im Laufe der Zeit immer mehr Code implementieren, nur um
aus den aus dem Storage geladenen Daten sinnvolle Objekte zu erzeugen.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Option 4 wurde dort ebenfalls andiskutiert, aber verworfen:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Schiebt man das Problem noch weiter &amp;ldquo;den Stack hoch&amp;rdquo;, etwa weil man auch
im Domain Model nicht mit klaren Objekt-Definitionen, sondern vielleicht
mit Hashtables, JSON-Datenformaten oder sonst was rumhantiert, so
erschwert dies meiner Meinung nach nicht nur die Übersicht im Code,
sondern auch die weitere Verarbeitung in Controllern, Services und Views.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;modellierung-von-spezialisierungen&#34;&gt;
    &lt;a href=&#34;#modellierung-von-spezialisierungen&#34;&gt;
	Modellierung von Spezialisierungen
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;An anderer Stelle kam es zu einer Diskussion um erweiterbare Strukturen und Spezialisierungen, also Superclass-Subclass-Beziehungen. In der SQL-Welt implementiert man diese oft mit 1:0-Strukturen (also 1:1-Beziehungen, bei denen der rechte Part optional ist, und der linke Part eine Art von Klassenidentifikation enthält).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/kundendb.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;KundenDB eines mir bekannten Providers&lt;/p&gt;
&lt;p&gt;Ein mir recht gut bekanntes Anwendungsbeispiel ist eine technische
Kundendatenbank bei einem Provider. Dort speichert man Kunden und Produkte
ab (ein Kunde kann eine Reihe von Produkten gekauft haben). Alle Produkte
haben gemeinsame Eigenschaften, etwa ein Freischalt- und ein Endedatum,
Preise, Rabatte und so weiter. Alle Produkte haben außerdem einen Typ, etwa
DSL, weitere IP-Adresse, Webserver, Dedicated Server und so weiter. Für
jeden Typ gibt es jetzt eine weitere Tabelle, in der Attribute gespeichert
werden, die für die Unterklasse spezifisch sind (also DSL-spezifisch,
Webserver-spezifisch und so weiter).&lt;/p&gt;
&lt;p&gt;Anwendungen arbeiten nun entweder mit der Oberklasse, etwa weil sie
abrechnen. Oder sie arbeiten mit einem JOIN zwischen Produkt und einer
spezifischen Unterklasse
(&lt;code&gt;Produkt p JOIN dsl d ON p.product_id = d.product_id AND p.type = &#39;dsl&#39;&lt;/code&gt;),
etwa weil sie Konfiguration generieren. Die einzige Komponente, die mit
allen Unterklassen als Unterklassen arbeiten muß, ist der Editor. Der
wiederum ist jedoch so allgemein gehalten, daß er im Grunde mit jeder Art
von Tabelle arbeiten kann - er verwendet weitere Tabellen mit Meta-Hints zum
Layout der Edit-Seiten.&lt;/p&gt;
&lt;p&gt;In schemalosen NoSQL-Datenbanken modelliert man dies oft recht frei, auf
eine von mehreren Weisen:&lt;/p&gt;
&lt;p&gt;Der unformalste Ansatz fügt einfach Attribute zu Elementen dazu. Es gibt
dabei keine Kontrolle, ob die vorhandenen Attribute komplett sind, sondern
Attribute werden einfach einzeln zugefügt wie sie gebraucht werden. Das kann
zu allerhand Überraschungen zur Laufzeit führen.&lt;/p&gt;
&lt;p&gt;In einem etwas formaleren Ansatz hat man ein Attribut, das in etwa einem
&amp;lsquo;objectClass&amp;rsquo;-Attribut von
&lt;a href=&#34;http://www.openldap.org/doc/admin22/schema.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LDAP Schema&lt;/a&gt;


entspricht und die Klassen listet, denen das Objekt folgt, und das somit die
&amp;lsquo;MUST&amp;rsquo; und &amp;lsquo;MAY&amp;rsquo;-Attribute festlegt. Diese sind womöglich sogar typisiert.
Validierung dieser Regeln erfolgt typischerweise jedoch nicht in der
Datenbank, sondern im Getter/Setter.&lt;/p&gt;
&lt;h2 id=&#34;datenmodellierung&#34;&gt;
    &lt;a href=&#34;#datenmodellierung&#34;&gt;
	Datenmodellierung
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Bei der Modellierung hat man dann wieder OOP-typisch die Wahl zwischen Einbettung und Verweisen
(&lt;a href=&#34;http://www.mongodb.org/display/DOCS/Schema&amp;#43;Design#SchemaDesign-Embedvs.Reference&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MongoDB&lt;/a&gt;

),
während SQL praktisch immer mit Verweisen arbeitet.&lt;/p&gt;
&lt;p&gt;Obendrein kommen dazu noch gelegentlich technische Fragen wie Subdokument
vs. eigenes externes Dokument, die in einigen dieser Systeme elementar
unterschiedlich behandelt werden: typischerweise hat ein Dokument einen
eigenständigen Primärschlüssel, ist also addressierbar, während ein
Subdokument keinen eigenen Primärschlüssel hat, und daher nicht direkt
addressierbar ist: Eine OID des Parents plus Suchausdruck ist kein
invarianter und stabiler Name.&lt;/p&gt;
&lt;p&gt;SQL arbeitet praktisch immer mit Verweisen und nennt diese Fremdschlüssel,
ist aber in der Lage, diese Verweise optional innerhalb einer Query
aufzulösen (das ist genau das, was ein JOIN tut), sodaß man durch die
Formulierung der Query in der Abfrage die Wahl zwischen Einbettung und
Verweis hat - nicht jedoch bei der Speicherung, die in der Regel mit
Verweisen erfolgt.&lt;/p&gt;
&lt;p&gt;Viele NoSQL-Datenbanken erlauben einem immerhin die Wahl zwischen Einbettung
und Verweisen, etwa indem sie einen Datentyp OID bereitstellen. Vielfach
fehlt aber die Option des &amp;lsquo;deep read&amp;rsquo;, also des Auflösens von OID in
Unterobjekte mit einer einzigen Query (&amp;lsquo;fetchObject: OID deepReadLevel: 3&amp;rsquo;),
sodaß man sich beim Auflösen der Referenzen zusätzliche Netzwerklatenzen
einhandelt.&lt;/p&gt;
&lt;p&gt;Ein Diskussionsbeitrag stellt genau dies dar, zieht dies aber argumentativ
anders herum auf:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Der Zeitpunkt, zu dem Daten normalisiert werden, ist unterschiedlich. Bei
einer SQL-Datenbank müssen die Daten beim INSERT dem Schema entsprechen,
d.h. ich muß sie gleich normalisiert, wenn ich sie entgegennehme. Bei
einem schemalosen Store kann ich die Daten auch erst ganz spät
normalisieren, möglicherweise erst wenn ich sie ausgelesen habe und nun
darstellen will.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;und meint dann:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Wenn ich Daten normalisiere, bevor ich sie in einen schemalosen Store
schreibe, dann sehe ich auch keinen wirklichen Vorteil gegenüber einer
SQL-Datenbank (modulo der von Dir erwähnten table locking
Implementationsdetails einiger spezieller Implementationen). Das
Haupt-Feature ist also IMHO genau die Möglichkeit, erst ganz spät zu
normalisieren, und dann hat man möglicherweise viel mehr Kontext, was man
mit den Daten überhaupt anfangen will.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ich arbeite möglicherweise zu lange mit SQL, denn ich habe Schwierigkeiten
mir vorzustellen, wieso das ein Vorteil ist. Also, genauer: Ich kenne
Anwendungsfälle, wo mich die interne Struktur der Daten nicht tangiert und
ich sie in SQL nicht ausmodellieren will - einfachstes Beispiel ist eine
Session-Tabelle, die im Grunde nur Tripel (sessionid, sessiondata, changed)
enthält, und bei der ich nie in die sessiondata hinein sehen will. In diesem
Fall ist es vollkommen in Ordnung, sessiondata als BLOB oder TEXT zu
modellieren und da ein serialize($_SESSION) abzuspeichern.&lt;/p&gt;
&lt;p&gt;Wenn ich aber strukturierte Sessions will, weil ich etwa Statistiken über
Artikel in aktiven Warenkörben erstellen möchte, dann ende ich
wahrscheinlich mit einer zweistufigen Hierarchie und Key-Value Tabellen oder
weiter ausstrukturieren Sessiontabellen. Allerdings sehe ich solche
Anwendungsfälle vielleicht eher in einem Bestell-Log als in einer
Session-Tabelle.&lt;/p&gt;
&lt;h2 id=&#34;zusammenfassung&#34;&gt;
    &lt;a href=&#34;#zusammenfassung&#34;&gt;
	Zusammenfassung
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Offenbar lag ich mit meinem Gefühl gar nicht so falsch: Das im Betrieb oft
unerträglich langsame ALTER TABLE von MySQL ist in der Tat ein stark
empfundenes Problem und motiviert Anwender stattdessen auf &amp;lsquo;schemalose&amp;rsquo;
Datenbanken zu setzen.&lt;/p&gt;
&lt;p&gt;Anwender von &amp;lsquo;schemalosen&amp;rsquo; Datenbanken haben ihr Schema stattdessen als Teil
von Bibliotheken in der Anwendung implementiert. Dabei variiert die
Codequalität recht stark, da keine &amp;lsquo;best practice&amp;rsquo; als Einbaufunktion von
der Datenbank bereitgestellt wird und auch keine
Standard-Bibliotheksfunktionen für diese Aufgabe von der Zugriffsbibliothek
für die entsprechende NoSQL-Datenbank bereitgestellt wird.&lt;/p&gt;
&lt;p&gt;Aus der Sicht des NoSQL-Produktes wird die Funktionalität also nicht vom
Server in den Client verlagert, sondern das Problem ignoriert und dem
Anwender zur Selbstimplementierung überlassen. Die Anwender durchdenken das
Problem dabei unterschiedlich stark und implementieren eine Lösung in der
Regel nur so weit als sie empirisch das Problem als dringlich zu empfinden
gelernt haben.&lt;/p&gt;
&lt;p&gt;Schemaprüfungen und formale Migrationen von einer früheren Version des
Schemas auf die aktuelle Version des Schemas sind dabei eher die Ausnahme.&lt;/p&gt;
&lt;p&gt;Viele NoSQL-Produkte, die über simple KV-Stores hinaus gehen, implementieren
hierarchische Datenstrukturen, die sich an dem relationalen Vorläufer IBM
IMS, an XML oder an LDAP orientieren. Dies ist dem Fehlen von
ausdrucksstarken Möglichkeiten mit Hierarchien und Bäumen in MySQL umzugehen
geschuldet.&lt;/p&gt;
&lt;p&gt;Andererseits fehlt in diesen NoSQL-Produkten in der Regel die Option,
Verweise aufzulösen ohne weitere Netzwerklatenzen zu generieren (Fehlen von
JOIN oder &amp;lsquo;deep reads&amp;rsquo;), sodaß man oft mit eingebetteten Dokumenten und
nicht-skalaren Daten arbeitet.&lt;/p&gt;
&lt;p&gt;Ich war verwirrt, weil einerseits NoSQL irgendwie der aktuelle Hype ist, ich
andererseits aber auf Konferenzen wie MongoBerlin letztes Jahr ein komisches
DejaVu hatte: Das Publikum dort fühlt sich an wie eine MySQL-Community von
2005.&lt;/p&gt;
&lt;p&gt;So weit korrekt, oder fehlt was?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Schemaless?</title>
      <link>https://blog.koehntopp.info/2011/04/19/schemaless.html</link>
      <pubDate>Tue, 19 Apr 2011 11:49:31 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2011/04/19/schemaless.html</guid>
      <description>&lt;h2 id=&#34;die-frage&#34;&gt;
    &lt;a href=&#34;#die-frage&#34;&gt;
	Die Frage:
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Ich brauche einmal Hilfe. Von Euch. Ich verstehe nämlich ein Konzept nicht.
Es geht um den Begriff &amp;ldquo;Schemaless&amp;rdquo;, der im Zusammenhang mit einigen
NoSQL-Datenbanken verwendet wird.&lt;/p&gt;
&lt;p&gt;Ich kann verstehen, daß für einige Leute ein ALTER TABLE wie in MySQL ein
Problem ist, weil es Tabellen während der Schemaänderung lockt. Da ALTER
TABLE in vielen Fällen die Daten zur Durchführung der Änderung umkopieren
muß, kann dieses Lock entsprechend lange bestehen bleiben, wenn die Daten
nur hinreichend groß sind.&lt;/p&gt;
&lt;p&gt;Ich kann nicht verstehen, wieso Leute glauben, daß &amp;ldquo;Schemaless&amp;rdquo; da eine
Hilfe wäre oder wieso Leute glauben, daß es so etwas wie &amp;ldquo;Schemaless&amp;rdquo;
überhaupt gibt.&lt;/p&gt;
&lt;p&gt;Daten in Datenbanken existieren ja in der Regel nicht im luftleeren Raum,
sondern sie werden von Code genutzt. Dieser Code macht Annahmen über die
Attribute, die in einer Tabelle (oder was immer Euer NoSQL als
Tabellenäquivalent verwendet) existieren dürfen oder müssen.&lt;/p&gt;
&lt;p&gt;Wie geht ihr damit um, wenn ihr &amp;ldquo;schemaless&amp;rdquo; arbeitet?&lt;/p&gt;
&lt;p&gt;Haben Eure Tabellen ein verpflichtendes Attribut &amp;ldquo;version&amp;rdquo;, und Euer Code
dann einen Getter/Setter, der die Version einer Row prüft und gegebenenfalls
überflüssige Attribute entfernt, fehlende Attribute mit Defaults ergänzt und
dann im Setter die Version auf den aktuellen Stand anpaßt? Wenn ja, wie ist
das &amp;ldquo;schemaless&amp;rdquo;? Ihr enforced ja ein Schema, und implementiert das ALTER
TABLE lazy, wie es in einigen Datenbanken gemacht wird, die nicht MySQL
sind.&lt;/p&gt;
&lt;p&gt;Wenn nein: Wie geht Euer Code stattdessen mit der Situation &amp;lsquo;fehlendes
Attribut&amp;rsquo; bzw. &amp;rsquo;nicht mehr gebrauchtes Attribut&amp;rsquo; um?&lt;/p&gt;
&lt;p&gt;Generell: Wie prüft Ihr Range und Validität von Daten in so einer Datenbank?&lt;/p&gt;
&lt;p&gt;Wäre es nicht sinnvoller, ALTER TABLE so anzupassen, daß es a) Indices im
Hintergrund erzeugt und b) Zufügen, Entfernen und Ändern von Spaltentypen
lazy implementiert wie oben geschildert?&lt;/p&gt;
&lt;p&gt;Bitte helft mir und diskutiert in den Kommentaren.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.koehntopp.info/2011/04/20/zusammenfassung-schemaless.html&#34;&gt;Die Antwort&lt;/a&gt;

 in einem späteren Artikel.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken zum Thema NoSQL</title>
      <link>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</link>
      <pubDate>Fri, 05 Nov 2010 06:41:00 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2010/11/05/ein-paar-gedanken-zum-thema-nosql.html</guid>
      <description>&lt;p&gt;Beim Durchstöbern der verschiedenen NoSQL-Datenspeicher stellt sich mir die
Frage, wieso man das alles überhaupt will. Genauer: Was genau ist das
Problem, das man mit NoSQL lösen möchte?&lt;/p&gt;
&lt;p&gt;Diejenigen Leute, die NoSQL-Lösungen einsetzen, haben in der Regel die
Schwierigkeit, daß ihre Datenmenge größer wird, als man auf einer einzelnen
Maschine mit der geforderten Servicequalität handhaben kann.&lt;/p&gt;
&lt;p&gt;Im Webbereich sind die Anforderungen für interaktives Browsen oft so, daß
man die gewünschten Antwortzeiten nur dann erreichen kann, wenn die dabei
verwendeten Datenbanken ihre Daten und Indices zum allergrößten Teil im RAM
halten können. Verfügbarkeit und Preis von Speicher sind aber Grenzen
gesetzt - mit aktuellen Nehalem-Kisten zum Beispiel liegt der Sweet-Spot
irgendwo bei 48G oder 96G Hauptspeicher, die Datenbankgröße für solche
zeitkritischen Systeme also nach meinen Erfahrungen zwischen 100G und 200G.&lt;/p&gt;
&lt;p&gt;Erst wenn Benutzer nicht mehr interaktiv browsend mit der Anwendung
interagieren kann man sich längere Antwortzeiten erlauben. Wird ein Schritt
zum Beispiel als &amp;ldquo;Buchung&amp;rdquo; angesehen, ist der Benutzer bereit, bis zu 10x
längere Reaktionszeiten hinzunehmen (2 Sekunden statt 0.2 Sekunden, ohne
Fortschrittsbalken, und bis zu 20 Sekunden mit einem Fortschrittsbalken).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/partition.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Partition visualisiert&lt;/p&gt;
&lt;p&gt;Gesucht ist also Technologie, die es mir erlaubt, ein Datenbankschema über
mehr als eine Maschine zu verteilen. Je weniger ich dabei in meiner
Anwendung davon sehe oder merke, um so schöner.&lt;/p&gt;
&lt;p&gt;Um ein großes Schema zu verteilen muß ich meine Daten partitionieren. Das
heißt, ich muß eine Menge (an Daten) in Teilmengen zerlegen, sodaß die
Teilmengen sich nicht überlappen und ihre Vereinigung wieder die Gesamtmenge
ergibt. Liegen die Teilmengen alle zusammen auf einer Maschine reden wir in
der Regel von einer Partition. Liegen sie auf verschiedenen Maschinen reden
wir in der Regel von Sharding (von Shard, Splitter).&lt;/p&gt;
&lt;p&gt;Die manuelle Vorgehensweise zum Sharding ist, ein Schema funktional zu
zerteilen. Dabei wird man alle Tabellen, die mit Funktionalität a zu tun
haben auf einen Server verlegem und alle Tabellen, die mit Funktionalität b
befaßt sind auf einen anderen Server. Das geht aber immer noch davon aus,
daß eine Tabelle zur Gänze auf einer einzelnen Maschine gehalten werden kann
und es setzt auch voraus, daß man sich Gedanken darüber macht, was man wie
warum wo hin schiebt. Der manuelle Ansatz hat den Vorteil, daß man mit
konventionellem Denken noch weiter kommt und auch konventionelle Abfragen
innerhalb einer Maschine noch wie erwartet funktionieren.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/sharding.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Automatisches Sharding&lt;/p&gt;
&lt;p&gt;Ansätze zum automatischen Sharding nehmen auf solche Dinge weniger
Rücksicht: Ich kann für jede Zeile jeder Tabelle auf irgendeine Weise eine
Maschinenadresse berechnen und den entsprechenden Datensatz dann auf diese
Maschine verschieben. Der automatische Ansatz hat den Vorteil, daß es keine
absoluten Skalierungslimits mehr gibt, sondern daß man die Datenmenge und
die Systemleistung &amp;ldquo;einfach&amp;rdquo; dadurch skalieren kann, daß man mehr Maschinen
zum Cluster hinzu fügt.&lt;/p&gt;
&lt;p&gt;Der automatische Ansatz hat auch einen Preis:&lt;/p&gt;
&lt;p&gt;Von den anderswo erklärten
&lt;a href=&#34;https://blog.koehntopp.info/2010/04/28/was-bedeutet-eigentlich-relationale-algebra.html&#34;&gt;Operationen der  Relationenalgebra&lt;/a&gt;


sind einige nun recht teuer geworden - der SQL-Join und die SQL-Aggregation.&lt;/p&gt;
&lt;p&gt;Für den Join stellt sich das Problem, daß man zwischen Tabellen eine
Verknüpfung erzeugen will, die zur Gänze oder in Teilen auf
unterschiedlichen Maschinen in einem Cluster liegen können. Je nachdem
welcher
&lt;a href=&#34;http://en.wikipedia.org/wiki/Category:Join_algorithms&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Join-Algorithmus&lt;/a&gt;


verwendet wird, kann dabei sehr viel Netzwerk-Kommunikation notwendig
werden.&lt;/p&gt;
&lt;p&gt;Das gilt um so mehr, wenn wir uns in Erinnerung rufen, daß wir dieses ganze
Sharding-Geschäft angefangen haben damit wir alle Daten im Speicher halten
können - Netzwerk-Latenzen werden also leicht die dominierenden Kosten bei
der Berechnung eines Joins
(&lt;a href=&#34;http://www.fromdual.ch/wie-der-mysql-optimizer-schummelt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;typisches Beispiel&lt;/a&gt;

 für die
Probleme bei einem Join über das Netz in MySQL Cluster).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/condition_pushdown.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Condition Pushdown&lt;/p&gt;
&lt;p&gt;MySQL Cluster und VoltDB sind beides Produkte, die immerhin versuchen,
einen Join über das Netz durchzuführen, und der Ansatz ist vergleichbar:
Anstatt die Daten zu dem Knoten zu transferieren, der den Join ausführt,
werden Teile der Query extrahiert und zu den Daten transportiert. MySQL
Cluster versucht das dynamisch und automatisch zu machen und nennt das
Condition Pushdown
(&lt;a href=&#34;http://johanandersson.blogspot.com/2010/10/pushed-down-joins-webinar.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Webinar zu MySQL Cluster Condition Pushdown&lt;/a&gt;

,
&lt;a href=&#34;http://blogs.oracle.com/mysql/2010/10/in_pursuit_of_the_holy_grail_-_mysql_cluster_and_push_down_joins.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;In Pursuit Of The Holy Grail&lt;/a&gt;

,
über Condition Pushdown in Cluster). VoltDB verlangt stattdessen, daß das
statisch und vorab gemacht wird: Die Entwickler müssen alle Abfragen als
Stored Procedures in Java schreiben und zur Laufzeit werden dann nur noch
Stored Procedures abgerufen.&lt;/p&gt;
&lt;p&gt;Im recht uneinheitlichen Bereich der NoSQL-Nondatenbanken hat man im
wesentlichen zwei Ansätze um mit dem Problem umzugehen. Für die untere
Schicht der NoSQL-Datenbanken (&amp;ldquo;Key Value Stores&amp;rdquo;) besteht die Lösung
schlicht darin, das Problem zu ignorieren, äh, dem Anwendungsprogrammierer
zur freien Modellierung zu überlassen. In der Praxis kommen dann zwei
Ansätze vor, die der Anwendungsprogrammierer verwendet um eine Lösung zu
modellieren.&lt;/p&gt;
&lt;p&gt;Der eine Ansatz programmiert das Äquivalent eines Full Table Scans in der
Anwendung nach, d.h. um die gesuchten Daten zu finden wird die gesamte
Datenbank in die Anwendung runtergeladen und der nicht gewünschte Teil der
Daten verworfen. Diese Lösung wird vor allen Dingen von den Anbietern von
Netzwerkequipment favorisiert.&lt;/p&gt;
&lt;p&gt;Der andere Ansatz nimmt den Join vorweg, d.h. er speichert als Teil des
Value jedes Key-Value Paares ein Array von Zeigern auf die verknüpften
Knoten. Lädt man den Ausgangsknoten runter, bekommt man mit dem Zeigerarray
auch eine Liste von Referenzen, denen man folgen kann, um die verknüpften
Daten zu finden.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/Network_Model.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Network Model (&lt;a href=&#34;http://en.wikipedia.org/wiki/File:Network_Model.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quelle&lt;/a&gt;

)&lt;/p&gt;
&lt;p&gt;Automatisiert man das und das Handhaben der Backreferences, hat man eine
Zeitreise in das Jahr 1969 durchgeführt und
&lt;a href=&#34;http://en.wikipedia.org/wiki/Network_database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMS&lt;/a&gt;

 neu erfunden
(ersatzweise auch eine XML-Datenbank oder LDAP erfunden). Immerhin ist es
jetzt verteilt.&lt;/p&gt;
&lt;p&gt;In den NoSQL-Datenbanken, die ein wenig mehr Struktur in den Daten
unterbringen findet man nun entweder solche Mechanismen, die Referenzen auf
Daten und ihre Backreferences automatisieren, d.h die sogenannten
Dokumentendatenbanken sind in Wahrheit Netzwerkdatenbanken.&lt;/p&gt;
&lt;p&gt;Oder man arbeitet mit Dokumenten und Subdokumenten, speichert also statt
Zeigern auf Objekte erster Ordnung (Dokumente) jetzt einfach die Objekte
selbst literal in den ihnen übergeordneten Objekten (man speichert
Subdokumente in Dokumenten). Das ist noch schlechter, weil man damit
zugleich hybride, nicht-opake und nicht stabile Identifier bekommt, wenn man
mit Subdokumenten arbeitet: Statt das Dokument 17 (Subdokument von 3) direkt
über seine ID referenzieren zu können (egal wie es in 3 verschachtelt ist
oder ob es in 3 und in 5 gleichermaßen referenziert wird), redet man jetzt
von 3.owner.name[2], also dem zweiten Element des Arrays Name unterhalb des
Slots owner des Dokumentes 3.&lt;/p&gt;
&lt;p&gt;Das ist eine Pfadabgabe (etwa eine XPath-Expression) relativ zur Wurzel des
Dokumentes mit der ID 3, und nicht stabil: Werden Elemente vorne in das
Array name eingefügt, oder wird der Typ des Slot owner verändert (der Skalar
owner wird zu einem Array owner[], sodaß es jetzt 3.owner[1].name[2] heißen
muß) oder der Nestinglevel von owner geändert, ist die Referenz ungültig.
Und das Subdokument kann nicht von zwei Dokumenten 3 und 5 zugleich
referenziert werden, da es literal Bestandteil von entweder 3 oder 5 ist.&lt;/p&gt;
&lt;p&gt;Kurzum: Man kann nicht sinnvoll normalisieren, weil man nicht sinnvoll
addressieren kann.&lt;/p&gt;
&lt;p&gt;Das ist Teil eines größeren Problems:
&lt;a href=&#34;http://highscalability.com/blog/2010/10/28/nosql-took-away-the-relational-model-and-gave-nothing-back.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NoSQL Took Away The Relational Model And Gave Nothing Back&lt;/a&gt;

:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The meaning of the statement was that NoSQL systems (really the various
map-reduce systems) are lacking a standard model for describing and
querying and that developing one should be a high priority task for them.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Unterdessen (nein: deswegen!) nähern sich SQL- und NoSQL auf eine Weise auch
wieder einander an. Weil SQL eine sinnvolle Sache ist, gibt es
&lt;a href=&#34;http://jaksprats.wordpress.com/2010/09/28/introducing-redisql-the-lightning-fast-polyglot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Redisql&lt;/a&gt;

,
einen SQL-Interpreter, der quasi den KV-Store Redis als Storage Engine
verwendet.&lt;/p&gt;
&lt;p&gt;Und es gibt
&lt;a href=&#34;http://yoshinorimatsunobu.blogspot.com/2010/10/using-mysql-as-nosql-story-for.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HandlerSocket&lt;/a&gt;

,
ein Plugin für MySQL, das das MySQL Sonderkommando
&lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/handler.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HANDLER&lt;/a&gt;

 mit einem
binären Netzwerkinterface ohne Authentisierung ausstattet und so Key-Value
Zugriffe und Index-Traversal sehr effizient verfügbar macht, solange die
Daten im RAM liegen (oder
&lt;a href=&#34;http://www.mysqlperformanceblog.com/2010/11/02/handlersocket-on-ssd/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;auf einer SSD&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Neben diesem echten harten Problem von JOIN und GROUP BY über das Netz gibt
es eine Reihe von weiteren Schwächen in MySQL und einigen anderen
SQL-Implementierungen, die von einigen NoSQL-Implementierungen angesprochen
werden und die meiner Meinung zu falschen oder gefährlichen Ansätzen führen.&lt;/p&gt;
&lt;p&gt;Das bekannteste Beispiel ist das
&lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/alter-table.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ALTER TABLE&lt;/a&gt;


Statement in MySQL, das auch in MySQL 5.1 in vielen Fällen noch sehr lange
dauert und alle Operationen auf der Tabelle blockiert, während es abläuft.
Das Thema ist drängend und die Komplexität der Workarounds
&lt;a href=&#34;http://www.facebook.com/note.php?note_id=430801045932&amp;amp;comments&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;grenzt an das Lächerliche&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;ALTER TABLE wird entweder verwendet, um die Indices einer Tabelle zu
verändern oder um die Struktur einer Tabelle zu verändern. Die korrekte
Lösung des Problems ist einerseits
&lt;a href=&#34;http://dev.mysql.com/doc/innodb-plugin/1.0/en/innodb-create-index-overview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Background Index Creation&lt;/a&gt;


(aber &lt;a href=&#34;http://dev.mysql.com/doc/innodb-plugin/1.0/en/innodb-create-index-limitations.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;es gibt viele Einschränkungen&lt;/a&gt;

),
wenn es um Indices geht.&lt;/p&gt;
&lt;p&gt;Oder es ist eine versionierte Tabellendefinition, wenn es um die
Tabellenstruktur geht - statt das ALTER TABLE auszuführen, wird eine neue
Version der Tabellendefinition angelegt. An jeder Row wird die
Versionsnummer der Tabellendefinition gespeichert, der die Row entspricht.
Beim Zugriff auf die Row werden die Daten gelesen und entsprechend der ALTER
TABLE-Anweisungen, die fehlen, auf den neusten Stand gebracht (ebenso alle
anderen Rows in derselben Page). Die Speicherseite ist nun &amp;lsquo;dirty&amp;rsquo; und wird
mit dem nächsten Checkpoint auf der Platte aktualisiert. Das ermöglicht
zugleich
&lt;a href=&#34;http://wiki.postgresql.org/wiki/Transactional_DDL_in_PostgreSQL:_A_Competitive_Analysis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Transactional DDL&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Was die meisten NoSQL-Nondatenbanken stattdessen machen ist schemalessness
zu propagieren. Dabei werden oftmals
&lt;a href=&#34;http://nosql.mypopescu.com/post/949327075/why-your-startup-should-use-a-schema-less-database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eigenartige Schlußfolgerungen&lt;/a&gt;


gezogen:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Avoiding schema changes and data migration are good reasons.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Die Folgerung &amp;ldquo;Aus Schemalessness folgt, daß man Schema Changes und
Datenmigration vermeiden kann&amp;rdquo; ist offensichtlicher Unsinn, wie jeder
erkennen kann, der einmal reale Anwendungen entwickelt hat - die Migration
wird nun jedoch wieder einmal dem Anwendungsprogrammierer zur Modellierung
in der Anwendung überlassen.&lt;/p&gt;
&lt;p&gt;Das heißt, man implementiert nun das &amp;lsquo;Transactional DDL&amp;rsquo;-Modell von oben in
der Anwendung nach: Jeder Datensatz bekommt eine Versionsnummer und der ORM
prüft beim Lesen jedes Satzes, ob die Versionsnummer auf Stand ist, und wenn
nicht, wendet er die notwendigen Transformationen auf das gelesene Objekt
an. Beim Zurückschreiben der Daten wird das aktuelle Datenmodell mit der
höchsten Versionsnummer geschrieben.&lt;/p&gt;
&lt;p&gt;Oder man tut das nicht, und verläßt sich auf obskure Defaults der verwendeten Plattform
(&lt;a href=&#34;http://blog.mongodb.org/post/119945109/why-schemaless&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MongoDB Blog Beispiel&lt;/a&gt;

 und die
Diskussion unten dran kommt zu demselben Schluß wie ich hier).&lt;/p&gt;
&lt;p&gt;Was also sucht man, wenn man sich mit NoSQL beschäftigt?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Workarounds für existierende Limits in der Implementierung von MySQL - das
führt in der Regel zu wenig sinnvollen Ergebnissen.&lt;/li&gt;
&lt;li&gt;Techniken, mit denen man Wachstum über die Grenzen einer einzelnen
Maschine hinaus besser in den Griff bekommen kann:
&lt;ul&gt;
&lt;li&gt;Sharding und Replikation weiter denken.&lt;/li&gt;
&lt;li&gt;Das Problem des Joins und der Aggregation in diesen Szenarien angehen.&lt;/li&gt;
&lt;li&gt;Lösungen dafür existieren, ob man sie nun Condition Pushdown oder
Map-Reduce nennt - beides ist sehr ähnlich.&lt;/li&gt;
&lt;li&gt;Ich erwarte, daß Autosharding und verteilte Ausführung von SQL, hinter
den Kulissen mit Map-Reduce/Condition Pushdown, in absehbarer Zeit
Bestandteil von Open Source SQL-Produkten werden.&lt;/li&gt;
&lt;li&gt;Ich erwarte, daß auch damit die Effekte, die sich aus der Verteilung des
Systems ergeben nicht vollständig in allen Fällen vor dem Endanwender
verborgen werden können.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Die relationale Datenbank wird 40.</title>
      <link>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</link>
      <pubDate>Tue, 08 Jun 2010 06:15:00 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2010/06/08/die-relationale-datenbank-wird-40.html</guid>
      <description>&lt;p&gt;Nicht nur wird PHP im Juni 15 Jahre alt, sondern ein anderer, älterer
Begleiter von PHP feiert ebenfalls ein Jubiläum:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Im Juni 1970&lt;/a&gt;


erschien in den Communications of the ACM der Artikel
&amp;ldquo;&lt;a href=&#34;http://www.google.de/search?q=a&amp;#43;relational&amp;#43;model&amp;#43;for&amp;#43;large&amp;#43;shared&amp;#43;data&amp;#43;banks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Relational Model of Data for Large Shared Data Banks&lt;/a&gt;

&amp;rdquo;
von E.F.Codd. Dieser Artikel ist die theoretische Grundlage für das, was
später SQL und relationale Datenbanken werden sollte.&lt;/p&gt;
&lt;p&gt;Seitdem MySQL und PHP vor 15 Jahren ausgezogen sind, das Web zu
revolutionieren, ist SQL eine Haushaltssprache geworden - es ist inzwischen
echt schwierig, Webspace zu kaufen, bei dem man nicht auch Zugriff auf eine
MySQL-Datenbank hat, und entsprechend gehen HTML-, PHP- und SQL-Kenntnisse
inzwischen einher.&lt;/p&gt;
&lt;p&gt;Andererseits gibt es Dinge, bei denen SQL an seine Grenzen stößt. Seit
einigen Jahren gibt es unter dem Begriff
&lt;a href=&#34;http://www.pythian.com/news/9387/liveblogging-at-confoo-blending-nosql-and-sql/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NoSQL&lt;/a&gt;


eine Sammlung von Werkzeugen, die mit persistentem Storage anders umgehen
als Codd sich das gedacht hat. Dabei geht es im Kern um Systeme, die
BASE statt ACID im Sinne von Codd sind, aber viele Entwickler sind gerade dabei,
Systeme zu bauen, die auch die guten Errungenschaften von SQL mit über Bord
werfen.&lt;/p&gt;
&lt;p&gt;Ohne eine besseren theoretischen Unterbau wird NoSQL kaum zu standardisieren
und weiter zu entwickeln sein.&lt;/p&gt;
&lt;p&gt;Eines der ältesten strukturellen Probleme von SQL und relationaler Algebra
ist die Schwierigkeit mit hierarchischen bzw. selftreferentiellen Daten
umzugehen. Neben Zeiger- und Pfadbäumen gibt es noch
&lt;a href=&#34;http://kris.koehntopp.de/artikel/sql-self-references/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;das Nested Set&lt;/a&gt;

-Modell, aber
alle drei Ansätze sind recht unhandlich und wenig elegant in der Nutzung.&lt;/p&gt;
&lt;p&gt;Verwandt damit ist das Problem, objektorientierte Vererbungsstrukturen auf
SQL-Speicher abzubilden. Ein - im übrigen brillianter und dringend
lesenswerter - Artikel beschriebt Objekt-Relationales Mapping (ORM) als
&lt;a href=&#34;http://blogs.tedneward.com/2006/06/26/The&amp;#43;Vietnam&amp;#43;Of&amp;#43;Computer&amp;#43;Science.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;das Vietnam der Informatik&lt;/a&gt;

.
Das trifft den Sachverhalt recht gut. Die Antwort von NoSQL auf dieses
Problem sind schema-freie Datenbanken, aber das ist ungefähr zu gleichen
Teilen Lösung wie Problem und sicherlich nicht unbedingt ein Fortschritt.&lt;/p&gt;
&lt;p&gt;Webanwendungen haben außerdem ungewöhnliche Anforderungen an Datenbanken und
andere Systeme: Die sind sehr read-heavy und dabei ist die absolute Anzahl
der Lesezugriffe bei populären Webanwendungen in der Regel so groß, daß es
keine einzelne Maschine gibt -
&lt;a href=&#34;https://blog.koehntopp.info/2007/08/11/zehn-zentimeter.html&#34;&gt;geben kann!&lt;/a&gt;

 -
die in der Lage ist, die Last zu stemmen. Man braucht mehr als eine Kiste,
unter Umständen gar tausende von Maschinen. Daher blickt man zwangsläufig
auf verteilte, asynchrone Systeme und damit das oben erwähnte BASE, und man
braucht um seine Algorithmen verteilen zu können, eine Form von
&lt;a href=&#34;http://en.wikipedia.org/wiki/MapReduce&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Map-Reduce&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;In Webanwendungen ist es außerdem wegen des starken Übergewichtes von
Lesezugriffen sinnvoll, seine Daten um diese Lesezugriffe herum zu
strukturieren und sie nicht auf die für Schreibzugriffe optimierte
&lt;a href=&#34;http://en.wikipedia.org/wiki/3NF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3NF&lt;/a&gt;

 zu bringen. Datenspeicher von
Webanwendungen sind also in der Regel schwer denormalisiert.&lt;/p&gt;
&lt;p&gt;Aus diesen Anforderungen rührt also die Grundsätze von NoSQL:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Denormalization&lt;/li&gt;
&lt;li&gt;Verteilte Systeme mit Eventual Consistency (BASE)&lt;/li&gt;
&lt;li&gt;Schema-Freiheit&lt;/li&gt;
&lt;li&gt;Horizontale Skalierbarkeit mit Map-Reduce&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die meisten NoSQL-Systeme versuchen, diese Grundsätze technisch umzusetzen,
vergessen dabei aber die Grundsätze von Codd - und bauen so Systeme, die auf
eine andere Weise nicht weniger schlecht sind als SQL-Datenbanken.&lt;/p&gt;
&lt;p&gt;SQL leistet nämlich dank der Arbeit von Codd eine ganze Reihe von wertvollen
Diensten, die jedoch von NoSQL-Systemen nicht oder nur unzureichend
umgesetzt werden.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/mapreduce.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;NoSQL-Systeme sind nicht deklarativ.&lt;/p&gt;
&lt;p&gt;Einmal kapselt SQL als deklarative Sprache den Datenzugriff vom prozeduralen
Code ab: In SQL sagt man nicht, wie die Daten geholt werden sollen, sondern
welche Daten man haben möchte. Es ist die Aufgabe der Datenbank, einen Plan
zu erarbeiten, mit dessen Hilfe der Datenzugriff effizient erfolgt. Der
SQL-Programmierer sagt also nicht: Öffne diesen Index, suche den Record x,
und dann steppe von dort aus durch den Index - für jeden gefundenen Record
mache damit einen Lookup in y und verbinde die beiden Strukturen, dann
filtere mit der Bedingung b. Sondern ein SQL-Programmierer sagt: Ich möchte
Daten, die die folgenden Bedingungen erfüllen, sieh zu wie Du sie bekommst.
Dadurch wird das Programm, in das der SQL-Code eingebettet wird, in großem
Maß von dem Datenspeicher unabhängig und es wird sehr leicht, Datenspeicher
und Programm teilweise voneinander unabhängig zu entwickeln und den
Datenspeicher mit verschiedenen Programmen gemeinsam zu nutzen.&lt;/p&gt;
&lt;p&gt;SQL ist dabei eine recht reiche Sprache: Da SQL eine Algebra auf diskreten
Relationen (= Tabellen) ist, operieren alle SQL-Befehle auf Tabellen und
haben wieder Tabellen als Ergebnis. Durch die verschiedenen Arten von
Subqueries kann man damit SQL-Befehle miteinander verketten und so mit den
Ergebnissen von SQL-Befehlen weiter rechnen. Die meisten anderen
Abfragesprachen (LDAP, XPath, und viele NoSQL-Abfrage&amp;quot;sprachen&amp;quot;) sind keine
Algebren und erlauben keine derartige Verknüpfung von Abfragen. Das zwingt
den Entwickler, Anfragen in Schleifen in Code zu gießen und dann entweder im
Client auszuführen (hohe Latenz) oder generierten Code an die Datenbank zur
Ausführung zu senden. Dadurch findet man nun wieder eine sehr viel engere
Kopplung von Code und Datenspeicher - ändern sich Zugriffschemata,
Tabellendefinitionen oder andere Dinge, muß Code angepaßt und die Anwendung
neu übersetzt werden, Queries werden als Code mit Schleifen und
Filterbedingungen geschrieben. Die Form des Codes ist dabei abhängig davon,
welche Zugriffshilfen in Form von Indices im Datenspeicher existieren - eine
SQL-Query ist in der Form (nicht jedoch in der Performance) unabhängig von
den existierenden möglichen Zugriffspfaden.&lt;/p&gt;
&lt;p&gt;Zum Teil geht das so weit, daß man zu den Fehlern und Problemen
hierarchischer Datenspeicher zurückfällt: Sind Daten als Graph oder Baum
gespeichert, dann definieren die Kanten im Graphen die festen möglichen
Zugriffspfade und Abfragen. Speichert man etwa in einer Personaldatenbank
Personen und das ihnen zugeordnete Inventar, dann kann man Inventar pro
Person leicht finden, aber es ist sehr viel teurer, alle Personen zu finden,
die eine bestimmte Sorte Werkzeug/Inventar verwenden.&lt;/p&gt;
&lt;p&gt;Wenn mehrere Anwendungen einen Datenspeicher gemeinsam nutzen entsteht das
Problem, daß man Datenintegrität und Zugriffsregeln aus der konkreten
Anwendung in eine von allen Anwendungen gemeinsam genutzte Filterschicht
abstrahieren möchte. In tradionellem SQL sind das Datentypen, Views,
Integrity-Constraints, Rules und Trigger, die Integritätsbedingungen werden
also Teil des Datenmodells. Im Ansatz meines Arbeitgebers existiert eine
Bibliotheksschicht, die Datenbankzugriffe abfängt und filtert - die
Integritätsbedingungen sind also Teil der Systembibliotheken. In den meisten
NoSQL-Systemen befaßt man sich mit dem Problem nicht und überläßt es dem
Anwender, damit klar zu kommen.&lt;/p&gt;
&lt;p&gt;Gesucht ist ein &amp;lsquo;NoSQL&amp;rsquo;-System (also eines, das die o.a. genannten vier
Eigenschaften hat), das die Vorteile von SQL nicht aufgibt.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
