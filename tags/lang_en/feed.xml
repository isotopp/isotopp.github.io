<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lang_en on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/lang_en.html</link>
    <description>Recent content in lang_en on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Dec 2023 12:29:54 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/lang_en/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>x86_64 binaries on M1</title>
      <link>https://blog.koehntopp.info/2023/12/05/x86_64-binaries-on-m1.html</link>
      <pubDate>Tue, 05 Dec 2023 05:06:07 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/12/05/x86_64-binaries-on-m1.html</guid>
      <description>&lt;p&gt;I installed a Python 2.7.18 with &lt;code&gt;pyenv&lt;/code&gt; on Apple Silicon,
and I needed that binary to be pure &lt;code&gt;x86_64&lt;/code&gt;.
This was necessary because I needed to load dynamic libraries that were only available in Intel format.&lt;/p&gt;
&lt;p&gt;It is not possible to load &lt;code&gt;x86_64&lt;/code&gt; libraries into an ARM binary.
If you build a multi-arch binary, you need to remember to request Intel every time you run a Python script
which tries to load the Intel-only shared library.
With an Intel-only binary, this will work every time without additional configuration.&lt;/p&gt;
&lt;h1 id=&#34;calling-the-intel-code-in-a-multi-architecture-binary&#34;&gt;
    &lt;a href=&#34;#calling-the-intel-code-in-a-multi-architecture-binary&#34;&gt;
	Calling the Intel code in a multi-architecture binary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;file&lt;/code&gt; command will tell you if a binary is multi-architecture:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; file /bin/ls
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/bin/ls: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit executable x86_64] [arm64e:Mach-O 64-bit executable arm64e]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/bin/ls (for architecture x86_64):	Mach-O 64-bit executable x86_64
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/bin/ls (for architecture arm64e):	Mach-O 64-bit executable arm64e
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can manually call the Intel code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; arch -arch x86_64 ls
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Applications		Movies		Music
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you call a binary this way, the first time this will trigger the installation of Rosetta2
(the Intel to ARM JIT compiler) on the Mac.&lt;/p&gt;
&lt;h1 id=&#34;compiling-for-intel-on-m1&#34;&gt;
    &lt;a href=&#34;#compiling-for-intel-on-m1&#34;&gt;
	Compiling for Intel on M1
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;By default, we compile for ARM (M1), and only for this architecture:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; cat hello.c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;int main(void) {
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;	printf(&amp;#34;Hello!\n&amp;#34;);
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; cc -o hello hello.c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; file hello
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;hello: Mach-O 64-bit executable arm64
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can call the compiler for Intel, and get an Intel-only binary:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; arch -arch x86_64 cc -o hello hello.c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; file hello
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;hello: Mach-O 64-bit executable x86_64
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; ./hello
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Hello!
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;compiling-python-for-intel-only&#34;&gt;
    &lt;a href=&#34;#compiling-python-for-intel-only&#34;&gt;
	Compiling Python for Intel only
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;pyenv&lt;/code&gt; installation process uses &lt;code&gt;python-build&lt;/code&gt;.
This, by default, uses the &lt;code&gt;readline&lt;/code&gt; and &lt;code&gt;openssl&lt;/code&gt; versions provided by Homebrew to build.
On my system, these are for ARM, so the Python will build and then fail in the linker stage.&lt;/p&gt;
&lt;p&gt;There is an option to force a build ignoring the Homebrew-provided components, &lt;code&gt;PYTHON_BUILD_SKIP_HOMEBREW&lt;/code&gt;.
This is a boolean variable: it is sufficient to set it to any value.
So:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;kk:~ kris$ PYTHON_BUILD_SKIP_HOMEBREW=1 arch -arch x86_64 pyenv install 2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Downloading openssl-1.1.1v.tar.gz...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-&amp;gt; https://www.openssl.org/source/openssl-1.1.1v.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installing openssl-1.1.1v...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installed openssl-1.1.1v to /Users/kris/.pyenv/versions/2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Downloading readline-8.0.tar.gz...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-&amp;gt; https://ftpmirror.gnu.org/readline/readline-8.0.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installing readline-8.0...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installed readline-8.0 to /Users/kris/.pyenv/versions/2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Downloading Python-2.7.18.tar.xz...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-&amp;gt; https://www.python.org/ftp/python/2.7.18/Python-2.7.18.tar.xz
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installing Python-2.7.18...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;patching file configure
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;patching file configure.ac
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;patching file setup.py
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installed Python-2.7.18 to /Users/kris/.pyenv/versions/2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is indeed the desired binary:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; file ~/.pyenv/versions/2.7.18/bin/python2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/Users/kris/.pyenv/versions/2.7.18/bin/python2: Mach-O 64-bit executable x86_64
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;building-a-virtualenv-for-intel-python-2718&#34;&gt;
    &lt;a href=&#34;#building-a-virtualenv-for-intel-python-2718&#34;&gt;
	Building a &lt;code&gt;virtualenv&lt;/code&gt; for Intel Python 2.7.18
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The virtual environment for Python 2.7 has to be built with an old version of the &lt;code&gt;virtualenv&lt;/code&gt; command,
which is compatible with the old Python:&lt;/p&gt;
&lt;p&gt;We make a &lt;code&gt;testdir&lt;/code&gt;, enter it and set the local Python version to the required version.
We then install an old version of the &lt;code&gt;virtualenv&lt;/code&gt; command, using &lt;code&gt;pip&lt;/code&gt;, globally into the old Python version.
This can then be used to create a virtual environment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; mkdir testdir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; testdir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; pyenv &lt;span class=&#34;nb&#34;&gt;local&lt;/span&gt; 2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; python --version
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Python 2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; which python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/Users/kris/.pyenv/shims/python
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now the installation of &lt;code&gt;virtualenv&lt;/code&gt; into our Python 2.7.18 instance:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; pip --version
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;pip 19.2.3 from /Users/kris/.pyenv/versions/2.7.18/lib/python2.7/site-packages/pip (python 2.7)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; pip install --user virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We now can call this version of &lt;code&gt;virtualenv&lt;/code&gt; for installation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; archaeology
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; ~/.local/bin/virtualenv venv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;created virtual environment CPython2.7.18.final.0-64 in 102ms
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;(venv) kk:testdir kris$ python --version
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Python 2.7.18
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;(venv) kk:testdir kris$ python
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Python 2.7.18 (default, Dec  5 2023, 12:09:45)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;[GCC Apple LLVM 15.0.0 (clang-1500.0.40.1)] on darwin
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;profit&#34;&gt;
    &lt;a href=&#34;#profit&#34;&gt;
	Profit!
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;And that gives us an ancient Python in a foreign machine language, so we can continue with our
software archaeology project.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;(venv) $ arch -arch x86_64 pip install cx_Oracle==7.3
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Collecting cx_Oracle==7.3
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Successfully built cx-Oracle
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Installing collected packages: cx-Oracle
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Successfully installed cx-Oracle-7.3.0
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that this will still need an &lt;code&gt;ORACLE_HOME&lt;/code&gt; pointing to your instantclient directory,
and the &lt;code&gt;dylib&lt;/code&gt; files linked from the Python libdir to the instantclient installation.&lt;/p&gt;
&lt;p&gt;So:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ORACLE_HOME=~/instantclient*
$ echo &amp;#34;export ORACLE_HOME=$ORACLE_HOME&amp;#34; &amp;gt;&amp;gt; ~/.bash_profile

$ cd ~/.pyenv/versions/2.7.18/lib
$ for i in ~/instantclient*/*.dylib*; 
&amp;gt; do
&amp;gt;   echo $i; 
&amp;gt;   ln -s $i .
&amp;gt; done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the proper &lt;code&gt;~/instantclient*/network/admin/TNSNAMES.ORA&lt;/code&gt; you can now&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;(venv) $ python2
...
&amp;gt;&amp;gt;&amp;gt; import cx_Oracle
&amp;gt;&amp;gt;&amp;gt; c = cx_Oracle.Connection(&amp;#34;sys&amp;#34;, &amp;#34;oracle&amp;#34;, &amp;#34;ORCL&amp;#34;)
&amp;gt;&amp;gt;&amp;gt; c
&amp;lt;cx_Oracle.Connection to sys@ORCL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>A Revolution Devours Its Children</title>
      <link>https://blog.koehntopp.info/2023/11/11/a-revolution-devours-its-children.html</link>
      <pubDate>Sat, 11 Nov 2023 05:06:07 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/11/11/a-revolution-devours-its-children.html</guid>
      <description>&lt;p&gt;Initially published in c&amp;rsquo;t 26/23, page 70.
All my texts are made available in this blog after some time.
The version shown is the raw edit of the article text without pictures and illustrations.&lt;/p&gt;
&lt;p&gt;Hier ist das Original &lt;a href=&#34;https://blog.koehntopp.info/2023/11/11/eine-revolution-frisst-ihre-kinder.html&#34;&gt;in deutscher Sprache&lt;/a&gt;

.&lt;/p&gt;
&lt;h1 id=&#34;a-revolution-devours-its-children&#34;&gt;
    &lt;a href=&#34;#a-revolution-devours-its-children&#34;&gt;
	A Revolution Devours Its Children
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;by Kristian Köhntopp&lt;/p&gt;
&lt;h2 id=&#34;departure-from-traditional-open-source-licenses&#34;&gt;
    &lt;a href=&#34;#departure-from-traditional-open-source-licenses&#34;&gt;
	Departure from Traditional Open Source Licenses
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Open source once set out to guarantee users the greatest possible freedom in the operation of software and to challenge the software titans.
Meanwhile, however, these have learned to use the documented freedoms to their advantage.&lt;/p&gt;
&lt;p&gt;There is unrest in the open-source community: In recent times,
it can be observed that established software companies with a large user base are restricting the freedoms of their users by
changing licenses of their open source projects.
The most recent example is HashiCorp, a company specialized in software for cloud infrastructure,
which has placed its core products under the BSL v1.1 (Business Source License), a formally non-open license.
The response was immediate:
the software has since been forked as OpenTofu and is now under the auspices of the Linux Foundation.&lt;/p&gt;
&lt;p&gt;HashiCorp is not the first company to do this: some time ago,
RedHat changed the positioning of CentOS as a free alternative to RedHat Enterprise Linux (RHEL)
and recently restricted the release of the RHEL source codes through an EULA (End User License Agreement),
Elastic has put ElasticSearch and Kibana under the formally non-open SSPL (Server Side Public License),
and MongoDB is also only available under the SSPL.&lt;/p&gt;
&lt;h2 id=&#34;four-freedoms-and-a-certification&#34;&gt;
    &lt;a href=&#34;#four-freedoms-and-a-certification&#34;&gt;
	Four Freedoms and a Certification
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Open Source and Free Software existed even before these terms were coined.
However, the actual &amp;ldquo;Open Source Revolution&amp;rdquo; began in the 1990s with the Linux kernel and the resulting distributions.
The term &amp;ldquo;Open Source&amp;rdquo; was coined by Bruce Perens and Eric Raymond,
formalized in the Open Source Definition and the Debian Free Software Guidelines.&lt;/p&gt;
&lt;p&gt;Both are refinements and clarifications of the original &amp;ldquo;Four Freedoms&amp;rdquo; in the mother of all open-source licenses,
the GNU General Public License (GPL), which are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Freedom 0: The freedom to run the program for any purpose.&lt;/li&gt;
&lt;li&gt;Freedom 1: The freedom to study how the program works and adapt it to your data processing needs.
This implies access to the source code.&lt;/li&gt;
&lt;li&gt;Freedom 2: The freedom to redistribute the program.
However, the GPL requires that the source code of the program, which corresponds to the redistributed program, is also offered.&lt;/li&gt;
&lt;li&gt;Freedom 3: The freedom to improve the program and distribute these improvements under the original license.
This also implies access to the source code and the right to modify it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the GPLv2 is the license that first codified these freedoms,
a whole range of licenses quickly developed that are all &amp;ldquo;Open Source&amp;rdquo;
according to the OSI guidelines (Open Source Initiative) or the DFSG (Debian Free Software Guidelines),
all of which are free but some are incompatible with the GPL.
This, in particular, filled many Usenet newsgroups with ongoing discussions throughout the late 90s.&lt;/p&gt;
&lt;h2 id=&#34;the-lamp-stack-a-wild-mix-of-licenses&#34;&gt;
    &lt;a href=&#34;#the-lamp-stack-a-wild-mix-of-licenses&#34;&gt;
	The LAMP Stack: A Wild Mix of Licenses
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The well-known LAMP stack for web development is also an example of the license confusion that can occur with open source.
LAMP includes the Linux Kernel, the Apache web server, the MySQL database, and the PHP programming language.
Each of these components has different licenses.&lt;/p&gt;
&lt;p&gt;While the Linux Kernel is licensed under GPLv2, the Apache web server is under Apache License 2.
This is a permissive license,
meaning it lacks provisions that enforce changes to the original program to be distributed under the same license as the original program.&lt;/p&gt;
&lt;p&gt;MySQL has two licenses:
The database can be used under the GPL, subject to the provisions and freedoms mentioned above.
However, the copyright holder is a company (originally MySQL, then SUN, and now Oracle) that holds all rights.
Developers must assign the rights to their patches to Oracle via a Contributor License Agreement (CLA).
This allows Oracle to also offer the source code under a commercial license.&lt;/p&gt;
&lt;p&gt;And PHP has been under the PHP License since version 4.
This is also a permissive license that allows the use and distribution of PHP with or without modifications,
as source code or executable program, but contains restrictions regarding the use of the &amp;ldquo;PHP&amp;rdquo; trademark.&lt;/p&gt;
&lt;p&gt;This leads to an important question from the late 90s:
What happens when you mix software with different licenses and distribute them together in a distribution or link them together in a translation process?&lt;/p&gt;
&lt;p&gt;The GNU Project quickly clarified that the boundaries of the license are the process boundaries.
If you develop a program under another license and link it with GNU software so that the result is executed in the same process afterward,
this is legally okay only if the other license is compatible with the GPL.&lt;/p&gt;
&lt;p&gt;Although the GPL is an open-source license, not many licenses are compatible with the GPL.
This is because the GPL contains freedom-preserving restrictions:
you can&amp;rsquo;t restrict the execution of the software (&amp;ldquo;Not in nuclear missiles!&amp;rdquo;).
And a program that contains GPL components must also be offered in source code with all changes.
This means not just the GPL components, but all components in this process space.&lt;/p&gt;
&lt;h2 id=&#34;the-debate-over-the-infectious-gpl&#34;&gt;
    &lt;a href=&#34;#the-debate-over-the-infectious-gpl&#34;&gt;
	The Debate Over the &amp;ldquo;Infectious&amp;rdquo; GPL
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The obligation to publish the source code then led to another discussion in the early 2000s.
At that time, Linux and Open Source became so prominent that they could not be ignored,
and many startups flirted with Open Source.
Although the GPL was the most widely used license at the time, it is not an attractive prospect for investors
to have to release all the company&amp;rsquo;s software sources under the GPL.&lt;/p&gt;
&lt;p&gt;It was during this time that the anti-open-source slogan of the &amp;ldquo;viral&amp;rdquo; or &amp;ldquo;contagious&amp;rdquo; GPL originated,
which is nonsense at its core:
On the one hand, the GPL is easy to contain because it ends clearly defined at process boundaries;
on the other hand, the provisions of the GPL make sense because they make direct exploitation of others&amp;rsquo; work more difficult
(&amp;ldquo;Quid pro quo: If you benefit from Open Source, then you should contribute in the same way.&amp;rdquo;).&lt;/p&gt;
&lt;h2 id=&#34;gplv3-against-software-patents&#34;&gt;
    &lt;a href=&#34;#gplv3-against-software-patents&#34;&gt;
	GPLv3 Against Software Patents
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In response to venture capitalists who brought another threat to Open Source into play, a reaction became necessary:
software patents.
If startups have to release their software under the GPL,
they might restrict their intellectual property in other ways to later collect licensing fees.
At the time, software patents were positioned as a real threat.&lt;/p&gt;
&lt;p&gt;The justification for version 3 of the GPL directly addresses this, and GPLv3 includes provisions that,
in simplified terms, state:
&amp;ldquo;If you use patents to sue users of any GPLv3-licensed software, then your right to use any GPLv3 software is terminated.&amp;rdquo;
This clause is effective, and it has led to, among other things,
Apple avoiding any form of GPLv3-licensed software in its products
and progressively replacing any GPL software in Apple products with software licensed differently.&lt;/p&gt;
&lt;p&gt;The provision that the GPL ends at process boundaries is sometimes problematic for the GNU project as well,
and so there are variants of the GPL and exceptions.
For example, code generated by GPL-covered programs is not protected by the GPL:
This allows code generators such as gcc, bison, and flex.
And for some libraries, including glibc, there is the LGPL, also called &amp;ldquo;Lesser GPL,&amp;rdquo;
which allows the libraries to be linked against non-GPL software.&lt;/p&gt;
&lt;h2 id=&#34;gpl-instead-of-lgpl-as-a-weapon&#34;&gt;
    &lt;a href=&#34;#gpl-instead-of-lgpl-as-a-weapon&#34;&gt;
	&amp;ldquo;GPL Instead of LGPL&amp;rdquo; as a Weapon
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Conversely, some companies have used the GPL as a weapon.
For example, libraries like &amp;ldquo;libmysqlclient.so&amp;rdquo; were available under the LGPL up to MySQL 3.23,
but from version 4 onwards, they are under the GPL.
Therefore, if one links this library into their commercial program and wants to distribute it,
they must buy a commercial MySQL license under the dual-licensing program.
MySQL summarized this in the slogan, &amp;ldquo;If you are free, we are free. If you are commercial, we are commercial.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;This was a problem for a while for the programming language PHP,
which linked against this library to access the database as part of the LAMP stack but has a formally non-GPL-compatible license.
PHP countered this problem by reimplementing the protocol as &amp;ldquo;mysqlnd,&amp;rdquo;
and in parallel, MySQL solved the problem by defining a license exception for PHP (and others).&lt;/p&gt;
&lt;h2 id=&#34;less-gpl-more-mit-bsd-and-apache&#34;&gt;
    &lt;a href=&#34;#less-gpl-more-mit-bsd-and-apache&#34;&gt;
	Less GPL, More MIT, BSD, and Apache
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;All these confusions are one reason why &amp;ldquo;modern&amp;rdquo; open-source software often no longer uses the GPL
but prefers other licenses such as MIT, BSD, or Apache.
They make a number of capital-financed business models around open source simpler,
especially if you want to build a company around a product that is open source in name only.
From 2005 onwards, business models based on open source began to flourish.
This has worked well enough for 15 years to grow the number of projects significantly.&lt;/p&gt;
&lt;p&gt;Some of these projects do not rely on individual companies as sponsors:
PHP, KDE, and Postgres, for example, are stable and large-scale OSS projects
that are not backed by a single large company and its venture capital investors –
they all feature a broad and deeply rooted base of contributors.&lt;/p&gt;
&lt;p&gt;In recent years, cracks have appeared: RedHat, Elastic, MongoDB, MariaDB (a MySQL fork), HashiCorp,
and many others have changed their licenses or restructured to exclude a specific use case.
Since this constitutes a violation of Freedom 0, they are no longer open-source projects in the sense of OSI and DFSG.&lt;/p&gt;
&lt;h2 id=&#34;the-elephant-in-the-room-is-the-cloud&#34;&gt;
    &lt;a href=&#34;#the-elephant-in-the-room-is-the-cloud&#34;&gt;
	The Elephant in the Room is the Cloud
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Amazon Web Services (AWS) is a system and a company that epitomizes a business model:
It monetizes the aspect of &amp;ldquo;operations,&amp;rdquo; which is often neglected and underfunded in companies,
and aims not to develop software for third parties but primarily to operate it.&lt;/p&gt;
&lt;p&gt;Amazon has been very successful with this model:
For some time now, more new installations of MySQL (and MongoDB, Postgres, Elastic, and many other databases)
have been running in its data centers than locally with clients (&amp;ldquo;on-premise&amp;rdquo;).
This is a class of systems that are notoriously hard to operate because errors in operation can irreparably ruin data.
Of course, one can roll back a faulty database version to the previous one,
but the data destroyed by the error is still permanently lost.&lt;/p&gt;
&lt;p&gt;The systematic underestimation of the costs and effort operations require is
what makes the principle of &amp;ldquo;Software as a Service&amp;rdquo; (SaaS) successful.
SaaS providers are selling not just a service,
but primarily an operational concept for this service that allows smooth and uninterrupted operation right after commissioning.
Because the operational concept is tested and prescribed, the quality of the service can be standardized,
measured, and then stable contracts can be entered into with third parties.&lt;/p&gt;
&lt;p&gt;Customers welcome this because operating software is a problem at least as challenging as developing software.
Many customers do not want to deal with this.
Often, they accept availabilities, response times, and costs that were completely unacceptable in their own in-house teams before.
All of this just to get the complex task of &amp;ldquo;operating the databases&amp;rdquo; out of the house –
this shows how uncomfortable companies are with dealing with &amp;ldquo;operations.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The operation of this software by AWS is not covered by a commercial agreement between the software manufacturer and Amazon,
but is based on the Freedom 0 of the GPL:
Amazon is allowed to run the software for any purpose, including as a service for others.
As a result, Amazon collects the money for the operation of these installations,
but the actual software developer, the manufacturing company or group, gets nothing from it.
This is not a sustainable financing model, but it is covered by the GPL and very advantageous for AWS,
so there is no incentive for them to change anything.&lt;/p&gt;
&lt;h2 id=&#34;business-source-license-as-an-early-reaction&#34;&gt;
    &lt;a href=&#34;#business-source-license-as-an-early-reaction&#34;&gt;
	Business Source License as an Early Reaction
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The issue of cloud services exploiting open-source software without contributing back to the developers was recognized early on:
The &amp;ldquo;Business Source License&amp;rdquo; (BSL) was first mentioned in the blog of Monty Widenius,
a key figure behind MariaDB, as early as 2013, and MariaDB has been using it for certain components since 2016,
with slight changes after suggestions from Bruce Perens, resulting in version 1.1 in 2017.
Other products followed suit and adopted the BSL: Couchbase, Uptrace, Kurtosis, Sentry, CockroachDB,
and recently all HashiCorp core products.&lt;/p&gt;
&lt;p&gt;The idea behind the BSL is that the software remains freely usable and the source code available,
but with restrictions.
The most important restriction usually means &amp;ldquo;AWS is not allowed to use this,&amp;rdquo;
phrased as &amp;ldquo;The software may not be offered as SaaS for third parties.&amp;rdquo;
Thus, one can use the software as before.
It can also be operated on AWS itself, or it can be provided within one&amp;rsquo;s own organization for other departments.&lt;/p&gt;
&lt;p&gt;However, one will not be able to buy the operation of the software as a service from a cloud operator,
but only from the creator of the software itself (e.g., via AWS Marketplace).
This limitation is intended to ensure the financing the development of the software
by preventing AWS from completely diverting this stream of money for itself.
The BSL comes with another rule stating that code changes must be released under a recognized open-source license (usually the Apache 2.0 license or GPL).
There is a time limit for that: a maximum of four years, ensuring that older versions of the software are always true open source.&lt;/p&gt;
&lt;p&gt;Formally, BSL software is not open source in the OSI or DFSG sense because, unlike the GPL,
Freedom 0 (&amp;ldquo;run for any purpose&amp;rdquo;) is restricted.
Therefore, it is also referred to as &amp;ldquo;Source Available.&amp;rdquo;
The Server Side Public License used by MongoDB, Elastic, and Kibana follows the same idea, only differently:
the SSPL is a variant of AGPLv3 that also restricts Freedom 0 and prohibits operating the software for third parties
(&amp;ldquo;as a Service&amp;rdquo;) unless a commercial license is acquired.&lt;/p&gt;
&lt;h2 id=&#34;non-free-free-software&#34;&gt;
    &lt;a href=&#34;#non-free-free-software&#34;&gt;
	Non-Free Free Software
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The fundamental idea behind the GPL&amp;rsquo;s freedoms is give and take:
&amp;ldquo;You can use our software, but you have to play nice in return.&amp;rdquo;
The ever-growing dominance of AWS is making it increasingly difficult for open-source creators to earn a living from their development work –
AWS offers their software as a service and integrates it with other services.
Freedom 0 of free software here turns against the creators of the software.&lt;/p&gt;
&lt;p&gt;The BSL and SSPL are reactions to this.
Formally, they are not free software, according to OSI or DFSG.
But perhaps it is time for open source to once again face changes and new threats,
adapting licenses and definitions for the new era, as has already happened with GPLv3 and AGPL.&lt;/p&gt;
&lt;p&gt;Perhaps the FSF, OSI, and Debian will not move and will insist on their definitions of &amp;ldquo;free software.&amp;rdquo;
But this does not deter developers of software under BSL and SSPL:
their software is already &amp;ldquo;almost free&amp;rdquo; and, due to their special rule,
will formally become free software according to the old definition after a few years.
There is no reason to reject BSL or SSPL, except for fundamentalism towards free software.
However, if those who care about the open-source idea do not want AWS to be the only company with a successful open-source business model,
then change is necessary.
Otherwise, users will soon find themselves back with dull, traditional commercial software,
the kind they used to get from companies like Microsoft and Oracle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: Starter Villain</title>
      <link>https://blog.koehntopp.info/2023/10/01/fertig-gelesen-starter-villain.html</link>
      <pubDate>Sun, 01 Oct 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/10/01/fertig-gelesen-starter-villain.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mastodon.social/@scalzi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Scalzi&amp;rsquo;s&lt;/a&gt;

 latest book is currently
&lt;a href=&#34;https://www.amazon.de/Starter-Villain-turbo-charged-supervillains-minions-ebook/dp/B0BJDXRGX8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Starter Villain&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/10/starter-villain.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The premise is simple: Charlie&amp;rsquo;s estranged Uncle Jake died.
Charlie and his uncle are estranged because Charlie&amp;rsquo;s father and Jake had a fallout at the funeral of Charlie&amp;rsquo;s mom,
and Charlie has not had much contact at all with Jake ever since.
Now, with Jake also dead, it turns out that Charlie somehow is his only heir.&lt;/p&gt;
&lt;p&gt;Then Charlie is holding watch at Jake&amp;rsquo;s funeral, and the entire story turns quickly into a James Bond novel,
with strange brutes trying to stab the corpse of Jake, ensuring he&amp;rsquo;s really dead,
and a collection of very weirdly imprinted flower bouquets &amp;ndash; &amp;ldquo;See you in hell&amp;rdquo; being one of the nicer ones.&lt;/p&gt;
&lt;p&gt;Charlie quickly learns that his uncle was a Villain, complete with a lair on a volcano island,
laser weapons to destroy satellites, and a collection of very nice and special cats (and Dolphins, but they are special and not nice).
He also learns that &amp;ldquo;Villain&amp;rdquo; does not exactly mean what he thinks that it means.&lt;/p&gt;
&lt;p&gt;Scalzi spent his pages playing nicely with the clichés and expectations around James-Bond-like supervillains,
and turning them into a fun story with a number of expected and unexpected twists.
He wouldn&amp;rsquo;t be Scalzi if there is no stuff to think about lurking in the background.
In this case, fairly obviously the relationship between 1950&amp;rsquo;s supervillains and present day billionaires, oligarchs
and our survival as a species.&lt;/p&gt;
&lt;p&gt;A nice two-afternoon read.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/Starter-Villain-turbo-charged-supervillains-minions-ebook/dp/B0BJDXRGX8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Starter Villain&lt;/a&gt;

&amp;rdquo;,
John Scalzi, EUR 9,99.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: A Life with Footnotes</title>
      <link>https://blog.koehntopp.info/2023/09/30/fertig-gelesen-a-life-with-footnotes.html</link>
      <pubDate>Sat, 30 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/30/fertig-gelesen-a-life-with-footnotes.html</guid>
      <description>&lt;p&gt;Rob Wilkins was the assistant and a good friend of Terry Pratchett.
He wrote a posthumous biography, titled
&lt;a href=&#34;https://www.amazon.de/gp/product/B09R2B8J17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Life With Footnotes&lt;/a&gt;

.
Wilkins is now the manager of the Pratchett literary estate.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/pratchett.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The book does what a biography is supposed to do:
It traces the life of Terry Pratchett,
illuminating his origins and the experiences that shaped his worldview.
Filled with anecdotes and tales from his readings, from conventions, and other encounters with fans,
it sketches a portrait of a lovable, quirky personality who crafted stories in his mind and then simply penned them down.&lt;/p&gt;
&lt;p&gt;Rob Wilkins then takes on the challenging segment of the biography and guides us through the tragic phase of Terry Pratchett:
his Alzheimer&amp;rsquo;s diagnosis, the mental and physical decline, the ever-increasing loss of control, and the interplay of good and bad days,
leading up to the emotional farewell that occurred long before his physical passing.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/gp/product/B09R2B8J17&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Terry Pratchett: A Life With Footnotes&lt;/a&gt;

&amp;rdquo;, Rob Wilkins, EUR 9,49.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: Combat Ready Kitchen</title>
      <link>https://blog.koehntopp.info/2023/09/29/fertig-gelesen-combat-ready-kitchen.html</link>
      <pubDate>Fri, 29 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/29/fertig-gelesen-combat-ready-kitchen.html</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://www.amazon.de/gp/product/B00TY3ZOQE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Combat Ready Kitchen&lt;/a&gt;

,
Anastacia Marx de Salcedo traces the history of food preservation from an american point of view,
and demonstrates the co-development of combat rations and modern U.S. supermarket food.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/combat-ready.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The book takes us through the history of U.S. combat rations, from before the invention of the tin can, through canned,
better preserved, but incredibly heavy food to what soldiers have today.
It shows how these military innovations have been seeded, purposefully, into the civilian food industry,
in order to enable the military to source food from civilian companies for their purposes, in formats that suit them.
This also had influence on how the industry preserves food for civilian consumption and enabled a multitude of convenience foods.&lt;/p&gt;
&lt;p&gt;While the development of food preservation for military and civilian needs was somewhat systematic,
the book is not.
It goes through the history not chronologically, but anecdotally, roughly ordered by kind of food,
but with plenty of sidelines, side stories and other distractions.
It still is an entertaining read, but it makes it hard to put down the book and take stock of what you just learned.&lt;/p&gt;
&lt;p&gt;One thing I took away is that food preservation as we understand it today is much more recent than most people think.
It is a thing humanity only learned in the late 80ies and early 90ies, and even today fundamental progress is being made.
Also, a lot of the stuff we do is not actually bad for the food, the nutrients or the taste,
it is in fact perfectly fine.
Still, other things amount to basically breaking down the food to constituent parts, and then reassembling something
from the parts, and that&amp;rsquo;s maybe less good, given how little we actually understand what makes a meal nourishing or healthy,
even today.&lt;/p&gt;
&lt;p&gt;Entertaining and interesting, but structured in a way that makes it harder than necessary for me to pull value out of it.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;%28https://www.amazon.de/gp/product/B00TY3ZOQE%29&#34;&gt;Combat Ready Kitchen: How the U.S. Military Shapes The Way You Eat&lt;/a&gt;

&amp;rdquo;,
Anastacia Marx de Salcedo, EUR 5.25.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fertig gelesen: Blue Machine</title>
      <link>https://blog.koehntopp.info/2023/09/26/fertig-gelesen-blue-machine.html</link>
      <pubDate>Tue, 26 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/26/fertig-gelesen-blue-machine.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://fediscience.org/@helenczerski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Helen Czerski&lt;/a&gt;

 wrote a book.
&lt;a href=&#34;https://www.amazon.de/Blue-Machine-Ocean-Shapes-English-ebook/dp/B0BCTPP3DH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blue Machine: How the ocean shapes our world&lt;/a&gt;


occupies the weird space between memoir, travel blog and science outreach.&lt;/p&gt;
&lt;p&gt;In the middle of this she manages to explain the biggest machine on our planet:
The collection of oceans in which the continents are embedded.
But also the deep love of science, the desire to understand how our world functions,
and the connection between all people than live on it.&lt;/p&gt;
&lt;p&gt;The book is the story of a person who literally travelled the world, from the poles to the equator,
and from the surface of the oceans to their dark cold depths.
It also is the story of a physicist with knowledge about bubbles and how they work,
and how that line of research led her around the world, and into the oceans.
It also is a gentle introduction into climate science,
showing us how the ocean can be seen as a machine that manages the thermals of the planet,
capturing and transporting heat, feeding the weather machine in the atmosphere with energy and water vapor,
and also capturing and releasing carbon dioxide.&lt;/p&gt;
&lt;p&gt;Following her travels and experiences, we learn about the vertical layering structure of the oceans,
about the ability of water to capture fantastic amounts of energy,
about currents and how they transport water, energy, nutrients and life around the world,
and how humans have been living off all this on the surface of something much greater, deeper and larger than we ever imagined.&lt;/p&gt;
&lt;p&gt;This is an amazing and entertaining book that shares a unique and personal perspective of our world,
and at the same time manages to convey how something this vast and enormous can be at the same time fragile and in need our or care and understanding.&lt;/p&gt;
&lt;p&gt;Strongly recommended read, well worth the time.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;a href=&#34;https://www.amazon.de/Blue-Machine-Ocean-Shapes-English-ebook/dp/B0BCTPP3DH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blue Machine&lt;/a&gt;

&amp;rdquo;, Helen Czerski, EUR 15.62&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Gospel of Efficiency vs. Actual Growth</title>
      <link>https://blog.koehntopp.info/2023/09/19/the-gospel-of-efficiency-vs-actual-growth.html</link>
      <pubDate>Tue, 19 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/19/the-gospel-of-efficiency-vs-actual-growth.html</guid>
      <description>&lt;p&gt;A decade ago, I came as a performance specialist into a rapidly growing environment.
With rapid growth, I mean anything that is larger than what Moore&amp;rsquo;s Law once delivered.
Moore&amp;rsquo;s law comes out at upwards of 45% Year-on-Year (YoY).
In my case, we experienced 80% YoY worldwide with 220% YoY in certain regions of the world for many years.
Even in 2008, when the economy stagnated, we still made 45% or more.&lt;/p&gt;
&lt;p&gt;Onboarding people into such an environment is weird.
They all have been programmed by their university education and their previous work experience to build things that last,
to consider things carefully and to be efficient, and save money at all cost.&lt;/p&gt;
&lt;p&gt;That is not how anything works in a high-growth environment, at all.
Rapid growth kills.
The tech we build, we build it for a certain expected target size.
Good tech can sustain a 10x growth (or shrinkage), but usually not much more.
At a larger change, things tend to fall apart.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; bc -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;scale&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; l&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;10&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;/l&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;2&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;3.321
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; l&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;10&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;/l&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;1.45&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;6.204
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;When you double each year, 10x is 3.3 years, approximately.&lt;/li&gt;
&lt;li&gt;When you grow at Moore&amp;rsquo;s Law rate, 10x is 6.2 years, approx.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a high-growth an environment, when you write software,
you can expect it to last around 4 years or so until it needs to be re-architected in order to continue to produce the same deliverables as before.
You do not know how it will fail much in advance, nor do you know how the business environment will change much in advance:
As you grow, bottlenecks will show up in unexpected places.&lt;/p&gt;
&lt;p&gt;If you grow faster than Moore&amp;rsquo;s law, buying larger computers will not help you.
You need to buy more computers, and change your code to run in a distributed environment.
That changes performance fundamentally, and code needs to be changed in order to deal with the properties of distributed environments.
Running distributed systems will add complexity that you really do not want in order to maintain growth,
because it makes change harder and slower, which you really can&amp;rsquo;t use, if you grow fast.&lt;/p&gt;
&lt;p&gt;Finally, on top of the change in technology, you also need to deal with change in organiation,
and to integrate a lot of new people which you need in order to deal with added complexity.&lt;/p&gt;
&lt;p&gt;That means, several unusual things are important, others that people have been trained to take as important are not.&lt;/p&gt;
&lt;p&gt;For example, in such an environment, all software is ephemeral.
In four years time it will be largely useless.
You do not know how things will fail unless you are close to failure.
You have vision for about 12 months ahead, at most.&lt;/p&gt;
&lt;p&gt;You will need to start to change your failing software by making architectural changes.
You do not know if they will succeed in time.
Do not follow one plan, follow all plans and hope that at least one succeeds in time.&lt;/p&gt;
&lt;p&gt;Cost is relevant only in the sense that you must not pay for current expenses with future growth.
You must be cash flow positive at all times,
but actual earnings are largely irrelevant until growth flattens out below 45%.
Never paying for current expense with future growth (not even for a short time) is very important,
because you do not know if that future growth will materialize.
If you ever run into a money vaccuum, you die very suddenly.&lt;/p&gt;
&lt;p&gt;Actual earnings are much less important.
Not dying from growth is already hard enough,
the objective is to have new solutions in place &lt;em&gt;in time&lt;/em&gt;,
and speed matters more than cost.&lt;/p&gt;
&lt;p&gt;This is a rare environment and people are generally not trained for it.
It goes in fact against most of what they have been trained for.
Getting that out of people&amp;rsquo;s minds in order to prepare them for success in such an environment is hard,
much harder than what one would initially think,
because you have to break down decades of education they had.
You need to have then accept a reality that is very different from what they have learned.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Need for Smarter Clients</title>
      <link>https://blog.koehntopp.info/2023/09/18/the-need-for-smarter-clients.html</link>
      <pubDate>Mon, 18 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/18/the-need-for-smarter-clients.html</guid>
      <description>&lt;p&gt;Somebody asked me very politely on the Fedi:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Would you please post all but the first post in a thread as &amp;ldquo;unlisted&amp;rdquo;?&lt;/p&gt;
&lt;p&gt;I like to follow you, but the sum of all posts by you takes up so much space on my front page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The answer to that request, also politely, is a firm &amp;ldquo;No.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Selection, ordering and presentation of posts is a client problem, which it has to solve, according to your configured preferences.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Of course, my client (Tusky) recognizes a thread and shows it as such.&lt;/p&gt;
&lt;p&gt;But all posts that are being sent as &amp;ldquo;public&amp;rdquo; are also shown separately on my front page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is an understandable problem, but not mine.&lt;/p&gt;
&lt;p&gt;I believe Tusky will also show you reposts of the same article by 17 different persons.
In total, you get to see 18 copies of that article (the original and 17 copies).
Would you ask these people to not repost because another of your followers already did that?
You would not.&lt;/p&gt;
&lt;p&gt;Tusky, and every other client must learn what it has shown previously, and to not show middle posts of threads if so desired.&lt;/p&gt;
&lt;p&gt;If we start to take care of recipient presentation preferences on the sender&amp;rsquo;s side, we are getting into an impossible situation.
The sum of all recipients has irreconcilable preferences.&lt;/p&gt;
&lt;p&gt;Also, we would end up in a &amp;ldquo;USENET-situation,&amp;rdquo; where advancement becomes impossible.
&amp;ldquo;No Umlauts, because my VT100 can&amp;rsquo;t render them.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I can&amp;rsquo;t and won&amp;rsquo;t ever care for any client&amp;rsquo;s presentation preferences.
Get a client that can render stuff the way you want, and pay your client developers of choice to build the client you want.&lt;/p&gt;
&lt;p&gt;This network is federated, with dozens of clients.
This offers you choice and makes it impossible for me to care for you all.
If you don&amp;rsquo;t like this, please unsubscribe to my account.
The network is large, and you won&amp;rsquo;t miss my content.&lt;/p&gt;
&lt;p&gt;Thanks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Invalid-UTF8 vs the filesystem</title>
      <link>https://blog.koehntopp.info/2023/09/14/invalid-utf8-vs-the-filesystem.html</link>
      <pubDate>Thu, 14 Sep 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/09/14/invalid-utf8-vs-the-filesystem.html</guid>
      <description>&lt;p&gt;A UNIX filename can contain arbitrary bytes in an arbitrary sequence, with two exceptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It cannot contain NUL (&lt;code&gt;\0&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;It cannot contain slash (&lt;code&gt;/&lt;/code&gt;), because that is the directory separator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But will all filesystems accept such filenames?
And how will this work with languages such as Python, which require all strings to be valid &lt;code&gt;utf-8&lt;/code&gt; and
which declare the filesystem interface to accept and return strings?&lt;/p&gt;
&lt;h1 id=&#34;a-test-program&#34;&gt;
    &lt;a href=&#34;#a-test-program&#34;&gt;
	A test program
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s check.
Here is a small C program, based on &lt;a href=&#34;https://stackoverflow.com/questions/1301402/example-invalid-utf8-string&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this stackoverflow article&lt;/a&gt;

.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;sys/stat.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;unistd.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xc3\xb1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xc3\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xa0\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x82\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x28\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xe2\x82\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x90\x8c\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x28\x8c\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x90\x28\xbc&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf0\x28\x8c\x28&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xf8\xa1\xa1\xa1\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\xfc\xa1\xa1\xa1\xa1\xa1&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;FILE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mkdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;keks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mo&#34;&gt;0755&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// don&amp;#39;t care if exists
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;chdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;keks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;       &lt;span class=&#34;c1&#34;&gt;// don&amp;#39;t care if succeed.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nf&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fopen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;unable to open %d (%s)!&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;examples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;continue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;fprintf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;keks&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;fclose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;xfs&#34;&gt;
    &lt;a href=&#34;#xfs&#34;&gt;
	XFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a Linux system with XFS, this works:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-xfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates all files. Even those with byte sequences that are not valid utf-8.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This works the same with ext4 on Linux.&lt;/p&gt;
&lt;h2 id=&#34;zfs&#34;&gt;
    &lt;a href=&#34;#zfs&#34;&gt;
	ZFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a Linux system with ZFS, filenames containing invalid utf-8 sequences are rejected.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-zfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates files with valid utf-8 names. The &lt;code&gt;open(2)&lt;/code&gt; syscall fails for names with invalid utf-8 filenames.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;apfs&#34;&gt;
    &lt;a href=&#34;#apfs&#34;&gt;
	APFS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When running this on a MacOS Ventura system with APFS, filenames containing invalid utf-8 sequences are rejected.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/09/invalid-utf8-apfs.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The program runs and generates files with valid utf-8 names. The &lt;code&gt;open(2)&lt;/code&gt; syscall fails for names with invalid utf-8 filenames.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;unpacking-invalid-utf-8-filenames-with-python&#34;&gt;
    &lt;a href=&#34;#unpacking-invalid-utf-8-filenames-with-python&#34;&gt;
	Unpacking invalid utf-8 filenames with Python
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I went and creates a &lt;code&gt;tar&lt;/code&gt; archive of the files generated on XFS and copied it over to my Mac.&lt;/p&gt;
&lt;p&gt;The following test program was used to unpack the &lt;code&gt;tar&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;ch&#34;&gt;#! /usr/bin/env python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tarfile&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;chardet&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test.tar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bytearray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;raw&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chardet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;detect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The test run fails:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;(venv) $ python tarnames.py
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Traceback (most recent call last):
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  File &amp;#34;.../tarnames.py&amp;#34;, line 15, in &amp;lt;module&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;    bname = bytearray(name, &amp;#39;raw&amp;#39;)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;            ^^^^^^^^^^^^^^^^^^^^^^
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;LookupError: unknown encoding: raw
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;intermediate-result&#34;&gt;
    &lt;a href=&#34;#intermediate-result&#34;&gt;
	Intermediate result
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;It probably is useful to restrict POSIX further and demand that filenames are always valid utf-8.
But that is not what the standard currently says, and also not what all filesystems guarantee.
And it can lead to unexpected behavior.&lt;/p&gt;
&lt;p&gt;Also, some programming languages such as Python demand of strings that they have valid utf-8 encoding,
but use filenames and strings equivalently.&lt;/p&gt;
&lt;p&gt;That can lead to weird behavior.&lt;/p&gt;
&lt;h1 id=&#34;further-research&#34;&gt;
    &lt;a href=&#34;#further-research&#34;&gt;
	Further research
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Apparently there is a function
&lt;a href=&#34;https://docs.python.org/3/library/sys.html#sys.getfilesystemencoding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;sys.getfilesystemencoding()&lt;/code&gt;&lt;/a&gt;


without parameters.
Python seems to assume that all filesystems have the same encoding and that it is not path dependent.&lt;/p&gt;
&lt;p&gt;Apparently there are &lt;code&gt;os.fsencode()&lt;/code&gt; and
&lt;a href=&#34;https://docs.python.org/3/library/os.html#os.fsencode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;os.fsdecode()&lt;/code&gt;&lt;/a&gt;

.&lt;/p&gt;
&lt;h2 id=&#34;modified-python-code&#34;&gt;
    &lt;a href=&#34;#modified-python-code&#34;&gt;
	Modified Python code
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;We are using &lt;code&gt;os.fsencode()&lt;/code&gt; to get &lt;code&gt;bytes&lt;/code&gt; from the filesystem interface.
We are then using &lt;code&gt;chardet.detect()&lt;/code&gt; on this byte-string and check the guesses.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;ch&#34;&gt;#! /usr/bin/env python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tarfile&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;chardet&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TarFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test.tar&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fsencode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;=}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chardet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;detect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bname&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ascii&amp;#39;, &amp;#39;confidence&amp;#39;: 1.0, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/a&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ascii&amp;#39;, &amp;#39;confidence&amp;#39;: 1.0, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xc3\xb1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xc3(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xa0\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;IBM866&amp;#39;, &amp;#39;confidence&amp;#39;: 0.99, &amp;#39;language&amp;#39;: &amp;#39;Russian&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2\x82\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2(\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xe2\x82(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0\x90\x8c\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1254&amp;#39;, &amp;#39;confidence&amp;#39;: 0.48310298982778344, &amp;#39;language&amp;#39;: &amp;#39;Turkish&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0(\x8c\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0\x90(\xbc&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1254&amp;#39;, &amp;#39;confidence&amp;#39;: 0.5521177026603239, &amp;#39;language&amp;#39;: &amp;#39;Turkish&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf0(\x8c(&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xf8\xa1\xa1\xa1\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;bname=b&amp;#39;keks/\xfc\xa1\xa1\xa1\xa1\xa1&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;ISO-8859-1&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The guesses are trying to find a valid charset for the bytestring, and they find the lowest (least large) charset that matches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Don&#39;t say Backup, say Restore</title>
      <link>https://blog.koehntopp.info/2023/08/23/dont-say-backup-say-restore.html</link>
      <pubDate>Wed, 23 Aug 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/08/23/dont-say-backup-say-restore.html</guid>
      <description>&lt;p&gt;This is about the third story I hear about a Fedi instance losing all their data because of a CI/CD mistake.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://firefish.social/notes/9iqefgi8rzfksnqc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lily Cohen (@lily@firefish.social) has bad news.&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Hugops, but also the usual grizzled old sysadmin advice:&lt;/p&gt;
&lt;h2 id=&#34;never-say-backup-always-say-restore-this-changes-your-mind&#34;&gt;
    &lt;a href=&#34;#never-say-backup-always-say-restore-this-changes-your-mind&#34;&gt;
	Never say backup. Always say restore. This changes your mind.
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;A backup is a cost center.
It has no value, it has only cost.
Only a restore has a proven value, and comes with knowledge:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You know you actually can restore, the backup was complete and does connect.&lt;/li&gt;
&lt;li&gt;You know how long the restore took, so you know the time to restore when asked. Not an estimate. The actual time.&lt;/li&gt;
&lt;li&gt;You know the restore procedure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Restore &lt;em&gt;every&lt;/em&gt; backup &lt;em&gt;all&lt;/em&gt; the time, then throw the recovered instance away.
Keep the metrics, keep the backup.&lt;/p&gt;
&lt;h2 id=&#34;there-is-no-such-thing-as-immutable-statelessness-or-whatever&#34;&gt;
    &lt;a href=&#34;#there-is-no-such-thing-as-immutable-statelessness-or-whatever&#34;&gt;
	There is no such thing as immutable, statelessness or whatever.
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Parts of your setup may be stateless deployments with immutable images.
That is, because you collected all system state and put it into one or two selected locations.
You can redeploy everything but these selected locations.&lt;/p&gt;
&lt;p&gt;If you drop them, if you make a config mistake, these things are gone gone.
They cannot be redeployed unless you have taken measures to do so.
See above, item 1.&lt;/p&gt;
&lt;h2 id=&#34;devops-is-easy-except-for-the-stateful-parts&#34;&gt;
    &lt;a href=&#34;#devops-is-easy-except-for-the-stateful-parts&#34;&gt;
	Devops is easy except for the stateful parts.
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;That is why the storage people and the database people all look down on you hipster devops people and make condescending remarks. 🙂
Yah, ok, they are nicer than you probably think they are,
but they &lt;em&gt;do&lt;/em&gt; have a completely different outlook on operations.&lt;/p&gt;
&lt;p&gt;Listen and learn. Also, restore test.&lt;/p&gt;
&lt;p&gt;Also,
&lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/user-guide/sync-options/#no-prune-resources&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ArgoCD: No prune resources&lt;/a&gt;


and
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes PV Reclaim Policy&lt;/a&gt;


&amp;ldquo;Retain, not Delete.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;There are people who have taken steps to prevent their CI/CD from messing with EBS volumes,
S3 buckets or K8s Persistent Volumes, and there are people who will lose data in the future.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t be in the second group.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/backup-restore-01.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;Nobody wants backup.
Everybody wants restore.&amp;rdquo;
&amp;ndash; Martin Seeger&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;See also
&lt;a href=&#34;https://blog.koehntopp.info/2017/02/01/nobody-wants-backup-everybody-wants-restore.html&#34;&gt;Gitlab Data Loss&lt;/a&gt;

.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MacOS, vim, git and exit...</title>
      <link>https://blog.koehntopp.info/2023/08/17/macos-vim-git-and-exit.html</link>
      <pubDate>Thu, 17 Aug 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/08/17/macos-vim-git-and-exit.html</guid>
      <description>&lt;p&gt;On &lt;code&gt;git commit&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt; invokes an editor (by default: &lt;code&gt;vi&lt;/code&gt;) and allows you to edit a commit message.
If the editor exits with status code 0, the commit message is accepted and used.
If the editor exists with status code &amp;gt;0, this is an error and the commit is aborted.
The commit message is lost.&lt;/p&gt;
&lt;p&gt;On MacOS, calling &lt;code&gt;/usr/bin/vi&lt;/code&gt;, the editor shipped with the OS, starts vim 9.0.1424 in vi mode.
In this mode, if you enter an illegal editor command such as &lt;code&gt;:W&lt;/code&gt;, the editor will exit with status 1.
This will happen even when you enter a legal editor command afterwards.
So&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;:W keks
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;:w keks
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;:q
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;will&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;kk:~ kris$ vi
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;kk:~ kris$ echo $?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This does not happen if the same editor is called as &lt;code&gt;vim&lt;/code&gt;.
This does not happen on Ubuntu 22.04, which as vim 8.2.4919 installed – it will exit 0 as &lt;code&gt;vi&lt;/code&gt; or &lt;code&gt;vim&lt;/code&gt;.
This suggests that this behavior of vim 9, when called as &amp;ldquo;vi&amp;rdquo; in compatibility mode, is an &amp;ldquo;improvement&amp;rdquo; that has been added on purpose.
I wonder if that is really the case.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;vim&lt;/code&gt;, the command &lt;code&gt;:&amp;lt;status&amp;gt;cq&lt;/code&gt; to force an exit status.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;:1cq
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;kk:~ kris $ echo $?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also &lt;code&gt;:0cq&lt;/code&gt; to force a zero.
This also works in compatibility mode.
You can, of course, also&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;$&lt;/span&gt; git config --global core.editor &lt;span class=&#34;s2&#34;&gt;&amp;#34;vim&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Electric Cars and Numbers</title>
      <link>https://blog.koehntopp.info/2023/08/13/electric-cars-and-numbers.html</link>
      <pubDate>Sun, 13 Aug 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/08/13/electric-cars-and-numbers.html</guid>
      <description>&lt;p&gt;(based on a series of posts on Mastodon)&lt;/p&gt;
&lt;h1 id=&#34;i-got-an-electric-car&#34;&gt;
    &lt;a href=&#34;#i-got-an-electric-car&#34;&gt;
	I got an electric car
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I made the driving license late in life, in 1998 at the age of 30.
My first car was a BMW 316i Coupe, used, 9000 Euro.
I drove this until 2007.
When I moved to Berlin, I found driving in the city inconvenient, and consequently used public transport.
Eventually the battery of the car died from standing around, and I sold it.&lt;/p&gt;
&lt;p&gt;In 2010, I became a father, and we bought a new car, a Renault Scénic Grande 7-seater.
This is a car made from cupholders and small compartments, and it served its function of
&amp;ldquo;Moving the family around, including Grandma&amp;rdquo; quite well.
Nothing Renault makes lasts longer than 15 years, though, and so the thing was showing signs of age.&lt;/p&gt;
&lt;p&gt;Also,
&lt;a href=&#34;https://blog.koehntopp.info/2023/05/11/city-of-amsterdam-and-combustion-engines.html&#34;&gt;the City of Amsterdam changes the rules&lt;/a&gt;


of how to get into the city, and the old Scenic soon would be unable to get into the city.
So, an electric car was needed.&lt;/p&gt;
&lt;p&gt;I tried to like the BYD Dolphin, but that car comes only with seats where the headrest is fixed and cannot be adjusted.
At my size, that means the headrest sits somewhere at my lower shoulder blades.
I asked for advice, and the BYD salesperson just pointed at the BYD Tank, a monstrous SUV.
That had adjustable headrests for sure, but you wouldn&amp;rsquo;t want to drive such a thing inside Amsterdam&amp;rsquo;s city limits.&lt;/p&gt;
&lt;p&gt;So Renault again, this time a Megane e-tech, with a 60 kWh battery, and some 16 kWh/100 km energy use.
Also, apparently some 160 kW engine (peak power), which really is a 55 kW engine (sustained power).&lt;/p&gt;
&lt;p&gt;These are weird units for energy and power for most people.&lt;/p&gt;
&lt;p&gt;What do they even mean and how can we imagine them?&lt;/p&gt;
&lt;h1 id=&#34;everything-in-kwh&#34;&gt;
    &lt;a href=&#34;#everything-in-kwh&#34;&gt;
	Everything in kWh
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Back in the day, we had incandescent light bulbs, and the standard thing everybody my age can imagine is the 100 W bulb.
It was as bright as a modern 14W LED light today.
Running the 100 W lamp for one hour uses 100 Wh of energy, running it for 10 hours is 1000 Wh, or 1 kWh.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/100W.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A 100 W incandescent bulk, &lt;a href=&#34;https://en.wikipedia.org/wiki/File:Gluehlampe_01_KMJ.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;as shown in Wikipedia&lt;/a&gt;

.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Watts are power (&amp;ldquo;Leistung&amp;rdquo; in German), and Watt-Hours are energy
(&amp;ldquo;Energie,&amp;rdquo; &amp;ldquo;Arbeit&amp;rdquo; in German.
&amp;ldquo;Leistung ist Arbeit pro Zeit&amp;rdquo; as my math teacher used to say to people who did not complete their test in time).&lt;/p&gt;
&lt;h2 id=&#34;solar-energy&#34;&gt;
    &lt;a href=&#34;#solar-energy&#34;&gt;
	Solar Energy
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The sun shining on Germany on a bright day delivers 1 kW per m^2, so 1 h of sunshine is an irradiation of 1 kWh/qm.
Solar cells currently have an efficiency of 20%, so 1000 W of irradiation become 200 W of electricity,
the other 800 W become heat or are reflected.&lt;/p&gt;
&lt;p&gt;Such a 1 m^2 solar array would have an installed peak capacity of 200 Wp (&amp;ldquo;Watt peak,&amp;rdquo; or &amp;ldquo;Nennleistung&amp;rdquo; in German).
Five of those would deliver 1 kWp, and produce around 950 kWh of energy per year, under optimal conditions.&lt;/p&gt;
&lt;p&gt;In fact, 46 m^2 of my roof are covered in solar panels.
&lt;a href=&#34;https://blog.koehntopp.info/2022/05/02/a-solar-roof.html&#34;&gt;That&amp;rsquo;s 9250 Wp&lt;/a&gt;

,
which under this formula should produce up to 8780 kWh/year.&lt;/p&gt;
&lt;p&gt;They did, in fact, deliver 8000-ish kWh/year, from June 2022 to June 2023.
To compare, we used 5500 kWh of electricity in the year before we got the Solar panels.&lt;/p&gt;
&lt;h2 id=&#34;fuels-and-energy&#34;&gt;
    &lt;a href=&#34;#fuels-and-energy&#34;&gt;
	Fuels and Energy
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When I was little, a car&amp;rsquo;s power was given in HP (Horsepower).
Today we use kW, but many people will still list HP in parentheses for old people&amp;rsquo;s convenience.&lt;/p&gt;
&lt;p&gt;1000 W are ~1 ⅓ HP, or 1 HP are ~750 W.
Drive that for one hour, and you have used 1 kWh.&lt;/p&gt;
&lt;p&gt;Conveniently, the energy content of many fuels is almost decimal.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Fuel&lt;/th&gt;
&lt;th&gt;kWh&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1l Diesel&lt;/td&gt;
&lt;td&gt;9.7 kWh, ~10 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1l Benzine&lt;/td&gt;
&lt;td&gt;8.5 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1 m^3 Natural Gas&lt;/td&gt;
&lt;td&gt;10-12 kWh, ~10 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Almost metric: 1 m^3 of Gas or 1 l of Diesel each has an energy content of 10 kWh.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So if your old Scenic Diesel uses 6.7l Diesel on 100 km, it has used around 66 kWh of energy.
A combustion engine car is around 33% efficient.&lt;/p&gt;
&lt;p&gt;So of these 66 kWh, around 22 kWh have been used to drive the distance.
The rest is waste heat.&lt;/p&gt;
&lt;p&gt;The new Megane uses 16 kWh for 100 km, so that is the energetic equivalent of 1.8l Benzine or 1.6l Diesel.
Times three, to account for combustion engine losses.&lt;/p&gt;
&lt;h2 id=&#34;other-energy-units&#34;&gt;
    &lt;a href=&#34;#other-energy-units&#34;&gt;
	Other energy units
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Calories (actually kilocalories, kcal) are known to many people as units for energy content of food.
A kilo of body fat is 7700 kcal, and that&amp;rsquo;s 8.9 kWh.
So 11.2 kilos of dad bod are 100 kWh.
Take that, Tesla.&lt;/p&gt;
&lt;p&gt;This is not theoretical energy at all, as
&lt;a href=&#34;https://www.youtube.com/watch?v=Vps_8dnnU_M&amp;amp;t=474s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;S4E8 Mythbusters: Salami Rocket&lt;/a&gt;


has demonstrated.&lt;/p&gt;
&lt;p&gt;A bar of Milka chocolate has around 0.6 kWh.
So charging a 60 kWh car battery is around 100 Milka bars of energy content.&lt;/p&gt;
&lt;p&gt;If you are driving a Diesel at 6l/100 km, you burn 60 kWh of energy content, or around one bar of Milka per Kilometer.
Things become very conveniently convertible if everything is kW and kWh.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bergfreunde.de/kalorienverbrauch-sport-rechner/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bergfreunde&lt;/a&gt;

 has a human activity energy calculator,
which covers anything from Walking to Sex.
8h of walking for a fat old man will burn 3350 kcal, or 3.9 kWh.
Assuming 6 km/h, we will burn 8.1 kWh/100 km.
That is less than the Megane, but more than the Carver.
And a lot more than biking.&lt;/p&gt;
&lt;h2 id=&#34;long-distance-driving-and-charging&#34;&gt;
    &lt;a href=&#34;#long-distance-driving-and-charging&#34;&gt;
	Long Distance driving and charging
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;If you run your electric vehicle for long distances, you will observe that the last 20% of charge,
from 80% to 100%, take longer than the rest.
That is because batteries take energy quickly as long as they are empty, and the final 20% charge particularly slowly.&lt;/p&gt;
&lt;p&gt;Most people do not wait for a full charge, but charge to 80%-ish and then continue to drive.
They also won&amp;rsquo;t drive the car down to 0%.&lt;/p&gt;
&lt;p&gt;So at an energy use of 16-20 kWh/100 km at a speed of 100 km/h, you will be driving for about 2-2.5 hours until the battery runs empty.
Then the car will need to charge, and because you are on the Autoahn, you&amp;rsquo;ll be using a fast charger.
That will bring the car to 80% in around 30 minutes, sufficient to pee and get a coffee.&lt;/p&gt;
&lt;p&gt;This is the rhythm of the electric long distance drive:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Start SoC&lt;/th&gt;
&lt;th&gt;End SoC&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;th&gt;Energy Stored&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;29 %&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;32 min&lt;/td&gt;
&lt;td&gt;30.20 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9%&lt;/td&gt;
&lt;td&gt;80%&lt;/td&gt;
&lt;td&gt;37 min&lt;/td&gt;
&lt;td&gt;42.15 kWh&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Carging at a DC fast charger on the Autobahn.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;at-home-and-charging&#34;&gt;
    &lt;a href=&#34;#at-home-and-charging&#34;&gt;
	At home, and charging
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/ladepunkt.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;11 KW charge point as it is installed in public spaces all over the country in the Netherlands
(&lt;a href=&#34;https://nl.wikipedia.org/wiki/Oplaadpunt#/media/Bestand:Oplaadpaal_Utrecht.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia&lt;/a&gt;

).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At home, you won&amp;rsquo;t be using a DC fast charger, but will be using an AC 11 kW charger.
On this, the car goes from 31% to 80% in 3h:10m.
A 22 kW charger would be twice as fast, but likely pointless.&lt;/p&gt;
&lt;p&gt;An 11 kW charger is always sufficiently fast to charge up completely in reasonable time.
And if not, sufficient to get to a SoC where you can drive to the Autobahn safely,
and then use a DC fast charger to charge up really fast.&lt;/p&gt;
&lt;h2 id=&#34;driving-accelerating-and-braking&#34;&gt;
    &lt;a href=&#34;#driving-accelerating-and-braking&#34;&gt;
	Driving, Accelerating and Braking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When you are driving a constant speed on a flat surface,
you are using the exact amount of energy needed to counteract wind resistance.
So if your car&amp;rsquo;s display reads &amp;ldquo;16 kW current energy use&amp;rdquo;, you are using 16 kW/21 HP to keep the current speed.
That is about as much as the engine power of an old 1978 Renault 4 (or a Citroen 2CV).&lt;/p&gt;
&lt;p&gt;The Megane has a more powerful engine, but only to accelerate nicely,
and then it will even reach the catalog power of &amp;ldquo;160 kW&amp;rdquo; &amp;ndash; for a short time.&lt;/p&gt;
&lt;p&gt;Well, the Megane also has a more powerful engine for better recuperation,
using the engine to convert kinetic energy back to electricity, and storing it back into the battery.
The limit for that is 60 kW, &amp;ldquo;accidentally&amp;rdquo; close to the sustained power of the engine.&lt;/p&gt;
&lt;p&gt;This is also a good case for a speed limit in the only country in Europa that has none:
In the Netherlands there is a 100 km/h speed limit (at night sometimes 120 km/h),
and that leads to extremely equalized car speeds on the Autobahn.&lt;/p&gt;
&lt;p&gt;You basically turn on cruise control, set it to 100 and are done with it.&lt;/p&gt;
&lt;p&gt;In Germany, you might set the Megane to 120 km/h, turn on as many assistance systems as possible
and switch mentally into Fuck-You mode, but you will still have to accelerate and decelerate more,
because speeds on the German Autobahn vary a lot.&lt;/p&gt;
&lt;p&gt;Not only does this make driving dangerous,
it also eats into your range without providing better average speeds.&lt;/p&gt;
&lt;h2 id=&#34;sustained-and-peak-power&#34;&gt;
    &lt;a href=&#34;#sustained-and-peak-power&#34;&gt;
	Sustained and Peak Power
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The Megane is sold with a peak power of 160 kW, but the motor has a sustained power of only 55 kW.
You run it at even less, 16 kW, unless you accelerate.&lt;/p&gt;
&lt;p&gt;Air resistance is growing with larger speed, and the sustained power of the motor
basically defines the cars top speed.
But of course, this will also draw from the battery accordingly,
so you will run out of energy faster, and need to charge earlier.&lt;/p&gt;
&lt;p&gt;At 160 km/h, you will draw 55 kW, and will run out of power after 1 h.&lt;/p&gt;
&lt;p&gt;It is typical for electric motors to overdrive them.
For example, an electric locomotive rated at 4000 kW is routinely driven at 6000 kW
on initial acceleration, until it hits the thermal limit, I have been told.&lt;/p&gt;
&lt;p&gt;Also, the energy use of trains is incredibly low.
A &lt;a href=&#34;https://de.wikipedia.org/wiki/Stadler_Flirt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stadler Flirt&lt;/a&gt;

 uses around 330 kWh/100 km.
That&amp;rsquo;s the energy content of 30l Diesel, for a train of 60m length and 180 seats (around 300-350 people in commuter mode).
Or in other words, 5 times the energy use of a Diesel car,
so if 6 seats are occupied, it breaks even with a car (at an average occupancy of 1.2 people/car).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/08/flirt-energy-use.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Flirt has drawn 1408 kWh from the overhead line, and recuperated 748 kWh, for a net energy use of 660 kWh.
At the Konstanz-Stuttgart Line (200 km), this equals 330 kWh/100 km, or around 39l of Benzine (or 34l of Diesel) in energy content.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;tldr&#34;&gt;
    &lt;a href=&#34;#tldr&#34;&gt;
	TL;DR
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;We can convert all kinds of energy into kWh, and use this to compare energy production and consumption.
This is convenient, because typical fuels happen to align somewhat with the metric system:
1 l of Diesel or 1 m^3 of Natural Gas both have each 10 kWh of energy content.
For fun, we can also do this with Milka Chocolate bars (0.6 kWh stored energy content)
or with Pizza (around 1 kWh per Europizza).&lt;/p&gt;
&lt;p&gt;We can do the same thing with power, and kW, and since power times time is energy,
we can also easily convert energy draw over time into battery depletion, and plan trips.&lt;/p&gt;
&lt;p&gt;Getting fluent with units and conversions helps us to develop a feel for range, speed, energy and cost.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ubuntu: systemctl --user does not work</title>
      <link>https://blog.koehntopp.info/2023/07/12/ubuntu-systemctl-user-does-not-work.html</link>
      <pubDate>Wed, 12 Jul 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/07/12/ubuntu-systemctl-user-does-not-work.html</guid>
      <description>&lt;p&gt;Memo to self:
I have a VPS with a legacy Ubuntu 20.04, and when creating a user to run a user-based service,
trying to use systemctl fails with the message:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user status
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Failed to connect to bus: No such file or directory
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To solve this, multiple changes were necessary:&lt;/p&gt;
&lt;h1 id=&#34;fixing-the-systemd-problem&#34;&gt;
    &lt;a href=&#34;#fixing-the-systemd-problem&#34;&gt;
	Fixing the &lt;code&gt;systemd&lt;/code&gt; problem
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The service is supposed to run as the user &lt;code&gt;theservice&lt;/code&gt;, from the directory &lt;code&gt;/home/theservice/therepo&lt;/code&gt;,
and is to be controlled by a systemd instance for this user.
There was no such instance running.&lt;/p&gt;
&lt;h2 id=&#34;missing-packages&#34;&gt;
    &lt;a href=&#34;#missing-packages&#34;&gt;
	Missing packages
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Several required packages were not installed (server image, minimal packages installed):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# apt install dbus-user-session libpam-systemd libpam-cgfs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;loginctl-config-not-correct&#34;&gt;
    &lt;a href=&#34;#loginctl-config-not-correct&#34;&gt;
	&lt;code&gt;loginctl&lt;/code&gt; config not correct
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Loginctl needs to be told what to do when the user is not logged in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# loginctl enable-linger theservice&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;missing-environment-variables&#34;&gt;
    &lt;a href=&#34;#missing-environment-variables&#34;&gt;
	Missing environment variables
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Two environment variables were not defined properly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ cat ~/.bashrc 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ~/.bashrc: executed by bash(1) for non-login shells.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# for examples&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# THIS INSERTED vvv&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;XDG_RUNTIME_DIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/run/user/&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;id -u&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;DBUS_SESSION_BUS_ADDRESS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;unix:path=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;XDG_RUNTIME_DIR&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bus&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# THIS INSERTED ^^^&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# If not running interactively, don&amp;#39;t do anything&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$-&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *i*&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      *&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As you can see in the &lt;code&gt;case&lt;/code&gt; statement and the comment before, the remainder of the &lt;code&gt;.bashrc&lt;/code&gt; is
only run for interactive shells.
The variable definitions must appear before the &lt;code&gt;case&lt;/code&gt; statement, as shown.&lt;/p&gt;
&lt;h2 id=&#34;userservice-not-enabled-and-started&#34;&gt;
    &lt;a href=&#34;#userservice-not-enabled-and-started&#34;&gt;
	&lt;code&gt;user@.service&lt;/code&gt; not enabled and started
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The user-based &lt;code&gt;systemd&lt;/code&gt; component was not enabled and started.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# systemctl enable user@.service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# systemctl start user@1011.service    # the userid of the user I needed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;defining-the-service&#34;&gt;
    &lt;a href=&#34;#defining-the-service&#34;&gt;
	Defining the service
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The service we want to run is a Python program in a virtual environment,
logging to stdout and stderr.
It needs to be started by &lt;code&gt;systemd&lt;/code&gt; as the service user.&lt;/p&gt;
&lt;p&gt;We check out the repo and create virtual environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# sudo -Hi theserviceuser&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ git checkout git@github.com:theuser/therepo.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ python3 -m venv venv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; venv/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will check out the source, create a &lt;code&gt;venv&lt;/code&gt; and then activate it and install the requirements.&lt;/p&gt;
&lt;p&gt;We can now create a service.
As the service user, run &lt;code&gt;systemctl --user edit --full theservice.service&lt;/code&gt; and install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-systemd&#34; data-lang=&#34;systemd&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# /home/theserviceuser/.config/systemd/user/theservice.service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Unit]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;The Service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;After&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;syslog.target network.target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Service]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Type&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;simple&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;WorkingDirectory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;ExecStart&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo/venv/bin/python3 /home/theserviceuser/therepo/main.py&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;Restart&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;on-abort&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;EnvironmentFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;/home/theserviceuser/therepo/.env&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;[Install]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;WantedBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;multi-user.target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By using the Python instance from the &lt;code&gt;venv&lt;/code&gt;, we will automatically use stuff from the &lt;code&gt;venv&lt;/code&gt;, no activation required.&lt;/p&gt;
&lt;p&gt;We can now update all this with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user stop theservice.service
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ git pull --rebase
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ systemctl --user start theservice.service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or a script that does the same.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL: InnoDB Fragmentation</title>
      <link>https://blog.koehntopp.info/2023/07/06/mysql-innodb-fragmentation.html</link>
      <pubDate>Thu, 06 Jul 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/07/06/mysql-innodb-fragmentation.html</guid>
      <description>&lt;p&gt;There is a really nice article by Pep Pla, over at
&lt;a href=&#34;https://www.percona.com/blog/the-impacts-of-fragmentation-in-mysql/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the Percona blog&lt;/a&gt;


about fragmentation in MySQL InnoDB tablespaces, which you should read.&lt;/p&gt;
&lt;p&gt;The article discusses &amp;ldquo;fragmentation&amp;rdquo; of data in tables, which happens in a way similar to how it happens in filesystems.&lt;/p&gt;
&lt;p&gt;InnoDB stores data by default in tablespaces, which by default are a file per table.
These files are subject to the fragmentation and growth rules of your filesystem,
but if you are smart, you are running MySQL on Linux on the XFS.
In that case, filesystem fragmentation (and unexplained commit latency variance) are not an issue,
because XFS takes care of handling this properly, and only database-internal fragmentation remains.&lt;/p&gt;
&lt;h1 id=&#34;primary-keys-data-order-and-working-set-size&#34;&gt;
    &lt;a href=&#34;#primary-keys-data-order-and-working-set-size&#34;&gt;
	Primary keys, data order and working set size
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Data inside an InnoDB tablespace is placed in primary key order, and that used to matter a lot,
because rows with closer primary keys used to be stored closer together on disk.
Up to the point where rows with adjacent primary keys had a good chance of being on the same page.&lt;/p&gt;
&lt;p&gt;In the past, it mattered more than today, because even if data was not stored on the same page,
pages that were physically stored closely together (on the same HDD track or cylinder) could be loaded faster.
That was the case, since &amp;ldquo;near&amp;rdquo; disk seeks were executed faster by an HDD than &amp;ldquo;far&amp;rdquo; disk seeks across the entire surface of a hard disk.&lt;/p&gt;
&lt;p&gt;With flash, seek times are largely irrelevant:
In fact, the internal Flash Translation Layer of flash storage will put data anywhere it sees fit,
and then issue you a Logical Block Address (LBA) that has no bearing whatsoever on the actual physical location of the page on the flash drive.
It may even move the actual physical data under you behind the scenes, and still refer to it by the same LBA.&lt;/p&gt;
&lt;p&gt;What matters a lot as a concept, though, is the Working Set Size (WSS) of your database.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Working Set is the set of pages your database is going to reference in the next future interval&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This interval may be, for example, the next 1m, 10m or 1h.
That is, it makes initially limited sense to speak of the WSS as an unqualified term.
You&amp;rsquo;d have to use it with an interval instead, so the WSS-1m, WSS-10m, WSS-1h and so on.&lt;/p&gt;
&lt;p&gt;If you could predict what pages will be needed in the WSS-10m, you could preload these pages and cache them.
This would bring the disk reads to zero or close to zero for the coming 10 minutes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Predicting the future is hard, though, especially if accuracy is required.
What we do instead is look to the past and hope the future looks alike.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So most people would want to look at the past 10 minutes,
and the recorded page numbers requested from disk as a triple of &lt;code&gt;(timestamp, tablespace_id, page_number)&lt;/code&gt;.
From this, we can build a histogram for a sliding 10m window, and we would know which pages have been in demand.
From the height of the histogram counter, we would even know how much.&lt;/p&gt;
&lt;p&gt;We can now size an InnoDB buffer pool, and calculate how large this pool would have to be to cache 95%, 99%, 99.99%, &amp;hellip;
of all page read requests.
Having a handle on the desired buffer pool size for a data set and a workload would be very useful to determine the amount
of memory our database instance would need to perform adequately:
It must be sized for – at least – the estimated buffer pool plus overhead plus some safety margin,
rounded up to available instance types.&lt;/p&gt;
&lt;p&gt;Unfortunately, we can only get aggregate statistics from an unpatched MySQL, and no page-read-request timeline as shown above.
Neither can we get a page-request histogram from &lt;code&gt;P_S&lt;/code&gt;, or a properly precalculated WSS estimation.
So it is necessary to patch MySQL to get this data, unfortunately.&lt;/p&gt;
&lt;p&gt;When we do this, and math a bit on the results, we observe there is actually such a thing as a WSS without a time-interval:&lt;/p&gt;
&lt;p&gt;As long as the workload is stable,
we can identify with some confidence a set of pages that need to be cached in order to quench most of the reads.
Adding buffer pool pages past this point will not improve performance substantially,
and there might still be a certain number of residual random page reads due to random accesses in the workload.
In order to also quench these, you&amp;rsquo;d have to be able to keep the entire database in memory.
While this is sometimes possible, there are workloads where this is not economical, especially at cloud pricing structures.&lt;/p&gt;
&lt;h2 id=&#34;designing-for-locality&#34;&gt;
    &lt;a href=&#34;#designing-for-locality&#34;&gt;
	Designing for locality
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Here Pep Pla comes in again, because he highlights in his article the principle of locality,
which is exactly what the working set size is.
Specifically, WSS is temporal locality – we cache the pages we will need in the future in memory,
so that spatial locality does no longer matter.
Even when using HDD.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By choosing a primary key smartly, we can make sure that primary keys that are being accessed &amp;ldquo;together&amp;rdquo; have similar values,
and each page is filled closely with many rows that we will be needing at the same time.&lt;/p&gt;
&lt;p&gt;For a fixed data size, this lowers the number of pages active concurrently, bringing down WSS size,
bringing down pool size, bringing down instance size, bringing down cloud cost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Also, it is important to keep the row size down, so many rows fit into the same page,
and finally getting a handle on fragmentation inside a page – but this is actually the least important factor in design.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors, exposing disk read request traces (as &lt;code&gt;(ts, tablespace_id, page#)&lt;/code&gt; triples)
and deriving a histogram and a WSS metric from it remains an open TODO point.&lt;/p&gt;
&lt;p&gt;Note how &amp;ldquo;Designing for locality&amp;rdquo; is not primarily a &amp;ldquo;fragmentation&amp;rdquo; issue – the amount of empty space per page,
segment or tablespace does not matter in the first place.
Packing rows that are needed together densely is what matters: data density matters.
And empty space in a page can ultimately adversely affect that, but it is really the last item on the list.&lt;/p&gt;
&lt;h1 id=&#34;fill-factors-and-you-do-not-need-to-optimize-table&#34;&gt;
    &lt;a href=&#34;#fill-factors-and-you-do-not-need-to-optimize-table&#34;&gt;
	Fill Factors, and you do not need to &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt;
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&amp;ldquo;Empty space in a page&amp;rdquo; is a special kind of fragmentation, and in databases it is commonly called &amp;ldquo;fill factor.&amp;rdquo;
Pep Pla has been testing the behavior of InnoDB with various workloads and page fill factor settings,
and this is the first documented and systematic work in this area that I am aware of.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;innodb_space&lt;/code&gt; tool from &lt;a href=&#34;https://github.com/jeremycole/innodb_ruby&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jeremy Cole&amp;rsquo;s Tooling&lt;/a&gt;

,
he observed the behavior of InnODB after a longer term mixed insert and delete workload.&lt;/p&gt;
&lt;p&gt;The results are pretty encouraging.
Basically, according to the results from his testing,
it never made sense to run &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; to repack and re-order the data for flash storage.
Disk seeks do not matter much any more on flash,
and there will always be empty space in the pages of tables that see permanent random inserts and deletes.
So running &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; will bring the table size down and repack it,
only to create a wave of page splits immediately after when the DML workload continues and needs room to work.&lt;/p&gt;
&lt;p&gt;Pep Pla shows fragmentation maps for the same table after 400 iterations of his DML workload using different fill factors,
and it shows that the initial fill factor after an &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; is no longer visually identifiable.
Instead, all tables look similarly fragmented, so their shape is dominated by the workload, not the
&lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; and the fill factor parameters.&lt;/p&gt;
&lt;p&gt;It may be useful to &lt;code&gt;OPTIMIZE&lt;/code&gt; (and compress) tables that are being archived, but as soon as they see DML,
they will be reshaped by the workload again, and you might as well not &lt;code&gt;OPTIMIZE&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;designing-for-locality-vs-uuid&#34;&gt;
    &lt;a href=&#34;#designing-for-locality-vs-uuid&#34;&gt;
	Designing for locality vs UUID
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;It is worth mentioning that very many tables have a row-access frequency that matches the rows primary key,
if the rows&amp;rsquo; primary key is an &lt;code&gt;auto_increment&lt;/code&gt;.
That is, very many applications frequently access rows that have recently been written,
while older rows are being used much less frequently.&lt;/p&gt;
&lt;p&gt;By using &lt;code&gt;auto_increment&lt;/code&gt; primary keys,
data is automatically ordered physically so that &amp;ldquo;cold data&amp;rdquo; is at the front of the table and &amp;ldquo;hot data&amp;rdquo; is at the end.
This also puts hot rows together into the same page or pages close by, at the end of the table.
This is good for performance in InnoDB, and also keeps the WSS down.&lt;/p&gt;
&lt;p&gt;Using a random primary key (a MD5 or a UUID v4) will not impose any order on the primary key.
In InnoDB, where the primary key value determines the physical position of the row in the table,
this essentially scatters rows across the entire table.
This creates a very large working set, bloating required buffer space, and increasing instance size:
There will be a hot row in any page with the same probability, so you&amp;rsquo;ll have to cache all pages to quench reads.&lt;/p&gt;
&lt;p&gt;Using a UUID v1 is better because they have a temporal component,
which can be used to leverage an &lt;code&gt;auto_increment&lt;/code&gt;-like ordering.
Unfortunately, MySQL does not do this by providing a UUID v1 data type, which does the right thing automatically.
Instead, we get to use a pair of functions &lt;code&gt;UUID_TO_BIN()&lt;/code&gt; and &lt;code&gt;BIN_TO_UUID()&lt;/code&gt;,
which require you to manually cast the data every time you access it and remember to set the swap flag properly.
This is very uncomfortable and error-prone,
more so in large development organizations.&lt;/p&gt;
&lt;p&gt;Try to use &lt;code&gt;auto_increment&lt;/code&gt; with MySQL InnoDB.
If you can&amp;rsquo;t, try to go with UUID v1 and the &lt;code&gt;UUID_TO_BIN()&lt;/code&gt; functions, with the swap flag set.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors, it remains an open TODO point to provide a UUID v1 and a UUID v4 data type.&lt;/p&gt;
&lt;h1 id=&#34;row-fragmentation&#34;&gt;
    &lt;a href=&#34;#row-fragmentation&#34;&gt;
	Row Fragmentation
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;MySQL InnoDB is famously bad at storing files, and Pep Pla discusses that cursory, too.
In fact, the Percona Blog also provides
&lt;a href=&#34;https://www.percona.com/blog/how-innodb-handles-text-blob-columns/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;another article on this&lt;/a&gt;


with some more depth, which is a lot more opinionated than the official manual on the subject at hand.&lt;/p&gt;
&lt;p&gt;Basically, when a row becomes too large (at 1/2 page size, 8 KB),
InnoDB stores individual fields of a row &amp;ldquo;off-table&amp;rdquo; in overflow pages.
The article does not discuss this, but to my knowledge, each overflow page holds only one field,
so the overhead is statistically much larger than &amp;ldquo;on average 1/2 page&amp;rdquo; as stated in that article.
This effect becomes stronger if you have tables with multiple BLOB/TEXT columns in a row,
and each is just barely large enough to trigger off-table storage.&lt;/p&gt;
&lt;p&gt;Accessing data that is stored in overflow pages uses up additional buffer pool pages to hold them,
at a rate of at least one per overflowed field, increasing the working set size, and hence necessary instance size.
In versions of MySQL before MySQL 8, such data also forced the use of on-disk temporary tables,
which impacted query performance badly to a large extent,
but this is now fortunately fixed.&lt;/p&gt;
&lt;p&gt;So in the past, the general advice was to avoid TEXT/BLOB columns altogether,
and if you must use them, do not use them as part of a join or any query that was marked as &amp;ldquo;using temporary.&amp;rdquo;
Since MySQL 8, this is much better, but still be aware of the working set size increase.&lt;/p&gt;
&lt;p&gt;For the various MySQL flavors remains an open TODO point to provide a more efficient (Postgres TOAST-like?) BLOB storage,
in order to bring down storage overhead.&lt;/p&gt;
&lt;p&gt;Another long-standing BLOB performance-related work item that is not linked to fragmentation
would be to provide a &amp;ldquo;partial updates&amp;rdquo;/&amp;ldquo;BLOB streaming&amp;rdquo; API in the protocol,
because this is another well-known point of inefficiency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try to store a BLOB larger than &lt;code&gt;max_allowed_packed&lt;/code&gt; in the database.&lt;/li&gt;
&lt;li&gt;Try to change 4 bytes at offset 32M in a 64M BLOB efficiently using MySQL protocol.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you do, and observe what happens on the wire, in memory and on disk, you&amp;rsquo;d be scared.
Until it is fixed, use the filesystem or S3 for this, and store filenames or URLs instead.&lt;/p&gt;
&lt;h1 id=&#34;recommendations&#34;&gt;
    &lt;a href=&#34;#recommendations&#34;&gt;
	Recommendations?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;You probably do not need to care much about fragmentation if your database uses flash-based storage.
InnoDB is relatively stable for DML workload, and &lt;code&gt;OPTIMIZE TABLE&lt;/code&gt; is usually not worth the effort,
unless you move a table to archive/read-only.&lt;/li&gt;
&lt;li&gt;You would do well to design for data density and temporal locality, bringing down working set size.
&lt;ul&gt;
&lt;li&gt;Often this happens automatically when using &lt;code&gt;auto_increment&lt;/code&gt; as a primary key.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Even in MySQL 8, you would still do well to keep BLOB and TEXT fields out of main tables,
or where it makes sense, out of the database completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Server Side improvements needed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL has no good instrumentation that can trace disk read requests by &lt;code&gt;(ts, tablespace_id, page#)&lt;/code&gt;,
making it hard to estimate working set size, and derive an optimal instance size from it.
You will need to patch the database server in order to grab this data.
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;li&gt;MySQL should have a UUID v1 and a UUID v4 data type, which would be a lot less error-prone that the
current set of functions.
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;li&gt;MySQL has an abysmally underdeveloped BLOB storage and long-standing gaps in its BLOB access API
(efficient partial updates, BLOB streaming).
This needs fixing in the mainline server source.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Great Resignation, Management Edition</title>
      <link>https://blog.koehntopp.info/2023/06/22/a-great-resignation-management-edition.html</link>
      <pubDate>Thu, 22 Jun 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/06/22/a-great-resignation-management-edition.html</guid>
      <description>&lt;p&gt;This is not much of a blog post, but just a &lt;a href=&#34;https://chaos.social/@isotopp/110586700595558261&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;thread dump from Mastodon&lt;/a&gt;

 as requested by a friend,
because my Mastodon posts expire after some time.&lt;/p&gt;
&lt;p&gt;Based on my work and the people I know, I have some (remote) view into what happens in a few companies at the C- and Mid-Level management.
And from where I sit, it seems the great resignation is not only a thing that affects workers, but also managers.
It is almost funny.&lt;/p&gt;
&lt;p&gt;These people are often pretty awesome administrative people.
Mid-level managers with amazing Jira- and Miro-skills, breaking down large work parcels of well-understood jobs into team-sized packages,
describing the requirements and planning the required hours, then mapping them onto calendars.
Or budget jugglers that take large unstructured sums of cost, and find a way to parcel them out in a halfway reasonable way into individual cost centers and items.&lt;/p&gt;
&lt;h1 id=&#34;digital-and-other-transformations&#34;&gt;
    &lt;a href=&#34;#digital-and-other-transformations&#34;&gt;
	Digital and other transformations
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;These companies are also all in a series of transformations, at all levels of the stack simultaneously.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many are moving on-premises workloads to cloud, but the workloads are not cloud-shaped.&lt;/li&gt;
&lt;li&gt;Two enterprises I happen to know about are also changing their implementation language from something exotic to something less efficient, but a lot easier to hire for.&lt;/li&gt;
&lt;li&gt;One enterprise is also breaking up a monolithic application into a set of microservices, but the cut lines are unclear and need to be found.&lt;/li&gt;
&lt;li&gt;One enterprise is modifying the way they do business from a single product to a series of interconnected and interdependent products, some of them in highly regulated markets.&lt;/li&gt;
&lt;li&gt;Another enterprise is changing the way they make their product from mostly manual labor into something based on sensor input and data science.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These transformations require a different kind of manager:
they need less of an administrative person, and more business process designer;
they require a different kind of empowerment and delegation, from the top to them, and from them on downwards – much more autonomous on the delegation poker side;&lt;/p&gt;
&lt;p&gt;What is also needed is an entirely different kind of understanding of the company itself, less interchangeable business administration skills,
and more business-specific skills about how the sausage is made.&lt;/p&gt;
&lt;p&gt;On top of that are traditional hierarchies and communication structures that are based on in-person attendance and mostly oral tradition,
and a skill-set that is well suited for the Clear and Complicated domains of &lt;a href=&#34;https://en.wikipedia.org/wiki/Cynefin_framework&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the Cynefin-Model&lt;/a&gt;

,
but wrong for the Complex and Chaotic domains.&lt;/p&gt;
&lt;p&gt;The Enterprise cannot perform the set of transitions it must execute to stay relevant,
when the entire Org and the people that carry and build the structure of the Org are incapable of transforming their way of working to match the problem.
So they leave.&lt;/p&gt;
&lt;p&gt;Which for an organization that is in the Complex and Chaotic realm of a transformation makes the problem worse,
because the intimate knowledge of the processes that make this company unique and competitive goes with them.
The people coming in have to learn these things,
but if the Org does not have &lt;em&gt;written&lt;/em&gt; account of what matters and has no way of &lt;em&gt;teaching&lt;/em&gt; these things that make this company special,
it basically loses its specialty and becomes meaningless, interchangeable and then soon extinct.&lt;/p&gt;
&lt;h1 id=&#34;what-remote-work-does-for-companies&#34;&gt;
    &lt;a href=&#34;#what-remote-work-does-for-companies&#34;&gt;
	What Remote Work does for companies
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Funnily,
companies that optimize for remote work are also companies
that out of necessity optimize for a written instead of an oral culture.
They tend to have very well documented ways of specifying and teaching what they do, why and how,
and a proper self-service onboarding process complemented by a mentoring system –
and that also works for mid- and C-level management.&lt;/p&gt;
&lt;p&gt;Companies that optimize for remote are executing transformations easier because they understand their meta better.
Many workers understand that.
Maybe not in this way or even in words, but they can read the room, and they are reacting to their environment, especially the skilled ones.&lt;/p&gt;
&lt;p&gt;A preference for remote work is useful even, or especially, if you come into the office,
because a company that can do remote properly understands what it does and how it works better than a company that executes &amp;ldquo;remote&amp;rdquo; with a &amp;ldquo;zoom harder&amp;rdquo; policy.&lt;/p&gt;
&lt;h1 id=&#34;interviewing-to-find-organizations-that-know-their-stuff&#34;&gt;
    &lt;a href=&#34;#interviewing-to-find-organizations-that-know-their-stuff&#34;&gt;
	Interviewing to find organizations that know their stuff
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;So when you interview, these are useful and interesting questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How did your company change their way of working during Covid?&lt;/li&gt;
&lt;li&gt;How did your management style evolve under Covid and after?&lt;/li&gt;
&lt;li&gt;How do you detect misalignment, disagreement or conflict or other causes for in-person meetings when working remotely,
and what are the ways you handle these situations?&lt;/li&gt;
&lt;li&gt;How do you evolve agreement from oral consensus to documentation to training material?
How do you document and teach processes?&lt;/li&gt;
&lt;li&gt;How did your way of working as a person and as a member of the Org evolve in the last 5 years?
What can you point to that illustrates process maturation and advancement?&lt;/li&gt;
&lt;li&gt;In what way did your Org execute transformations in the last five years?
That certainly was not frictionless.
What worked, what didn&amp;rsquo;t, what did the Org learn?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If that reads a lot like a reverse interview – well, that&amp;rsquo;s what it is.&lt;/p&gt;
&lt;p&gt;But the objective is clear:
You want to find out if the org you are about to join has access to its own meta,
and if it can change and consciously design its org structure, work, and communications culture.&lt;/p&gt;
&lt;p&gt;All companies right now are executing a series of transformations at multiple levels of their business.
That is because the world right now is a lot less stable than it used to be in the last 50 years.
But only those that do not let these things happen to them, but are actively shaping the process will not be painful to work at.&lt;/p&gt;
&lt;p&gt;You must find these early in the interview process.&lt;/p&gt;
&lt;p&gt;In any case, the information you want to find when interviewing for a job is again:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Does this company shape itself and its future consciously?
Does it design itself?
Or does change happen to the org accidentally?
Does it understand what it does, and why? Or are they winging it?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Most management is winging it, most companies are cheating their way to the next quarterlies.&lt;/p&gt;
&lt;p&gt;You do your work, but you do have an understanding of what management is supposed to do.
Does management understand their job, tho?&lt;/p&gt;
&lt;p&gt;Can you respect your current or future management?
Can they express the value they provide in a way &lt;em&gt;that is understandable and meaningful to you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Can they explain the business, and what specifically the competitive advantage is this org has within its own competitive set?
Do they know why this differentiation exists, and how it is protected or extended?
Do they understand in what way the structure they are building and upholding helps in doing this?
And how it needs to change to be able to continue?&lt;/p&gt;
&lt;p&gt;Basically, you want to find out if they know the C-level strategy they exist in.
If they know what direction everybody is supposed to march in, and what their local objectives are as a part of the greater whole.
You need to find out if they have context that they are making local decisions in.&lt;/p&gt;
&lt;p&gt;Incidentally, it is this (and not ping-pong tables) that builds engagement and loyalty.&lt;/p&gt;
&lt;p&gt;People love to work for a company that understands how it functions,
and can talk sensibly about this – about its business and communication processes,
and the why and how of useful interaction.&lt;/p&gt;
&lt;p&gt;People love to work for organizations that have an idea of how to change and into what, instead of being shaped by accident.&lt;/p&gt;
&lt;h1 id=&#34;stressors&#34;&gt;
    &lt;a href=&#34;#stressors&#34;&gt;
	Stressors
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Another contributing factor is that transformations interrupt the value extraction process of neoliberal shareholder value,
and also upsets established hierarchies.&lt;/p&gt;
&lt;p&gt;Shifting to the left side of the Cynefin model means you need smaller teams of higher qualified people.
Teams that perform work in a way that is much harder to quantify,
and create value that is hard to express in right-side organizational structures.&lt;/p&gt;
&lt;p&gt;That is, shareholders and their demand for dividend and rising stock value interfere with the investment needs,
increased risk and hard to measure gains that transformations require,
and thus the owners of the enterprise are an impediment to the change that the company needs to be able to continue to deliver value to them.&lt;/p&gt;
&lt;p&gt;That is, some individual owners always understand that problem,
but the owners as a group don&amp;rsquo;t and can&amp;rsquo;t and are working against their own best interest.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Side Remark:&lt;/em&gt; Similar structural pressure is currently visible in German society, at the &amp;ldquo;Berlin vs. Berlin Outskirts&amp;rdquo; conflict or at the national mobility and energy transformation.&lt;/p&gt;
&lt;h1 id=&#34;side-remarks-from-the-pandemic-coping-discord&#34;&gt;
    &lt;a href=&#34;#side-remarks-from-the-pandemic-coping-discord&#34;&gt;
	Side Remarks from the Pandemic Coping Discord
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;a-friend-gives-an-example-at-the-individual-level&#34;&gt;
    &lt;a href=&#34;#a-friend-gives-an-example-at-the-individual-level&#34;&gt;
	A friend gives an example at the individual level
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;IC: &amp;ldquo;The existing code is bad and undocumented. Three weeks for the fix, provided there are no landmines.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;So you commit to 3w?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;IC: &amp;ldquo;No, because I don&amp;rsquo;t know if there are landmines. Usually there are.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;But I need a binding commitment to before the end of July!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s lack of tech understanding paired with pressure from the shareholder end.&lt;/p&gt;
&lt;h2 id=&#34;another-friend-talks-about-stressors&#34;&gt;
    &lt;a href=&#34;#another-friend-talks-about-stressors&#34;&gt;
	Another friend talks about Stressors
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;M: &amp;ldquo;My personal theory is that we are running into some inherent limits of the current management model during the last decade and are now seeing stress fractures.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;But the question is where the stress is originating.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;Complexity (as observed at each management level).&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;Ok, that matches what I think if you accept that it is these transformations that are causing the stress. What you call stress fractures I call transformation overload.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M (responding to the three-week-commitment example above):
&amp;ldquo;A good example for what I mean by complexity at that management level:
The manager can communicate only a scalar detail upwards, but the problem is a complex data object.
The manager cannot report what happens nor the risk properly.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;K: &amp;ldquo;A command and control management is unable to handle situations that require nuance and understanding of detail?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;Yes. Management level A needs to reduce their stress, and forces their lower level B to simplify. That increases pressure and stress at the level of B.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: C has called this &amp;ldquo;driven by financials.&amp;rdquo;
The only universal scalar is Euro,
but expressing all things in Euros is becoming increasingly harder and is losing information.&lt;/p&gt;
&lt;p&gt;M: A lot of fighting and pressure is actually about &amp;ldquo;simplify your reporting&amp;rdquo; vs. &amp;ldquo;accept my complexity.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;This is also in part why we see a preference for managed services. They are an attempt to encapsulate complexity. Often that fails, and the complexity reappears and attacks the PO consuming that service.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;C: &amp;ldquo;A way to solve the conflict is to ask more &amp;lsquo;Why&amp;rsquo; questions downstack, and to create more tasks that allow for interpretation.&amp;rdquo;
That is basically a move to the left-hand side of Cynefin.&lt;/p&gt;
&lt;p&gt;M: &amp;ldquo;That requires a trust that is larger than Euro-Scalars. And ultimately that breaks at the shareholder-level, latest.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;H2: &amp;ldquo;And non-technical management also believes these things are simple. Click here, and ChatGPT will develop the software autonomously. It&amp;rsquo;s those pesky IT people making all these things that complicated.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What to do with self-driving car data?</title>
      <link>https://blog.koehntopp.info/2023/06/12/what-to-do-with-self-driving-car-data.html</link>
      <pubDate>Mon, 12 Jun 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/06/12/what-to-do-with-self-driving-car-data.html</guid>
      <description>&lt;p&gt;This is what a self-driving car sees, or constructs from the sensor data it uses:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-01.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Screenshot from &lt;a href=&#34;https://youtu.be/JC94Y063x58?t=38&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How is LiDAR remote sensing used for Autonomous vehicles?&lt;/a&gt;

&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Specifically, LIDAR data is supposed to be extremely accurate and fast,
&lt;a href=&#34;https://www.asprs.org/a/publications/proceedings/fall2006/0009.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lidar Data Accuracy&lt;/a&gt;


claims 2-3cm resolution and many scans per second for aircraft LIDAR, and
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8659977/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Assessing Vehicle Profiling Accuracy of Handheld LiDAR&lt;/a&gt;


claims similar resolution for casual LIDARing crash scenes with Apple handheld hardware.&lt;/p&gt;
&lt;p&gt;Autonomous vehicles are using this data to detect other traffic, vehicles and persons, to classify them,
and to model their behavior.
For this, they are building a model of the world around them,
in which the position and the speed vector of anything detected is very well known and tracked.
It stands to reason that this is a very well-calibrated system, because if it were not,
the car would build the world-model wrongly and hit other people or things.&lt;/p&gt;
&lt;h1 id=&#34;questions-for-self-driving-car-builders&#34;&gt;
    &lt;a href=&#34;#questions-for-self-driving-car-builders&#34;&gt;
	Questions for self-driving car builders
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;detecting-speeding-while-driving&#34;&gt;
    &lt;a href=&#34;#detecting-speeding-while-driving&#34;&gt;
	Detecting speeding while driving
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-02.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Albrechtstraße, driving towards Wenckebachstraße, in Berlin. To the right a playground. This road is a &amp;ldquo;30 zone&amp;rdquo;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Consider this car driving in a 30 zone in Berlin towards the main road. It is being passed on the left by another car,
driving&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;35 km/h&lt;/li&gt;
&lt;li&gt;50 km/h&lt;/li&gt;
&lt;li&gt;70 km/h&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this situation, should the self-driving car send a report to the police for a traffic-violation (speeding) automatically?
If yes, why at this threshold and not any other? If no, why should the car ignore this?&lt;/p&gt;
&lt;h2 id=&#34;detecting-speeding-while-parking&#34;&gt;
    &lt;a href=&#34;#detecting-speeding-while-parking&#34;&gt;
	Detecting speeding while parking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Consider the same situation, but the car is parked in a GDPR-compliant &amp;ldquo;Sentry Mode&amp;rdquo;.
That is, the car does not record any data from the public space, unless it has reason to (for example, because it is being burglared).
But of course its sensors do not stop at a road boundary, and it still somehow notices the speeding happening.&lt;/p&gt;
&lt;p&gt;Should it report the traffic violation, or let it go?
If it should let it go despite having a recording, why? If the threshold is different from driving, why?&lt;/p&gt;
&lt;h2 id=&#34;the-offending-car-could-have-been-on-auto-but-it-was-not&#34;&gt;
    &lt;a href=&#34;#the-offending-car-could-have-been-on-auto-but-it-was-not&#34;&gt;
	The offending car could have been on auto, but it was not
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Consider the offending, speeding car to be a model at least as capable as the model doing the recording.
It could drive autonomously, and if it were, it would have been following the posted speed limit of 30 km/h.
But the driver disabled the autonomous mode and manually and willfully speeded.&lt;/p&gt;
&lt;p&gt;Should the driver be fined normally or get a different fine? Why?&lt;/p&gt;
&lt;p&gt;Should that car have reported itself and its driver? Why or why not?&lt;/p&gt;
&lt;h2 id=&#34;the-recording-car-is-parked-illegally&#34;&gt;
    &lt;a href=&#34;#the-recording-car-is-parked-illegally&#34;&gt;
	The recording car is parked illegally
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The driver of the recording car tries to park illegally:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/06/self-driving-03.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Wenckebachstrasse 1, Berlin. The driver tries to park to the right of the Seat and the red-white boundary.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The car has a map of legal parking spaces in the area available, and can position itself within 3 cm accuracy.
The driver tries to park it to the right of the Seat and the red-white boundary.
The car warns the driver, and is overridden.
Behind the driver on the other side of the road is a playground.
The building in front of the driver is the Wenckebach Hospital.&lt;/p&gt;
&lt;p&gt;Should the car self-report the parking violation? Should this include data about the driver?
Should another car spotting this report the parking violation?
Or should only a &lt;a href=&#34;https://algoritmeregister.amsterdam.nl/en/automated-parking-control/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scanauto&lt;/a&gt;

 report this once it spots it on its tour?
Why or why not?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting rid of phishing training mails</title>
      <link>https://blog.koehntopp.info/2023/05/23/getting-rid-of-phishing-training-mails.html</link>
      <pubDate>Tue, 23 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/23/getting-rid-of-phishing-training-mails.html</guid>
      <description>&lt;p&gt;Just like your work computer is being infested with corporate malware as to prevent it from being taken over from other people&amp;rsquo;s malware,
your account is also being spammed with corporate malware spam as to prevent it from being taken over by other malware spam.
And just like corporate malware &lt;a href=&#34;https://blog.koehntopp.info/2018/06/18/websense-dlp-gives-instant-root.html&#34;&gt;increases your machine&amp;rsquo;s attack surface&lt;/a&gt;

,
because it is &lt;a href=&#34;https://blog.koehntopp.info/2017/10/20/aslr.html&#34;&gt;badly written&lt;/a&gt;

 and running with privileges,
corporate spam is a useless &lt;a href=&#34;https://publikationen.bibliothek.kit.edu/1000119662&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nuisance&lt;/a&gt;

 that
&lt;a href=&#34;https://blog.lukaszolejnik.com/solving-phishing-is-not-simple-can-anti-phishing-training-make-it-even-worse/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doesn&amp;rsquo;t do what it is supposed to do&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Of course, working in an enterprise, you will be subjected to such campaigns anyway.
So the best outcome for you would be to identify a phishing training campaign when it runs the first time,
and then upgrade your filters so that you will never be bothered again.&lt;/p&gt;
&lt;p&gt;The good news is that all phishing training campaigns have automatically detectable traits,
mostly X-Header lines, because the campaign needs to be able to deliver quantifiable results to the corporate overlords that pay for it.
And of course, we can filter for these.&lt;/p&gt;
&lt;h1 id=&#34;the-x-header&#34;&gt;
    &lt;a href=&#34;#the-x-header&#34;&gt;
	The X-Header
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;What X-Header actually is being used depends a lot on the Phishing Training service provider your company is using.
It may be something such as &lt;code&gt;X-KnowB4&lt;/code&gt; or &lt;code&gt;X-PhishMe&lt;/code&gt; or similar.
To find out what it is, you need to check the actual raw message content.&lt;/p&gt;
&lt;p&gt;In Mail.app, select the message you have identified as phishing training mail, and select
&lt;code&gt;View -&amp;gt; Message -&amp;gt; Raw Source (⌥⌘U)&lt;/code&gt;.
Then check for lines that start with &lt;code&gt;X-&lt;/code&gt; in the header that identify the training provider or reference &amp;ldquo;Phish&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-06.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See Message Raw Source in Mail.app.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In Outlook for Mac, select the message you have identified as phishing training mail, and select
&lt;code&gt;View Source&lt;/code&gt;.
Then check for lines that start with &lt;code&gt;X-&lt;/code&gt; in the header that identify the training provider or reference &amp;ldquo;Phish&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-07.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See Message Raw Source in Outlook for Mac.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The line you are looking for might be looking like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-08.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;*In our case, the line identifying the phishing training mails looks like &lt;code&gt;X-Phishme: Phishing_Training&lt;/code&gt;.
In fact, we only care about the presence of the &lt;code&gt;X-PhishMe&lt;/code&gt; header line and the actual value after the &lt;code&gt;:&lt;/code&gt; is completely irrelevant.&lt;/p&gt;
&lt;p&gt;This header, in the exact spelling shown, is what we want. It is best to copy and paste it to prevent spelling errors.&lt;/p&gt;
&lt;h1 id=&#34;mailapp&#34;&gt;
    &lt;a href=&#34;#mailapp&#34;&gt;
	Mail.app
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;m on a Mac, and for a long time my corporate email was on Gmail.
Unfortunately, Gmail cannot filter on arbitrary X-headers, and registering an application to OAuth against corporate mail is complicated.
But Apple&amp;rsquo;s &lt;code&gt;Mail.app&lt;/code&gt; comes preregistered, was allowed, and can filter.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-01.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;So I can just sacrifice another 200 MB or so to the God of Better Mail and get proper filters in return.
In any case, &lt;code&gt;⌘-,&lt;/code&gt; (&amp;ldquo;Cmd-Comma&amp;rdquo;) gives me the &lt;code&gt;Rules&lt;/code&gt; menu, and from there I can &lt;code&gt;Add Rule&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-02.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;You would want to add a filter on the Header-Line &lt;code&gt;X-PhishMe&lt;/code&gt;.
For what, we want to create a rule that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-03.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is what our filter should look like, but it can&amp;rsquo;t.
That is, because the first time around Mail.app does not know about this &lt;code&gt;X-&lt;/code&gt; header.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Currently, your Mail.app does not yet understand this particular X-Header, so when you want to create this rule,
you need to &lt;code&gt;Edit header list...&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-04.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;and then add the header to the list of known header lines:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-05.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Only now can you create the filter as shown above.
In this example, I have moved the message to the Trash Bin, but you can choose any target you want.
Whatever you do, make sure that the last action you choose is &amp;ldquo;Stop evaluating rules&amp;rdquo;, then hit OK.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now drag the rule up so that it becomes the first rule in the list.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You are done.&lt;/p&gt;
&lt;h1 id=&#34;outlook&#34;&gt;
    &lt;a href=&#34;#outlook&#34;&gt;
	Outlook
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In Outlook for Mac, also hit &lt;code&gt;⌘-,&lt;/code&gt; (&amp;ldquo;Cmd-Comma&amp;rdquo;) and choose &lt;code&gt;Rules&lt;/code&gt;.
Create a new rule and make sure it is enabled:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-09.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The rule should look like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/phish-10.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;That is, move the message to a folder of your choice, and make sure to enable &amp;ldquo;Stop processing more rules&amp;rdquo;.
Make sure the rule is the first one in the list.&lt;/p&gt;
&lt;p&gt;You are done.&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;
    &lt;a href=&#34;#summary&#34;&gt;
	Summary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;All phishing trainings need to have uniquely identifiable marks in order for the training campaign to produce the required key performance indicators.
We can find these labels and use them to filter.
Our mailer will automatically ignore subsequent runs of the phishing training, for our peace of mind.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: towards 2004 – LFS</title>
      <link>https://blog.koehntopp.info/2023/05/17/50-years-in-filesystems-towards-2004-lfs.html</link>
      <pubDate>Wed, 17 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/17/50-years-in-filesystems-towards-2004-lfs.html</guid>
      <description>&lt;p&gt;This is part 5 of a series.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo; on the traditional Unix Filesystem.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo; on the BSD Fast File System.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html&#34;&gt;1994&lt;/a&gt;

&amp;rdquo; on SGI XFS.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html&#34;&gt;Vnodes&lt;/a&gt;

&amp;rdquo; on how to have multiple filesystems in Unix.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see by comparing modern educational material and the problems discussed with older material.
Or look for the research papers and sources that fueled the change. So this is what we do.&lt;/p&gt;
&lt;h1 id=&#34;frontiers-in-the-nineties&#34;&gt;
    &lt;a href=&#34;#frontiers-in-the-nineties&#34;&gt;
	Frontiers in the Nineties
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;SGI&amp;rsquo;s XFS is pretty much the culmination point in filesystem technology for anything that does in-place updates.
Extents, generous usage of B+-trees and lock splitting across allocation groups make it a great filesystem that is fast and scales well.
The introduction of a metadata log allows it to recover quickly.&lt;/p&gt;
&lt;p&gt;The Nineties were also busy with operating systems research.
Specifically, cluster operating systems were very much en vogue:
Tanenbaum was in Amsterdam, busy with &lt;a href=&#34;https://en.wikipedia.org/wiki/Amoeba_%28operating_system%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amoeba&lt;/a&gt;

.
Bell Labs was busy with &lt;a href=&#34;https://en.wikipedia.org/wiki/Plan_9_from_Bell_Labs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plan 9&lt;/a&gt;

.
And at the UCB, Ousterhout was working on &lt;a href=&#34;https://en.wikipedia.org/wiki/Sprite_%28operating_system%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sprite&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;All were experimenting with cluster-unified filesystems, distributed processing, workload migration,
and generally trying to build what 20 years later would become the &lt;a href=&#34;https://www.amazon.com/Datacenter-Computer-Introduction-Warehouse-Scale-Architecture/dp/159829556X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Warehouse-Scale Computer&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Part of the Sprite development at UCB, specifically, was the Log-Structured File System (LFS), and
Mendel Rosenblum and John K. Ousterhout present it in &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/sd93/seltzer.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this paper&lt;/a&gt;

 from 1992.
This is a long paper, 27 pages, but if you read it with hindsight, you can really appreciate how enlightened it was.&lt;/p&gt;
&lt;h1 id=&#34;lfs&#34;&gt;
    &lt;a href=&#34;#lfs&#34;&gt;
	LFS
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Filesystems with in-place updates are in part already using logs for faster recovery in 1992.
The paper poses the question &amp;ldquo;What if we had a filesystem that only had a log, and never did in-place updates?&amp;rdquo;,
calling it a log-structured file system.
It then proceeds to present an implementation and benchmarks for such a thing.&lt;/p&gt;
&lt;h2 id=&#34;reads-are-cached-only-writes-matter&#34;&gt;
    &lt;a href=&#34;#reads-are-cached-only-writes-matter&#34;&gt;
	&amp;ldquo;Reads are cached, only writes matter&amp;rdquo;
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In working with distributed operating systems, the Sprite team noticed that they have a lot of memory available.
They found with increasing memory sizes, the probability of a file being served by the buffer cache instead of reading it from disk increased by a lot,
and eventually almost all disk reads are being served from memory.&lt;/p&gt;
&lt;p&gt;Writes cannot be cached very well, and eventually they need to hit persistent storage,
but with the reads being cached it would be worthwhile and possible to construct a filesystem optimized for writes.&lt;/p&gt;
&lt;p&gt;The team also observes that CPU speeds grow exponentially, following Moore&amp;rsquo;s law.
The same seems to be true for memory sizes, which being on-chip silicon structures also obey this law.
But disks do not work that way.
While their capacity grows, their transfer speed and seek time does not improve much, because mechanical parts do not obey Moore&amp;rsquo;s law.
Disks are a problem: While linear writes perform well, seeks are slow and are not getting faster much.&lt;/p&gt;
&lt;p&gt;So they propose never overwriting any data, but always appending changed blocks to the end of a log.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/log-adoption.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;“Ah you think the log is your ally? You merely adopted the log. I was born with it, designed for it.”&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;garbage-collection&#34;&gt;
    &lt;a href=&#34;#garbage-collection&#34;&gt;
	Garbage collection
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Of course, disks in the Nineties were finite, as they are now.
So there has to be a &lt;em&gt;cleaner&lt;/em&gt; process that identifies, frees and compacts space that is no longer needed by any current view of the filesystem.&lt;/p&gt;
&lt;p&gt;This is much like the Garbage Collection in Java Virtual Machines, which were invented around the same time.
And much like the GC in JVMs, it would turn out to be the weak spot of the system.&lt;/p&gt;
&lt;p&gt;A lot of the paper busies itself with simulating workloads on the filesystem with different cleaner policies,
and the team then lands on a system that very much evolves in the same way Java GC evolved,
with a multi-tier compaction process that mirrors the &amp;ldquo;Young&amp;rdquo;, &amp;ldquo;Old&amp;rdquo;, and &amp;ldquo;Permanent&amp;rdquo; generations of Java objects.
This is not entirely surprising from hindsight:
Other, newer systems such as Cassandra, Zookeeper and other storages that use LSM Trees are using a very similar strategy with good success.&lt;/p&gt;
&lt;p&gt;Specifically, LFS partitions the storage into contiguous segments, and cleans storage segment by segment:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We used a simulator to explore different cleaning policies and discovered a simple but effective algorithm based on cost and benefit:
it segregates older, slowly changing data from younger rapidly changing data and treats them differently during cleaning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Other code takes multiple nearly empty segments of the same age and copies them together into a single segment, freeing up the others.&lt;/p&gt;
&lt;p&gt;This creates a certain amount of background copy activity from the cleaner process.
It also creates a race between the writers to the system using up free space,
and the cleaner process trying to provide sufficient free space.
If the system writes data heavily and free space goes down, the cleaner may need to be prioritized higher,
consuming more I/O, in order to make sufficient progress in providing clean segments to write to.
This will also slow down the writers.&lt;/p&gt;
&lt;p&gt;Benchmarks executed as part of the research show that the system can indeed write to disk at up to 70% of the theoretically available maximum bandwidth.
But this is true only under ideal conditions.
Also, the data is not stored in read-order at all, so read performance is only good if data is actually cached.&lt;/p&gt;
&lt;p&gt;Segments are sufficiently large to amortize the cost of seeking to them.
In the Mid-Nineties, that meant a size of around 0.5 to 1 MB.&lt;/p&gt;
&lt;p&gt;Cleaning is then a three-step process:
After suitable segments have been identified from metadata,
the cleaner reads multiple segments into memory, compacts them into a smaller number of segments,
and writes them out to disk in a single large I/O operation.
The old segments can now be marked as clean, and be returned to the free segment pool.&lt;/p&gt;
&lt;h2 id=&#34;using-ffs-data-structures&#34;&gt;
    &lt;a href=&#34;#using-ffs-data-structures&#34;&gt;
	Using FFS data structures
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;LFS uses data structures from FFS almost unchanged:
The filesystem has superblocks, inodes, direct and indirect blocks, and uses the same structures for directories, too.
All information changed is buffered and then written out sequentially in a single disk write that appends atomically and asynchronously to the log.&lt;/p&gt;
&lt;p&gt;Not overwriting things means duplicating things, so when a file grows by appending a block, the file&amp;rsquo;s inode changes.
This means the block containing the changed inode needs to be written out again, together with block added to the file.
LFS needs to keep track of inodes in an &lt;em&gt;inode map&lt;/em&gt;, and this now also needs to be updated and written out:
even if it is small enough to be cached in memory, it needs to be persisted.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/lfs-structures.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;LFS does indeed do limited in-place updates: The superblock and checkpoint region are written in fixed locations.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;LFS stops short of also appending new copies of the inode map and ultimately the superblock for each disk write,
and puts these things into fixed locations.
So we do have in-place updates for certain limited metadata structures.
This is unfortunate, as we will see when we are looking at LFS&amp;rsquo; legacy.&lt;/p&gt;
&lt;h2 id=&#34;soft-updates&#34;&gt;
    &lt;a href=&#34;#soft-updates&#34;&gt;
	Soft Updates
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In order for LFS to write out changes to data and metadata such as indirect blocks, direct blocks, inodes and directories,
updates had to be written in the proper order, even if the entire write happened in a single big I/O operation.
Writing out data &amp;ldquo;from the leaves of the filesystem tree to the top&amp;rdquo; sorts the updates in a way that made recovery easier,
because each data structure that had pointers to dependent blocks would be written out only after these blocks had already been persisted.&lt;/p&gt;
&lt;p&gt;It turns out that this logic also has merit for traditional filesystems that do in-place updates.
It allows &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/bsdcon02/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;file system checking to go on in the background&lt;/a&gt;

 while the filesystem is already being made available,
and it can &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/usenix99/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eliminate almost all synchronous metadata updates&lt;/a&gt;

 in the filesystem.&lt;/p&gt;
&lt;h1 id=&#34;lfs-in-bsd&#34;&gt;
    &lt;a href=&#34;#lfs-in-bsd&#34;&gt;
	LFS in BSD
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The BSD FFS crew, also at UCB, was very aware of Ousterhout&amp;rsquo;s work, and picks it up the year after he publishes.
They port the filesystem to BSD and &lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/sd93/seltzer.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;write a 1993 paper about it&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/lfs-ffs-feature-comparison.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Features and subsystems of BSD FFS are matched with the equivalent structures and concepts on the BSD LFS side.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;They note a few shortcomings, and present improvements:
The cleaner was single-threaded. No matter how many LFS filesystems were mounted, there was only a single cleaner process.
Now there is one per mounted filesystem.
They also provide a structural verifier for the filesystem, something similar to a &lt;code&gt;fsck&lt;/code&gt;, but a thing that can run in the background,
while the filesystem is mounted.&lt;/p&gt;
&lt;p&gt;Also, the original LFS code was using more memory than necessary, and BSD LFS was made a lot more memory efficient.&lt;/p&gt;
&lt;p&gt;A lot of the paper is then a validation that their implementation is indeed a faithful port, and an improvement over original LFS,
and benchmarking.&lt;/p&gt;
&lt;p&gt;The benchmarks confirm improved write performance, but also show weakness concerning read workloads.
This is for two reasons: data is possibly fragmented,
and the file system buffer cache in their machines is often too small to soak up the disk reads.
And secondly, when the cleaner process is running, it interacts badly with both the disk reads and writes via disk seeks,
and that costs more performance than anticipated.
This is in particular true for a database-like (TPC-B) benchmark load,
which performs badly and requires extensive tuning.&lt;/p&gt;
&lt;p&gt;Notably, the paper already hints at several improvements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There are two places where in-place updates still happen.
By removing them, the filesystem would automatically become transactional and gain snapshot functionality.
In fact, each disk write would eventually create a snapshot, and actually &amp;ldquo;snapshotting&amp;rdquo; the filesystem would simply mean
to prevent the cleaner from collecting certain snapshots.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adding checksums to disk blocks already has happened in a few places.
Turning this into a Merkle tree would be a trivial extension, and make validating the complete integrity not only of the
structure, but also of the file data a lot easier.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The paper already notes that ordering writes in the log in a certain way makes background validation easier:
If blocks being pointed to are written before blocks that point to them, referential integrity of the filesystem is being kept at all times.
It is just that a transaction may be incomplete, but because it&amp;rsquo;s not referenced anywhere that is not a problem,
and the disk blocks will be eventually collected and freed by the cleaner.&lt;/p&gt;
&lt;p&gt;Nothing in this idea is actually dependent on the filesystem being LFS.
In fact, it can and was successfully applied to BSD FFS, too, under the name of
&lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/usenix99/mckusick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;soft updates&lt;/em&gt;&lt;/a&gt;

,
allowing to mount unchecked filesystems and then running a check in the background.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;performance-war&#34;&gt;
    &lt;a href=&#34;#performance-war&#34;&gt;
	Performance War
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;While Seltzer, Bostic, McKusick et al., the original authors of the BSD FFS, were busy porting Sprite LFS to BSD,
and tuning it,
Larry McVoy and S.R. Kleiman pick up the BSD FFS sources at Sun and add support for extents to it.
The resulting patch is tiny, and the work is being documented in
&lt;a href=&#34;https://people.freebsd.org/~pfg/docs/fs/ExtentlikePerformanceforUFS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extent-like Performance from a UNIX File System&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;To Seltzers chagrin, EFS often and consistently outperforms LFS, requires little to no tuning.
In &lt;a href=&#34;https://people.freebsd.org/~pfg/docs/fs/ExtentlikePerformanceforUFS.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;File System Logging Versus Clustering: A Performance Comparison&lt;/a&gt;


this is confirmed, even if it takes a long paper with many benchmarks to arrive at this finding.
The problem is mostly with the disk seeks induced from running the cleaner.&lt;/p&gt;
&lt;p&gt;If only something could be done about this&amp;hellip;&lt;/p&gt;
&lt;p&gt;Something could be done, but it would happen at Sun and NetApp, and not in BSD: We&amp;rsquo;re getting ZFS and WAFL.&lt;/p&gt;
&lt;p&gt;Also, we&amp;rsquo;re getting things that can seek a lot faster than disks: Flash Storage.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: A detour on vnodes</title>
      <link>https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html</link>
      <pubDate>Mon, 15 May 2023 01:02:03 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/15/50-years-in-filesystems-vnodes.html</guid>
      <description>&lt;p&gt;This is part 4 of a series.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo; on the traditional Unix Filesystem.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo; on the BSD Fast File System.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html&#34;&gt;1994&lt;/a&gt;

&amp;rdquo; on SGI XFS.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see by comparing modern educational material and the problems discussed with older material.
Or look for the research papers and sources that fueled the change. So this is what we do.&lt;/p&gt;
&lt;h1 id=&#34;how-to-have-multiple-filesystems&#34;&gt;
    &lt;a href=&#34;#how-to-have-multiple-filesystems&#34;&gt;
	How to have multiple filesystems
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Steve Kleiman wrote
&amp;ldquo;&lt;a href=&#34;https://www.semanticscholar.org/paper/Vnodes%3A-An-Architecture-for-Multiple-File-System-in-Kleiman/e0d14c74f23ef9b21c2fc37b5197fbfe348a7fcf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vnodes: An Architecture for Multiple File System Types in Sun UNIX&lt;/a&gt;

&amp;rdquo;
in 1986.&lt;/p&gt;
&lt;p&gt;This is a short paper, with little text, because most of it is listing of data structures and diagrams of C language &lt;code&gt;struct&lt;/code&gt;&amp;rsquo;s pointing at each other.
Kleiman wanted to have multiple file systems in Unix, but wanted the file systems to be able to share interfaces and internal memory, if at all possible.
Specifically, he wanted a design that provided&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one common interface with multiple implementations,&lt;/li&gt;
&lt;li&gt;supporting BSD FFS, but also NFS and RFS, two remote filesystems, and Non-Unix filesystems, specifically MS-DOS,&lt;/li&gt;
&lt;li&gt;with the operations being defined by the interface being atomic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the implementations should be able to handle memory and structures dynamically, without performance impact,
reentrant and multicore capable, and somewhat object-oriented.&lt;/p&gt;
&lt;h1 id=&#34;two-abstractions&#34;&gt;
    &lt;a href=&#34;#two-abstractions&#34;&gt;
	Two abstractions
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;He looked at the various operations, and decided to provide two major abstractions:
The filesystem (&lt;code&gt;vfs&lt;/code&gt;, virtual filesystem) and the inode (&lt;code&gt;vnode&lt;/code&gt;, virtual inode), representing a filesystem and a file.&lt;/p&gt;
&lt;p&gt;In true C++ style (but expressed in C), we get a virtual function table for each type, representing the class:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the &lt;code&gt;vfs&lt;/code&gt; type, this is a &lt;code&gt;struct vfsops&lt;/code&gt;,
a collection of function pointers with operations such as &lt;code&gt;mount&lt;/code&gt;, &lt;code&gt;unmount&lt;/code&gt;, &lt;code&gt;sync&lt;/code&gt; and &lt;code&gt;vget&lt;/code&gt;.
Later in the paper, prototypes and functionality of these functions are explained.&lt;/li&gt;
&lt;li&gt;For the &lt;code&gt;vnode&lt;/code&gt; type, likewise, we get &lt;code&gt;struct vnodeops&lt;/code&gt;.
The functions here are &lt;code&gt;open&lt;/code&gt;, &lt;code&gt;rdwr&lt;/code&gt; and &lt;code&gt;close&lt;/code&gt;, of course, but also &lt;code&gt;create&lt;/code&gt;, &lt;code&gt;unlink&lt;/code&gt;, and &lt;code&gt;rename&lt;/code&gt;.
Some functions are specific to a filetype such as &lt;code&gt;readlink&lt;/code&gt;, &lt;code&gt;mkdir&lt;/code&gt;, &lt;code&gt;readdir&lt;/code&gt; and &lt;code&gt;rmdir&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actual mounts are being tracked in &lt;code&gt;vfs&lt;/code&gt; objects, which point to the operations applicable to this particular subtree with their &lt;code&gt;struct vfsops *&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, open files are being tracked in &lt;code&gt;vnode&lt;/code&gt; instances, which again, among other things, have a &lt;code&gt;struct *vnodeops&lt;/code&gt; pointer.
&lt;code&gt;vnodes&lt;/code&gt; are part of their &lt;code&gt;vfs&lt;/code&gt;, so they also have &lt;code&gt;struct *vfs&lt;/code&gt; to their filesystem instance.&lt;/p&gt;
&lt;p&gt;Both, the &lt;code&gt;vfs&lt;/code&gt; and the &lt;code&gt;vnode&lt;/code&gt; need to provide a way for the implementation to store implementation specific data (&amp;ldquo;subclass private fields&amp;rdquo;).
So both structures end with &lt;code&gt;caddr_t ...data&lt;/code&gt; pointers.
That is, the private data is not part of the virtual structure, but located elsewhere and pointed to.&lt;/p&gt;
&lt;h2 id=&#34;vnodes-in-action&#34;&gt;
    &lt;a href=&#34;#vnodes-in-action&#34;&gt;
	Vnodes in action
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/vfs-vnode-structures.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;One full page in the paper is dedicated to showing the various structures pointing at each other.
What looks confusing at first glance is actually pretty straightforward and elegant, once you trace it out.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Kleiman sets out to explain how things work using the &lt;code&gt;lookuppn()&lt;/code&gt; function, which replaces the older &lt;code&gt;namei()&lt;/code&gt; function from traditional Unix.
Analogous to &lt;code&gt;namei()&lt;/code&gt;, the function consumes a path name, and returns a &lt;code&gt;struct vnode *&lt;/code&gt; to the vnode represented by that pathname.&lt;/p&gt;
&lt;p&gt;Pathname traversal starts at the root vnode or the current directory vnode for the current process,
depending on the first character of a pathname being &lt;code&gt;/&lt;/code&gt; or not.&lt;/p&gt;
&lt;p&gt;The function then takes the next pathname component, iteratively, and calls the &lt;code&gt;lookup&lt;/code&gt; function for the current vnode.
This function takes a pathname component, and a current &lt;code&gt;vnode&lt;/code&gt; assuming it is a directory.
It then returns the &lt;code&gt;vnode&lt;/code&gt; representing that component.&lt;/p&gt;
&lt;p&gt;If a directory is a mountpoint, it has &lt;code&gt;vfsmountedhere&lt;/code&gt; set.
This is a &lt;code&gt;struct vfs *&lt;/code&gt;. &lt;code&gt;lookuppn&lt;/code&gt; follows the pointer,
and can call the &lt;code&gt;root&lt;/code&gt; function for that &lt;code&gt;vfs&lt;/code&gt; to get the root &lt;code&gt;vnode&lt;/code&gt; for that filesystem, replacing the current &lt;code&gt;vnode&lt;/code&gt; being worked on.&lt;/p&gt;
&lt;p&gt;The inverse must also be possible:
When resolving a &amp;ldquo;&lt;code&gt;..&lt;/code&gt;&amp;rdquo; component and the current &lt;code&gt;vnode&lt;/code&gt; has a root flag set in its &amp;ldquo;flags&amp;rdquo; field,
we go from the current &lt;code&gt;vnode&lt;/code&gt; to the &lt;code&gt;vfs&lt;/code&gt; following the &lt;code&gt;vfsmountedhere&lt;/code&gt; pointer.
Then we can use the &lt;code&gt;vnodecovered&lt;/code&gt; field in that &lt;code&gt;vfs&lt;/code&gt; to get the &lt;code&gt;vnode&lt;/code&gt; of the superior filesystem.&lt;/p&gt;
&lt;p&gt;In any case, upon successful completion, a &lt;code&gt;struct vnode*&lt;/code&gt; representing the consumed pathname is returned.&lt;/p&gt;
&lt;h2 id=&#34;new-system-calls&#34;&gt;
    &lt;a href=&#34;#new-system-calls&#34;&gt;
	New system calls
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In order to make things work,
and to make things work efficiently, a few new system calls had to be added to round out the interfaces.&lt;/p&gt;
&lt;p&gt;It is here in Unix history that we get &lt;code&gt;statfs&lt;/code&gt; and &lt;code&gt;fstatfs&lt;/code&gt;, to get an interface to filesystems in userland.
We also gain &lt;code&gt;getdirentries&lt;/code&gt; (plural) to get multiple directory entries at once (depending on the size of the buffer provided),
which makes directory reading faster a lot for remote filesystems.&lt;/p&gt;
&lt;h1 id=&#34;in-linux&#34;&gt;
    &lt;a href=&#34;#in-linux&#34;&gt;
	In Linux
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Looking at the Linux kernel source, we can find the general structure of Kleiman&amp;rsquo;s design,
even if the complexity and richness of the Linux kernel obscure most of it.
The Linux kernel has a wealth of file system types, and added also a lot of functionality that wasn&amp;rsquo;t present in BSD 40 years ago.
So we find a lot more structures and system calls,
implementing namespaces, quotas, attributes, read-only modes, directory name caches, and other things.&lt;/p&gt;
&lt;h2 id=&#34;the-file&#34;&gt;
    &lt;a href=&#34;#the-file&#34;&gt;
	The file
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Still, if you squint, the original structure can still be found:
Linux splits the in-memory structures around files in two, the opened &lt;code&gt;file&lt;/code&gt;, which is an inode with a current position associated,
and the &lt;code&gt;inode&lt;/code&gt;, which is the whole file.&lt;/p&gt;
&lt;p&gt;We find instances of file objects, &lt;code&gt;struct file&lt;/code&gt;, defined
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L942C3-L981&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Among all the other things a file has, it has most notably a field &lt;code&gt;loff_t f_pos&lt;/code&gt;,
an offset (in bytes) from the start of the file,
the current position.&lt;/p&gt;
&lt;p&gt;The file&amp;rsquo;s class is defined via a virtual function table.
We find the pointer as &lt;code&gt;struct file_operations *f_op&lt;/code&gt;,
and the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1754-L1798&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
It shows all the things a file can do, most notable, &lt;code&gt;open&lt;/code&gt;, &lt;code&gt;close&lt;/code&gt;, &lt;code&gt;lseek&lt;/code&gt; and then &lt;code&gt;read&lt;/code&gt; and &lt;code&gt;write&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The file also contains pointers to the inode, &lt;code&gt;struct inode *f_inode&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-inode&#34;&gt;
    &lt;a href=&#34;#the-inode&#34;&gt;
	The inode
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Operations on files without the need of an offset work on the file as a whole,
defined as &lt;code&gt;struct inode *&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Check the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L595-L705&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
We see other definitions in here that have no equivalent in BSD from 40 years ago, such as ACLs and attributes.&lt;/p&gt;
&lt;p&gt;We find the inode&amp;rsquo;s class is defined via a virtual function table,
&lt;code&gt;struct inode_operations *i_op&lt;/code&gt;,
and the definition &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1800-L1840&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Again, a lot of them deal with new features such as ACLs and extended attributes,
but we also find those we expect such as &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;unlink&lt;/code&gt;, &lt;code&gt;rename&lt;/code&gt; and so on.&lt;/p&gt;
&lt;p&gt;The inode also contains a pointer to a filesystem, the &lt;code&gt;struct super_block *i_sb&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-superblock&#34;&gt;
    &lt;a href=&#34;#the-superblock&#34;&gt;
	The superblock
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;A mountpoint is represented as an instance of &lt;code&gt;struct super_block&lt;/code&gt;,
defined &lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1136-L1268&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
Again, the class is a &lt;code&gt;struct super_operations *s_op&lt;/code&gt;, defined
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1886-L1918&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;As an added complexity, there is no finite list of filesystems.
It is instead extensible through loadable modules, so we also have a &lt;code&gt;struct file_system_type&lt;/code&gt;,
&lt;a href=&#34;https://github.com/torvalds/linux/blob/v6.3/include/linux/fs.h#L1886-L1918&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;

.
This is basically a class with only one class method as a factory for superblocks, &lt;code&gt;mount&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;summary&#34;&gt;
    &lt;a href=&#34;#summary&#34;&gt;
	Summary
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Unix changed.
It became a lot more runtime extensive, added a lot of new functionality and gained system calls.
Things became more structured.&lt;/p&gt;
&lt;p&gt;But the original design and data structures conceived by Kleiman and Joy held up, and can still be found in current Linux, 40 years later.
We can point to concrete Linux code, which while looking completely different, is structurally mirroring the original design ideas.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>50 years in filesystems: 1994</title>
      <link>https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html</link>
      <pubDate>Fri, 12 May 2023 12:13:14 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html</guid>
      <description>&lt;p&gt;This is part 3 of a series.
The first part is &amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/05/50-years-in-filesystems-1974.html&#34;&gt;1974&lt;/a&gt;

&amp;rdquo;.
The second part is &amp;ldquo;&lt;a href=&#34;https://blog.koehntopp.info/2023/05/06/50-years-in-filesystems-1984.html&#34;&gt;1984&lt;/a&gt;

&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Progress is sometimes hard to see, especially when you have been part of it or otherwise lived through it.
Often, it is easier to see if you compare modern educational material, and the problems discussed with older material.
And then look for the research papers and sources that fueled the change.&lt;/p&gt;
&lt;p&gt;In Linux (and Unix in general), this is easy.&lt;/p&gt;
&lt;h1 id=&#34;1994--the-sgi-xfs-filesystem&#34;&gt;
    &lt;a href=&#34;#1994--the-sgi-xfs-filesystem&#34;&gt;
	1994 — The SGI XFS Filesystem
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In 1994, the paper &lt;a href=&#34;http://www.scs.stanford.edu/nyu/02fa/sched/xfs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scalability in the XFS File System&lt;/a&gt;

 saw publication.
Computers got faster since 1984, and so did storage.
Notably, we are now seeing boxes with multiple CPUs, and with storage reaching into the Terabytes.
The improvements to the 4.3BSD fast filing system (or the modified version in SGI IRIX called EFS) were no longer sufficient.&lt;/p&gt;
&lt;p&gt;SGIs benchmarks cite machines that had large backplanes with many controllers (one benchmark cites a box with 20 SCSI controllers),
many disks (three-digit-numbers of hard drives),
and many CPUs (the benchmarks quote 12 socket machines) with a lot of memory (up to one gigabyte quoted in the benchmarks).&lt;/p&gt;
&lt;p&gt;Filesystems became larger than FFS could handle,
files became larger than FFS could handle,
the number of files per directory led to large lookup times,
central data structures such as allocation bitmaps did no longer scale,
and global locks made concurrent access to the file system with many CPUs inefficient.
SGI set out to design a fundamentally different filesystem.&lt;/p&gt;
&lt;p&gt;Also, the Unix community as a whole was challenged by Cutler and Custer,
who showed with NTFS for Windows NT 4.0 what was possible if you redesign from scratch.&lt;/p&gt;
&lt;h1 id=&#34;requirements&#34;&gt;
    &lt;a href=&#34;#requirements&#34;&gt;
	Requirements
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;The XFS filesystem was a firework of new ideas, and a large deviation from traditional Unix filesystem design.
The list of new things is long:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facilitate concurrency with
&lt;ul&gt;
&lt;li&gt;allocation zones&lt;/li&gt;
&lt;li&gt;inode lock splitting&lt;/li&gt;
&lt;li&gt;facilities for large, parallel I/O requests, DMA and Zero-Copy I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scalability of access by building the filesystem around the concepts of
&lt;ul&gt;
&lt;li&gt;B+-Trees&lt;/li&gt;
&lt;li&gt;Extents: pairs of (start, length) descriptors&lt;/li&gt;
&lt;li&gt;decoupling &amp;ldquo;file write&amp;rdquo; and &amp;ldquo;file layout&amp;rdquo; on disk to allow for contiguous files by using delayed allocation and preallocation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Introduce a write-ahead log to journal metadata changes
&lt;ul&gt;
&lt;li&gt;log asynchronously to allow for write coalescence&lt;/li&gt;
&lt;li&gt;leveraging the log for recovery, so that recovery time is proportional to the amount of data in flight, not the size of the filesystem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XFS was written with these requirements,
and primarily in order to provide a filesystem that could leverage all the performance of large SGI boxes for video editing, video serving and scientific computing.&lt;/p&gt;
&lt;h2 id=&#34;a-logging-filesystem-but-not-a-log-structured-filesystem&#34;&gt;
    &lt;a href=&#34;#a-logging-filesystem-but-not-a-log-structured-filesystem&#34;&gt;
	A logging filesystem, but not a log structured filesystem
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;This is also happening at about the same time as John K. Ousterhout asking
&amp;ldquo;&lt;a href=&#34;https://web.stanford.edu/~ouster/cgi-bin/papers/osfaster.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why Aren’t Operating Systems Getting Faster As Fast as Hardware?&lt;/a&gt;

&amp;rdquo;.
Ousterhout started to explore the ideas of a log-based filesystem with the experimental Sprite operating system.&lt;/p&gt;
&lt;p&gt;Log-based filesystems are an extremely radical idea that we need to discuss later, even if they originally predate XFS by a bit.
But they weren&amp;rsquo;t very usable originally, because they need different hardware which can offer a lot more disk seeks.
Log structured file system ideas had to become a lot more refined to actually have an impact,
so we are going to discuss them later in the series.&lt;/p&gt;
&lt;h2 id=&#34;what-irix-had-before&#34;&gt;
    &lt;a href=&#34;#what-irix-had-before&#34;&gt;
	What IRIX had before
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;IRIX as coming already with EFS, the specially sauced-up version of BSD FFS that used extents.
It suffered from an 8 GB filesystem size limit, a 2 GB filesize limit, and it could not utilize the full hardware I/O bandwidth,
which made many customers of these fantastically expensive machines somewhat sad.&lt;/p&gt;
&lt;p&gt;Demands for video playback and from the database community led to requirements
that stated the new filesystem needed to support hundreds of TB of disk space,
hundreds of MB/s of I/O bandwidth and many parallel I/O requests in order to be able to saturate the hardware provided,
and all this without running out of CPU.&lt;/p&gt;
&lt;p&gt;The title of the paper is &amp;ldquo;Scalability in the XFS File System&amp;rdquo; and not &amp;ldquo;Implementation of …&amp;rdquo;,
so it is more a show of the features provided and a superficial discussion of the implementation and the design decisions around it.
It is not an in-depth discussion of the implementation,
nor are extensive benchmarks provided.&lt;/p&gt;
&lt;h1 id=&#34;features&#34;&gt;
    &lt;a href=&#34;#features&#34;&gt;
	Features
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;large-filesystems&#34;&gt;
    &lt;a href=&#34;#large-filesystems&#34;&gt;
	Large filesystems
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;XFS supports large filesystems.
Previous filesystems use 32-bit pointers to blocks.
At 8 KB block size, with 32-bit block pointers, the limit is 32 TB.&lt;/p&gt;
&lt;p&gt;Moving to 64-bit block pointers would make many data structures multiple of 8 bytes in size, which seemed like a waste.&lt;/p&gt;
&lt;p&gt;For concurrency (see below), XFS introduces the concept of &lt;strong&gt;allocation groups&lt;/strong&gt; (AGs), which are always smaller than 4 GB.
Allocation groups have local instances of the filesystem data structures, for example, inode maps or free block tracking.
These are independently locked and so allow for concurrent operations in different allocation groups.&lt;/p&gt;
&lt;p&gt;Allocation groups also help to save on pointer sizes:
Where possible, AG-relative block numbers are being used, and these always fit into 32-bit pointers.
In fact, a 4G allocation group can have only 1M blocks or fewer blocks (at 4K minimum blocksize),
so a single maximum sized extent within a single AG can be packed into 40 bits (5 bytes).&lt;/p&gt;
&lt;p&gt;The maximum file size and filesystem size is 8 EB (2^63-1).&lt;/p&gt;
&lt;h2 id=&#34;bandwidth-and-concurrency&#34;&gt;
    &lt;a href=&#34;#bandwidth-and-concurrency&#34;&gt;
	Bandwidth and Concurrency
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Concurrent operations are a design goal for XFS.
1994 is the age of 20 MB/s SCSI controllers, but SGI built machines with large chassis that could house many controllers and many drives.
Benchmarks quote machines with an aggregate bandwidth of 480 MB/s delivering file I/O performance of over 370 MB/s with no tuning, including all overheads.
This is quite an impressive result for everyday usage in 1994.&lt;/p&gt;
&lt;p&gt;XFS achieves this using large blocks (4 KB or 8 KB block size), and the concept of extents.&lt;/p&gt;
&lt;h3 id=&#34;extents-and-b-trees&#34;&gt;
    &lt;a href=&#34;#extents-and-b-trees&#34;&gt;
	Extents and B-Trees.
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Extents&lt;/strong&gt; are a core concept in XFS.
They are tuples, most of the time pairs of &lt;code&gt;(startblock, length)&lt;/code&gt;.
For mapping file blocks to disk blocks (&amp;ldquo;bmap&amp;rdquo;), they are triples &lt;code&gt;(offset, length, startblock)&lt;/code&gt;.
Using truncated values, because of the size limits imposed by the maximum AG size,
they can describe a contiguous sequence of blocks up to 2M blocks in size in 4 bytes,
which is a lot more efficient than what BSD FFS did before.&lt;/p&gt;
&lt;p&gt;Extents also allow XFS to do large I/O requests because they describe sections of contiguous blocks,
making it easy to create read or write requests for several blocks apiece.
It does I/O by default with 64 KB memory buffers, unless special provisions are being made to make them even larger.&lt;/p&gt;
&lt;p&gt;The filesystem assumes an underlying disk structure with striping, and provides a number of 2 or 3 outstanding I/O requests to allow for concurrent I/O.
It checks for backpressure, that is, it checks that the application is actually reading data.
If it does, it issues additional read requests to keep the number of requests in flight at 3 by default,
good for 192 KB in flight at once.&lt;/p&gt;
&lt;p&gt;Groups of Extents can be collected in linear lists, but that will lead to scaling problems.
So XFS uses &lt;strong&gt;B+-Trees&lt;/strong&gt;, which degrade to linear lists if there is only one single index block.&lt;/p&gt;
&lt;p&gt;Usually tuples are indexed on their first value, but for some structures such as free lists, multiple indexes are kept:
It is useful to index free space by &lt;code&gt;startblock&lt;/code&gt; for closeness, but also by &lt;code&gt;length&lt;/code&gt; to fit free spaces in the right size.&lt;/p&gt;
&lt;h3 id=&#34;breaking-the-single-writer-inode-lock&#34;&gt;
    &lt;a href=&#34;#breaking-the-single-writer-inode-lock&#34;&gt;
	Breaking the single-writer inode lock
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/overlapping-write.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;Posix locks the in-memory inode to guarantee &lt;a href=&#34;https://blog.koehntopp.info/2018/11/29/but-is-it-atomic.html&#34;&gt;atomic writes&lt;/a&gt;

.
This makes sure any two large multiple-block writes always happen one-before-the-other.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;XFS also breaks the in-memory inode locks:
Posix demands that large, overlapping, multiple block writes are totally ordered.
When they overlap, it must not happen that there is a block soup of alternating blocks from write A and write B.&lt;/p&gt;
&lt;p&gt;The default implementation in most kernels is simply a file-global lock placed at the in-memory inode, making sure there can be only one writer per inode.
Implementers of databases hate that because it limits the write concurrency on any single file to One.
This is, for example, why Oracle recommends that you make tablespaces from multiple files, each no larger than one GB.&lt;/p&gt;
&lt;p&gt;XFS, in &lt;code&gt;O_DIRECT&lt;/code&gt; mode, removes this lock and allows atomic, concurrent writes, making database people very happy.&lt;/p&gt;
&lt;h2 id=&#34;dynamic-inodes-and-improved-free-space-tracking&#34;&gt;
    &lt;a href=&#34;#dynamic-inodes-and-improved-free-space-tracking&#34;&gt;
	Dynamic Inodes and improved Free Space Tracking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;With large filesystems, you can never know:
The applications may need a large number of inodes for many small files, or a small number of large files.
Also, what is a good distance between the inode and the data blocks that belong to the file?&lt;/p&gt;
&lt;p&gt;There is no good answer to the first question, and &amp;ldquo;as close as possible&amp;rdquo; is the answer to the second question.
So XFS creates Inodes dynamically, as needed, in chunks of 64 inodes.&lt;/p&gt;
&lt;p&gt;The relatively large inode size of 256 bytes (compared to 128 in BSD FFS and 64 in traditional Unix)
is being compensated by the fact that XFS creates Inodes only as needed, and places them relatively closely to the file start.
This frees up a substantial amount of disk space –
in Unix filesystems with fixed inode counts as much as 3-4% of the disk space can be locked up in pre-allocated inodes.
And even with cylinder groups, there will be considerable distance between an inode and the first data block.&lt;/p&gt;
&lt;p&gt;Because inodes can reside anywhere on the disk and not just behind the superblock, they need to be tracked.
XFS does with one B+-tree per allocation group.
The tree is indexed by the start block, and records for each inode in the chunk if it is available or in-use.
The inodes themselves are not kept in the tree, but in the actual chunks which are close to the file data.&lt;/p&gt;
&lt;p&gt;Similarly, free space is tracked in chunks, and kept in per-AG trees, indexed twice: by start block and by length.&lt;/p&gt;
&lt;h2 id=&#34;write-ahead-log&#34;&gt;
    &lt;a href=&#34;#write-ahead-log&#34;&gt;
	Write-Ahead Log
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Recovering a large filesystem after a crash can be slow.
The recovery time is proportional to the size of the filesystem, and the number of files in it,
because the system basically has to scan the entire filesystem and rebuild the directory tree in order to ensure things are consistent.
With XFS, the filesystem also is a lot more fragile, as it provides a variable number of inodes, spread out non-contiguously over the disk.
Recovering them would be extra expensive.&lt;/p&gt;
&lt;p&gt;Using write-ahead logging for metadata, this can be avoided most of the time.
Recovery time is proportional to the size of the log, that is, the amount of data in flight at the time of the crash.&lt;/p&gt;
&lt;p&gt;The log contains log entries containing a descriptor header and a full image of all changed metadata structures:
inodes, directory blocks, free extent tree blocks, inode allocation tree blocks, allocation group blocks, and the superblock.
Because full images are stored in the block, recovery is simple: the recovery process simply copies these new, changes images into the place where they are supposed to be, without needing to understand what kind of structure it changes.&lt;/p&gt;
&lt;p&gt;The trust of the authors into the log was huge:
Initially XFS had no &lt;code&gt;fsck&lt;/code&gt; program.
This turned out to be overly optimistic, and so now &lt;code&gt;xfs_repair&lt;/code&gt; exists.&lt;/p&gt;
&lt;h3 id=&#34;metadata-update-performance&#34;&gt;
    &lt;a href=&#34;#metadata-update-performance&#34;&gt;
	Metadata update performance
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS is logging metadata updates, which means they need to be written to the filesystem log.
By default, this log is placed inline, in the filesystem.
But it is also possible to take it out, and put onto other media, for example, flash storage or battery-backed memory.&lt;/p&gt;
&lt;p&gt;Writes to the log are asynchronous, if possible, but with partitions serving NFS they cannot be.
Asynchronous writes allow for write batching, with speeds things up.
But NFS servers profit a lot from accelerated log storage.&lt;/p&gt;
&lt;p&gt;Because all metadata updates need to be logged, it can happen that intense metadata operations flood the log.
A &lt;code&gt;rm -rf /usr/src/linux&lt;/code&gt; for example is not an operation where XFS is particularly fast, because the metadata update stream will eventually overflow the log.
And because everything else in XFS is parallel by AG, the log is usually the only source of contention.&lt;/p&gt;
&lt;h2 id=&#34;large-files-and-sparse-files&#34;&gt;
    &lt;a href=&#34;#large-files-and-sparse-files&#34;&gt;
	Large files and sparse files
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In FFS, files are mapped by the classical dynamic array, with direct blocks and up to three levels of indirect blocks.
With 64-bit filesize, this becomes unwieldy: there will be more than three levels of indirect blocks required,
and a substantial number of blocks would be required what essentially becomes a list of incrementing numbers.
FFS (and EFS) are also forced to layout blocks the moment each block is allocated in the filesystem buffer pool.
So effectively, no attempt to contiguously layout files on disk is being made.
Instead, blocks are placed individually.&lt;/p&gt;
&lt;p&gt;XFS replaces this dynamic array with extents.&lt;/p&gt;
&lt;p&gt;In file placement maps, these mapping extents are triples &lt;code&gt;(blockoffset, length, disk block)&lt;/code&gt;.
These extents are stored in the inode itself until this overflows.
Then XFS starts to root a B+-tree of the mapping extents in the inode, indexed by logical block number for fast seeks.&lt;/p&gt;
&lt;p&gt;This data structure allows compressing a substantial number of blocks (up to 2M blocks) in a single descriptor,
assuming contiguous allocation is possible.
So even large files could be stored in very few extents, in the optimal case one extent per AG.&lt;/p&gt;
&lt;h3 id=&#34;delayed-allocation-and-preallocation-for-contiguous-layout&#34;&gt;
    &lt;a href=&#34;#delayed-allocation-and-preallocation-for-contiguous-layout&#34;&gt;
	Delayed allocation and Preallocation for contiguous layout
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS also provides a new concept, delayed allocation, in which virtual extents can be allocated in the file system buffer pool.
These are blocks full of yet unwritten data that have not been layouted, and hence lack a physical position.
Only on flush these blocks are layouted, contiguously, and then written out linearly in large writes, to speed things up.&lt;/p&gt;
&lt;p&gt;This is a fundamental change to how the filesystem buffer cache works –
previously it was possible to use &lt;code&gt;(device, physical block number)&lt;/code&gt; to identify buffer cache blocks and prevent duplicate buffer allocation.
When porting XFS to Linux, the Linux kernel initially could not accommodate strategies that do not use such identification in the normal buffer cache, so at first XFS required a separate buffer cache.
This got fixed later, as the porting progressed.&lt;/p&gt;
&lt;p&gt;To ensure that files can be layouted without fragmentation, in a single extent, XFS aggressively preallocates storage for open files.
The default amount of disk space preallocated is dependent on the amount of free space in the filesystem, and can be substantial.&lt;/p&gt;
&lt;p&gt;The internet is littered with questions by XFS users asking where their disk space is, and the answer is always &amp;ldquo;in the open file handles of &lt;code&gt;/var/log&lt;/code&gt;. Also, check the &lt;a href=&#34;https://man7.org/linux/man-pages/man5/xfs.5.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;manpage&lt;/a&gt;

 for &lt;code&gt;allocsize=&lt;/code&gt; and also check &lt;a href=&#34;https://linux-xfs.oss.sgi.narkive.com/jjjfnyI1/faq-xfs-speculative-preallocation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;/proc/sys/fs/xfs/speculative_prealloc_lifetime&lt;/code&gt;&lt;/a&gt;

.&amp;rdquo;&lt;/p&gt;
&lt;h3 id=&#34;locality&#34;&gt;
    &lt;a href=&#34;#locality&#34;&gt;
	Locality
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;XFS does not use allocation groups for locality much.
They exist mostly for concurrency.
Instead, file placement is mostly around directories and existing blocks of the current file.
The only exception is &amp;ldquo;new directories&amp;rdquo;, which are placed &amp;ldquo;away&amp;rdquo; from their parent directory by putting them into a different AG.&lt;/p&gt;
&lt;p&gt;In large files, if new extents need to be placed, they go &amp;ldquo;initially near the inode, then near the existing block in the file which is closest to the offset in the file for which we are allocating space&amp;rdquo;, as the paper specifies.
This places the inode close to the start of the file, and blocks added later to whatever is already present.&lt;/p&gt;
&lt;h2 id=&#34;large-directories&#34;&gt;
    &lt;a href=&#34;#large-directories&#34;&gt;
	Large directories
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;In the traditional Unix filesystem and in BSD FFS, directory name lookups are linear operations.
Large directories slow this down a lot, for any kind of pathname to inode translation.&lt;/p&gt;
&lt;p&gt;XFS chose the ubiquitous B+-Tree as a structure for directories, too, but with a quirk:
Since the keys are supposed to be filenames, a variable length structure, they would be completely different from all the other tree implementations in the filesystem.
The XFS authors did not like this idea, so they are hashing the filename into a fixed 4-byte name hash, and then store one or more directory entries as &lt;code&gt;(name, inode)&lt;/code&gt; pairs in the value.&lt;/p&gt;
&lt;p&gt;There was some tradeoff discussion involved in this, but the authors found that short keys allow storing many entries per block,
leading to wide trees, and thus faster lookups.
They boast &amp;ldquo;We can have directories with millions of entries&amp;rdquo;, something that was previously unthinkable in Unix filesystems.&lt;/p&gt;
&lt;h1 id=&#34;a-lot-of-code&#34;&gt;
    &lt;a href=&#34;#a-lot-of-code&#34;&gt;
	A lot of code
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2023/05/xfs-scaling.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;


&lt;em&gt;XFS Benchmarks in 1994 show nice and welcome linear scaling behavior that utilizes the hardware offered well.
It handles well on large boxes with (for 1994) high core-counts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;XFS is a large filesystem.
Linux ext2 is only 5000 lines of kernel code (and about 10x this in user-land).
XFS is 50.000 lines of kernel code, and that is without the IRIX volume manager XLV (in Linux, the XFS port uses LVM2 instead).&lt;/p&gt;
&lt;p&gt;XFS was released under the GNU GPL in May 1999, and was ported into the Linux kernel starting in 2001.
As of 2014, it was supported in most Linux distributions and RHEL used it as the default filesystem.
And even in 2024 it is still holding up reasonably well, on HDD and on flash.&lt;/p&gt;
&lt;p&gt;It still is the filesystem with the best scaling behavior, the best concurrency behavior, and the most consistent commit times,
which makes it the preferred filesystem for any kind of database usage.
This is due to the elimination of several global locks that impair concurrent usage and performance in large filesystems,
and due to the consistent use of B+-Tree structures with &lt;code&gt;O(log(n))&lt;/code&gt; scaling behavior where before algorithms with worse scaling behavior have been used.
The use of extents also allows dynamically growing I/O sizes, benefiting throughput,
and together with the novel idea of delayed allocation encourage contiguous file placement.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

