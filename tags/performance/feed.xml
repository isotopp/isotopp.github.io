<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Performance on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/performance.html</link>
    <description>Recent content in Performance on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>kris-blog@koehntopp.de (Kristian Köhntopp)</managingEditor>

    
    <webMaster>kris-blog@koehntopp.de (Kristian Köhntopp)</webMaster>

    
    <lastBuildDate>Fri, 07 Mar 2025 16:58:05 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/performance/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Waffle House Index of Tooling</title>
      <link>https://blog.koehntopp.info/2020/06/08/waffle-house-index-of-tooling.html</link>
      <pubDate>Mon, 08 Jun 2020 11:46:42 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2020/06/08/waffle-house-index-of-tooling.html</guid>
      <description>&lt;p&gt;Charity Majors was &lt;a href=&#34;https://twitter.com/mipsytipsy/status/1268418428542443520&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on fire and on target, again&lt;/a&gt;

:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/mipsytipsy/status/1268418428542443520&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2020/06/waffle-house-index.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;What is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Waffle_House_Index#Levels&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Waffle House Index&lt;/a&gt;

?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Waffle House Index is an informal metric named after the Waffle House restaurant chain and is used by the Federal Emergency Management Agency (FEMA) to determine the effect of a storm and the &lt;strong&gt;likely scale of assistance required for disaster recovery&lt;/strong&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;A &amp;ldquo;Waffle House Index for Tooling&amp;rdquo; would be an indicator how bad the situation on the ground in an IT department is. Charity Majors suggest &amp;ldquo;CPU load alerts&amp;rdquo; as a tooling emergency indicator.&lt;/p&gt;
&lt;p&gt;Why? CPU load or %CPU used is a useful metric, because it tells you how &amp;ldquo;full&amp;rdquo; the compute part of a thing is.&lt;/p&gt;
&lt;h3 id=&#34;rightsizing-capacity-is-not-easy&#34;&gt;
    &lt;a href=&#34;#rightsizing-capacity-is-not-easy&#34;&gt;
	&amp;ldquo;Rightsizing capacity&amp;rdquo; is not easy
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Alerting on it is a very weird idea, though, and still I find people doing this all of the time. Usually these people are in dire need of a better education, though.&lt;/p&gt;
&lt;p&gt;If you right size your infrastructure, your goal is to have as little overhead as possible in provisioned resources: Only provision as little as needed, just as much as necessary to deliver.&lt;/p&gt;
&lt;p&gt;But if you did that, a CPU alert would be going off all of the time, because ideally you want your boxes loaded to the limit, right?&lt;/p&gt;
&lt;h3 id=&#34;alerting-or-provisioning&#34;&gt;
    &lt;a href=&#34;#alerting-or-provisioning&#34;&gt;
	Alerting or provisioning?
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Or you can&amp;rsquo;t, because this is complicated: there are a lot of preconditions that go into even being able to load boxes to this limit. If you can&amp;rsquo;t, then a CPU load alert would also be useless, because it would either never fire, or if it did, it would be too late.&lt;/p&gt;
&lt;p&gt;Web workloads, specifically, are usually spiky. Your workload may be within the provisioned capacity most of the time, but there will be very sudden, very short spikes that are not. These spikes are usually way shorter than the time it takes to grow your capacity. The way to handle that is to provision not for a median needed capacity, or even low 90ies percentile of required capacity, but to provision for max or 99.9 in order to be able to ride the waves.&lt;/p&gt;
&lt;p&gt;If you alert on CPU load in such an environment, by the time the alert goes off, it will be too late already. Also, if you could alert, you could also size.&lt;/p&gt;
&lt;h3 id=&#34;experimentation-has-effects-on-capacity&#34;&gt;
    &lt;a href=&#34;#experimentation-has-effects-on-capacity&#34;&gt;
	Experimentation has effects on capacity
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Or you may be in an environment where the code is unpredictable, because you change it a lot with experiments going in and out of the codebase, or from 1%-on to full-on.&lt;/p&gt;
&lt;p&gt;When experimenting, it is important to expose code to users really quickly. That code being efficient is not a priority, because most of it will be scrapped as having a net-negative outcome anyway. It is not worth it putting engineering into code before you have the business side of things right.&lt;/p&gt;
&lt;p&gt;Being able to run experiments means you need to overprovision capacity.&lt;/p&gt;
&lt;h3 id=&#34;detailed-many-dimensional-highly-tagged-metrics&#34;&gt;
    &lt;a href=&#34;#detailed-many-dimensional-highly-tagged-metrics&#34;&gt;
	Detailed, many-dimensional, highly tagged metrics
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;But that of course means you need to alert on change in variants, and compare code path variants not only with respect to business metrics, but also on technical metrics in order to offset business wins. With proper experimentation, you cannot only say &amp;ldquo;This code is making us x Euro/h richer than the base variant.&amp;rdquo; You also need to be able to say &amp;ldquo;To run this we will have to pay y Euro/h more&amp;rdquo; and &amp;ldquo;Refactoring this for efficiency will cost z Euro in Engineering Time over a potential lifecycle of n hours, so y Euro/h more&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This not only enables quantified reasoning over the change the experiment introduces, but also about how to proceed with the codebase when it goes full-on: Do we leave it as is and just buy more machinery, or do we put engineers on it to make it nice?&lt;/p&gt;
&lt;h3 id=&#34;production-load-testing-numbers-for-capacity&#34;&gt;
    &lt;a href=&#34;#production-load-testing-numbers-for-capacity&#34;&gt;
	Production load testing numbers for capacity
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;But in order to allow developers to experiment safely, you need to have accurate capacity metrics, which CPU load is not. Testing in production, safely, specifically automated load tests with actual production users and separate monitoring of experiment codepaths (and consumption attribution at the request level to experiment variants) will provide these numbers.&lt;/p&gt;
&lt;p&gt;And that is the way to go: From reactive scaling (&amp;ldquo;CPU Load too high, raise capacity&amp;rdquo;) to predictive scaling (&amp;ldquo;Our capacity is x req/m per box, and we have n. Evening peak will be m, so we need y boxen more by 16:00.&amp;rdquo;). Which brings us back to the spiky loads where we started.&lt;/p&gt;
&lt;h2 id=&#34;tldr&#34;&gt;
    &lt;a href=&#34;#tldr&#34;&gt;
	TL;DR
    &lt;/a&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If CPU load alerting worked, reactive autoscaling would work, too.&lt;/li&gt;
&lt;li&gt;In a web workload environment, it usually doesn&amp;rsquo;t.&lt;/li&gt;
&lt;li&gt;If you experiment, you need to attribute cost and benefit to experiment variants.
&lt;ul&gt;
&lt;li&gt;That means load tests with production users.&lt;/li&gt;
&lt;li&gt;That means detailed, many-dimensional metrics with many tags, and a lot of ad-hoc metrics exploration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Once you have that, you are also ready for predictive autoscaling, which actually works.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your shop uses CPU load alerting, chances are that their tooling and education is in need of emergency updating.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Some latency numbers illustrated</title>
      <link>https://blog.koehntopp.info/2020/02/28/some-latency-numbers-illustrated.html</link>
      <pubDate>Fri, 28 Feb 2020 10:45:23 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2020/02/28/some-latency-numbers-illustrated.html</guid>
      <description>&lt;p&gt;These images are older than time itself. I picked them up while working as a consultant for MySQL AB, but I do not know the source.&lt;/p&gt;
&lt;p&gt;Here are some important latency numbers. A pixel is a nanosecond (nano = 10^-9, a billionth of a second, 1 billion events/s = 1 GHz):&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2020/02/latency-top.gif&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;And below is the HDD disk seek latency in full at the same scale. An uncached index access can result in up to 5 disk seeks, worst case.&lt;/p&gt;
&lt;p&gt;Each waiting core in a 3 GHz computer cannot execute 3 million clock cycles per millisecond wait, so 13.7ms disk seek 41.1 million clock cycles wait time per stalled core.&lt;/p&gt;
&lt;p&gt;That is why we give so much memory to index and data memory caches in databases. This is why InnoDB page compression exists.&lt;/p&gt;
&lt;p&gt;This is also why SSD and NVME flash are so important to database people.&lt;/p&gt;
&lt;p&gt;This is also why it is important that your queries use indexes, and why you should batch queries. That is, &amp;ldquo;select a, b c from t where id in (&amp;hellip;)&amp;rdquo; instead of a query per id-value in a loop.&lt;/p&gt;
&lt;p&gt;Not graphed: Talking to a service in another data center, for example talking to a web service in the cloud from on-premises, or talking to a service in one cloud from another cloud. Assume 10ms, or approximately one HDD disk seek for this.&lt;/p&gt;
&lt;p&gt;If that service does not have an API that allows batching and/or asynchronous operation, they are maybe not entirely appropriately aware of performance issues.&lt;/p&gt;
&lt;p&gt;Please zoom in for details:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2020/02/latency.gif&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL Performance Limits</title>
      <link>https://blog.koehntopp.info/2019/09/06/mysql-performance-limits.html</link>
      <pubDate>Fri, 06 Sep 2019 15:30:14 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2019/09/06/mysql-performance-limits.html</guid>
      <description>&lt;p&gt;The last time I saw a MySQL server operating at a performance limit
was in 2012. Back them we had a production master on (then) current
hardware, running stable at about 21000 QPS. At 24000 QPS it tended
to become unstable and fall over, dying in global locks on the
InnoDB Adaptive Hash Index or other global locks.&lt;/p&gt;
&lt;p&gt;I need to better understand how MySQL works today, and what the limits
are on a box that is considered large in 2019.&lt;/p&gt;
&lt;h1 id=&#34;what-do-i-expect&#34;&gt;
    &lt;a href=&#34;#what-do-i-expect&#34;&gt;
	What do I expect?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;Well, boxen are a lot larger than they have been in 2012, and
we invented NVME and Flash Storage since then.&lt;/p&gt;
&lt;p&gt;I expect MySQL to be able to eat the full box I am throwing at
it and not die in locks. I also expect the performance levels
I can reach to be scaling with the query execution times I observe
in production times number of cores.&lt;/p&gt;
&lt;p&gt;I do observe appro. 1/3 ms query execution time on the queries
I simulate here, in production. So I would like to see about
3000 QPS per core. With a 64 core box, that would be around 200k QPS,
easily 10x-ish more than in 2012.&lt;/p&gt;
&lt;h1 id=&#34;what-did-i-get&#34;&gt;
    &lt;a href=&#34;#what-did-i-get&#34;&gt;
	What did I get?
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;This is all read testing of a memory resident data set. Other testing
to follow.&lt;/p&gt;
&lt;p&gt;After some woes described below, I got 200k QPS or better in all
cases, for simple PK lookups in fact almost 2x as much.&lt;/p&gt;
&lt;p&gt;SK lookups are about 1/2 as fast as PK lookups or faster, allowing
for &amp;ldquo;one level of indirection&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;MySQL 8 scales well enough to eat all of a 64 core box with 1/2 TB
of RAM without choking or locking up or being otherwise jittery. It
is adequate for any hardware that in 2019 we can reasonably throw at
it. From a 2012 PoV this is an awesome achievement.&lt;/p&gt;
&lt;h1 id=&#34;the-box&#34;&gt;
    &lt;a href=&#34;#the-box&#34;&gt;
	The box
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;So my current test box is an single socket AMD 7702 (64C, HT off)
with 512G of memory and&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# nvme list&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Node             SN                   Model                                    Namespace Usage                      Format           FW Rev
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme0n1     39X0A05ZTZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme1n1     29X0A00CTZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme2n1     2950A00FTZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme3n1     39X0A067TZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme4n1     39X0A060TZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme5n1     39X0A069TZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme6n1     39X0A06ETZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/dev/nvme7n1     39X0A05LTZZF         KCM51VUG800G                             &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          27.79  GB / 800.17  GB    &lt;span class=&#34;m&#34;&gt;512&lt;/span&gt;   B +  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; B   3006T21F
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# vgcreate kristest /dev/nvme{0..7}n1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# lvcreate -n mysql -L4T -i8 kristest&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# mkfs -t xfs /dev/kristest/mysql&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I then run the performance-datagen.sql script to create a test table
kristest.t, and then run performance-querygen.py to create a file
with test queries, file.sql.&lt;/p&gt;
&lt;p&gt;mysqlslap then does&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mysqlslap --user&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kristest --password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;lt;secret&amp;gt;&amp;#39;&lt;/span&gt; --host&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;localhost --concurrency&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;64&lt;/span&gt; --iterations&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20000&lt;/span&gt; --create-schema&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kristest --verbose --query&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;./file.sql
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and I observe the running test with &lt;code&gt;innotop -d1 -mQ&lt;/code&gt; and &lt;code&gt;innotop -d1 -mC&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;findings&#34;&gt;
    &lt;a href=&#34;#findings&#34;&gt;
	Findings
    &lt;/a&gt;
&lt;/h1&gt;
&lt;h2 id=&#34;mysql-8016-binlog-row-minimal-buffer-pool-384g&#34;&gt;
    &lt;a href=&#34;#mysql-8016-binlog-row-minimal-buffer-pool-384g&#34;&gt;
	MySQL 8.0.16, Binlog, ROW, MINIMAL, Buffer Pool 384G
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;For all tests:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ du -sh /mysql/kristest/data
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;87G
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+-----------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+-----------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+-----------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1&#34;&gt;
    &lt;a href=&#34;#testmodes-1&#34;&gt;
	Testmodes 1
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 32.8G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 63.52, 61.70, 59.23
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 384k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1-2&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2&#34;&gt;
	Testmodes 1, 2
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 34.3G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 63.82, 64.89, 61.63
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 270k-320k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1-2-3&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2-3&#34;&gt;
	Testmodes 1, 2, 3
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2, 3 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 88.4G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 64.10, 57.94, 56.72
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 5.5k-6.2k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There is a distinct warmup phase during which the box is not
saturated and Read I/O can be observed. When the RES approaches
disk size, this disk traffic ceases and final load and final
QPS ratings are achieved.&lt;/p&gt;
&lt;h3 id=&#34;testmodes-1-2-3-4&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2-3-4&#34;&gt;
	Testmodes 1, 2, 3, 4
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2, 3, 4 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 94.6G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 65.91, 63.10, 59.75
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 407-1002 (yup, no &amp;#34;k&amp;#34;, this is as low as 407 QPS)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;explain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64419&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17490&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7919&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56196&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;54754&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70263&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select_type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partitions&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;possible_keys&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_len&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ref&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filtered&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Extra&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                 &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SIMPLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12674&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;condition&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;warning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64419&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17490&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7919&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56196&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;54754&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70263&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134777240&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0836&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0838&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0839&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab083b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab083c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab083e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab083f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0841&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0842&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;95&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ab0844&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70263&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;27807&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;28246&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;57810&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4313&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;48136&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;27740&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;94290&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;88230&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;58281&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12674&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;38&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;increase-selectivity&#34;&gt;
    &lt;a href=&#34;#increase-selectivity&#34;&gt;
	Increase selectivity
    &lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;In our testing above, we see that the cardinality of i1 is 100k, and
the table size is 128m. That&amp;rsquo;s 1280 result rows on the average for
a random value of i1.&lt;/p&gt;
&lt;p&gt;We also observe that testmode 4 results ask for 2-11 values of i1 or i2,
where testmode 3 results ask for a single value of i1 or i2. The average
number of testmode 4 values we ask for is 6, and testmode 4 happens
to be 6x slower.&lt;/p&gt;
&lt;p&gt;So it might be that the number of result set rows is determining the
query speed.&lt;/p&gt;
&lt;p&gt;We can test: We increase the cardinality of i1 to match id, 128. And
for i2 we are going up to 256m cardinality.&lt;/p&gt;
&lt;h2 id=&#34;the-slow-way&#34;&gt;
    &lt;a href=&#34;#the-slow-way&#34;&gt;
	The slow way
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Modify the dataset:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;update&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134937574&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134937574&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;affected&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;53&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;46&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matched&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Changed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Warnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;During the execution of that update statement, we see an aggregate write
load of 320 MB/s (~40 MB/s per NVME). This is not very high. It needs to
be tested with more write benchmarks, later.&lt;/p&gt;
&lt;p&gt;Also, there are four INDEX() definitions active on t, i1, i2, c1
and c2, two of which are being updated.&lt;/p&gt;
&lt;p&gt;This is not fast, either, and this is the n00b way of doing things. We
redo this again, differently:&lt;/p&gt;
&lt;h2 id=&#34;a-faster-way&#34;&gt;
    &lt;a href=&#34;#a-faster-way&#34;&gt;
	A faster way
    &lt;/a&gt;
&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;affected&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;46&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;85&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Duplicates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Warnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;update&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134937574&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134937574&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;affected&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;07&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matched&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Changed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;134217728&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Warnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;affected&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;04&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Duplicates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Warnings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TBH, I&amp;rsquo;d expect MySQL by now to do bulk index updates in mass ALTER tables
quicker than &amp;rsquo;the slow way&amp;rsquo; in 2019. OTOH, that is probably stuff that
you get when you pay for Red Oracle instead of Blue.&lt;/p&gt;
&lt;h2 id=&#34;testing-with-selective-i1-i2&#34;&gt;
    &lt;a href=&#34;#testing-with-selective-i1-i2&#34;&gt;
	Testing with selective i1, i2
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Now i1 and i2 are much more selective, and instead of 12k result rows,
a search on i1 should on the average return 1 row, on i2 even 0.5 rows.
Let&amp;rsquo;s see how that affects runtimes up SK lookup queries (testmode 3, 4).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s rerun everything, starting with a cold mysqld again, so that I
do get proper memory sizes as well.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# du -sh /mysql/kristest/data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;94G     /mysql/kristest/data
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1-1&#34;&gt;
    &lt;a href=&#34;#testmodes-1-1&#34;&gt;
	Testmodes 1
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 32.8G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 64.14, 43.67, 20.08
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 360k-420k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1-2-1&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2-1&#34;&gt;
	Testmodes 1, 2
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 33.8G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 60.36, 56.82, 39.73
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 280k-330k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testmodes-1-2-3-1&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2-3-1&#34;&gt;
	Testmodes 1, 2, 3
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2, 3 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 34.6G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 58.61, 58.29, 55.80
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 200k-320k (very jittery)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Did not reach load 60+, even after long warmup and with 0 I/O.
Some i2 queries can return 0 rows, might be the cause?&lt;/p&gt;
&lt;h3 id=&#34;testmodes-1-2-3-4-1&#34;&gt;
    &lt;a href=&#34;#testmodes-1-2-3-4-1&#34;&gt;
	Testmodes 1, 2, 3, 4
    &lt;/a&gt;
&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;testmodes = [ 1, 2, 3, 4 ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;VSZ 421G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;RES 35.6G
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;load average: 67.68, 63.57, 58.80
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;QPS 210k-260k
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After an even longer wait, performance jitters way less and stabilizes
around 248k with a jitter of &amp;lt;10k in both directions. Warmup times
for this size of hardware and this amount of memory are insane.&lt;/p&gt;
&lt;p&gt;And with our changes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;explain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64419&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17490&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7919&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56196&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;54754&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70263&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select_type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partitions&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;possible_keys&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key_len&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ref&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filtered&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Extra&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                 &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SIMPLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Using&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;condition&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;warning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;localhost&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kristest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64419&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17490&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7919&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70137&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56196&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;54754&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70263&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;116937151&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9462&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9464&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9466&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9467&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9469&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da946a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da946c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da946d&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da946f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;da9470&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c97e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b92c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;98039&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bbd64c8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56196&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;74380528&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;81571&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;57401&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42293&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;39260&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;69425&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;29342&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;38434&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4147&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Yes, optimizer estimates can be a bit off. Still, the point is being
made: Cardinality is up, result set size is down, performance returns.&lt;/p&gt;
&lt;p&gt;We have been looking at a result set size/selectivity problem, not at
sucky handling of SK in InnoDB.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>d = a*b&#43;c at scale</title>
      <link>https://blog.koehntopp.info/2017/11/25/d-abc-at-scale.html</link>
      <pubDate>Sat, 25 Nov 2017 20:44:52 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/11/25/d-abc-at-scale.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/11/dabc.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://haifux.org/lectures/267/Introduction-to-GPUs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to GPUs&lt;/a&gt;

 (PDF)&lt;/p&gt;
&lt;p&gt;So you already know how your CPU works, basically, and want to understand
what your GPU does differently. Ofer Rosenberg has you covered:
&lt;a href=&#34;http://haifux.org/lectures/267/Introduction-to-GPUs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to GPUs&lt;/a&gt;

 does what it
says on the tin.&lt;/p&gt;
&lt;p&gt;The NVIDIA take on this can be found in &lt;a href=&#34;http://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Introduction to Modern GPU
Architecture&lt;/a&gt;


by Ashu Rege, but because this is from 2008, it&amp;rsquo;s showing it&amp;rsquo;s age. The
first 15 slides or so focus more on the gaming aspect and less on the
technology, but are full of matching screenshots.&lt;/p&gt;
&lt;p&gt;The following slides then show how GPU evolved from specialised graphics
processing units to a general parallel instruction execution architecture -
what you get is basically a single chip supercomputer. Starting at slide 60
we go into Aliasing and sub-pixel addressing. Only the final three slides
mention CUDA.&lt;/p&gt;
&lt;p&gt;Kayvon Fatahalian again takes us on a tour through history, from 1993
onwards to 2011, in
&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15462-f11/www/lec_slides/lec19.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How a GPU works&lt;/a&gt;

.
The key innovation, &amp;ldquo;unified shaders&amp;rdquo;, seems to be from 2006. The slideset
seems to have considerable overlap with the Ofer Rosenberg set.&lt;/p&gt;
&lt;p&gt;Andy Glew explains the ideas and possible optimisations inside the typical
GPU architectures in a large slideset at
&lt;a href=&#34;https://parlab.eecs.berkeley.edu/sites/all/parlab/files/20090827-glew-vector.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Coherent Threading: Microarchitectures between SIMD and MIMD&lt;/a&gt;

.
One point he makes is that there is a spectrum between classical multicore
CPUs (MIMD) and classical vector CPUs (SIMD), and that seems to be the space
that GPUs occupy. He lists that as SIMT (Single Instruction, Multiple
Threads), and then at length explains how this enables optimisations that
keep all cores (hundreds) busy by switching between even more threads (tens
of thousands) in hardware.&lt;/p&gt;
&lt;p&gt;So what does all of this give you? Well, here is an overview of the
evolution of graphics 2000-2015, as seen by NVIDIA.
&lt;a href=&#34;https://www.youtube.com/watch?v=6QJvAiCHXqc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Now, all of this is even relevant if you do not want to blow up pixels,
because the very same operations are being executed at scale for
&lt;a href=&#34;https://www.youtube.com/watch?v=df2_72wjEdw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;routing packets&lt;/a&gt;

 or running classifiers
in neural networks. Google does this at
&lt;a href=&#34;https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scale with custom hardware&lt;/a&gt;


that is not quite GPU.&lt;/p&gt;
&lt;p&gt;A remarkable takeaway is that they are using 8-bit integers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A TPU contains 65,536 8-bit integer multipliers. The popular GPUs used
widely on the cloud environment contains a few thousands of 32-bit
floating-point multipliers. As long as you can meet the accuracy
requirements of your application with 8-bits, that can be up to 25X or
more multipliers.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Their design is basically a monster 8-bit matrix multiplier with neural
network specific postprocessing.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/11/tpu-15.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

]&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Google Tensorflow Processor&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;The Postprocessing is a non-linear function, or as they state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Neural network models consist of matrix multiplies of various sizes -
that’s what forms a fully connected layer, or in a CNN, it tends to be
smaller matrix multiplies. This architecture is about doing those things -
when you’ve accumulated all the partial sums and are outputting from
the accumulators, everything goes through this activation pipeline. The
nonlinearity is what makes it a neural network even if it’s mostly
linear algebra.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The large matrix multiplier is implemented as a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Systolic_array&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Systolic Array&lt;/a&gt;

, which makes it even
less general, more specialised than the SIMT units of a GPU -  a Single
Function, Multiple Data, Merged Results processor or a Domain Specific
Processor. That is, this part of the operation of the TPU is not
programmable, but hardwired in silicon - producing 65536 8-bit matrix
multiplication/addition results every cycle at very low power cost.&lt;/p&gt;
&lt;p&gt;Google claims to be 83x more power efficient than a CPU and 29x more power
efficient than a GPU. A more in-depth look at the TPU is available from the
&lt;a href=&#34;https://arxiv.org/abs/1704.04760&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;April 2017 TPU Paper&lt;/a&gt;

 and a
&lt;a href=&#34;https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matching article&lt;/a&gt;


on The Next Platform. The Google article is remarkable, because it
demonstrates how the Google custom hardware wipes the floor even with
contemporary GPU-based architectures, in terms of performance and even more
so in terms of performance/Watt.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nextplatform.com/2017/04/12/googles-tpu-investment-make-sense-going-forward/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA reacted to these chips&lt;/a&gt;


by enabling lower precision math (= less memory needed) and by producing
GPUs better usable for machine learning, both training and inference (using
the trained models as classifiers for data). So we see 16-bit float and
8-bit integers being used in NVIDIAs Pascal chips for this. NVIDIA claims to
be able to catch up to Google TPU performance with this generation of
hardware, but at more power consumption.&lt;/p&gt;
&lt;p&gt;Google &lt;a href=&#34;https://blog.google/topics/google-cloud/google-cloud-offer-tpus-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kind of counters&lt;/a&gt;


with a &lt;a href=&#34;https://www.nextplatform.com/2017/05/22/hood-googles-tpu2-machine-learning-clusters/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2nd generation TPU&lt;/a&gt;

.
We also see that hardware development innovation cycles in this area are
currently much faster than the deprecation time for said hardware (see also
the changes in the Knights-anything lineup from Intel), so this is a
classical rent-don&amp;rsquo;t-buy situation for the aspiring cloud user who also
happens to have their own data center.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Latency Numbers, visualised and memorised</title>
      <link>https://blog.koehntopp.info/2017/10/12/latency-numbers-visualised-and-memorised.html</link>
      <pubDate>Thu, 12 Oct 2017 22:36:21 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/10/12/latency-numbers-visualised-and-memorised.html</guid>
      <description>&lt;p&gt;There is a well known Github Gist
&amp;ldquo;&lt;a href=&#34;https://gist.github.com/jboner/2841832&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Latency Numbers Every Programmer Should Know&lt;/a&gt;

&amp;rdquo;,
which explains which things take how long.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/srigi/status/917998817051541504&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/10/latency-numbers.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/srigi/status/917998817051541504&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scaled Latency Numbers&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;If you scale these things down 3 billion times, a clock cycle (0.3ns)
becomes a second. And suddenly things are relateable.
(&lt;a href=&#34;https://twitter.com/srigi/status/917998817051541504&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tweet&lt;/a&gt;

)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/hellerbarde/2843375&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/10/latency-numbers-2-640x320.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/hellerbarde/2843375&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Another attempt to visualize this&lt;/a&gt;

, not entirely unlike
&lt;a href=&#34;https://xkcd.com/radiation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this XKCD&lt;/a&gt;

.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What GPUs can do…</title>
      <link>https://blog.koehntopp.info/2017/10/12/what-gpus-can-do.html</link>
      <pubDate>Thu, 12 Oct 2017 23:51:20 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/10/12/what-gpus-can-do.html</guid>
      <description>&lt;p&gt;Pcgamer reports &amp;ldquo;&lt;a href=&#34;http://www.pcgamer.com/nvidia-ceo-says-moores-law-is-dead-and-gpus-will-replace-cpus/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nvidia CEO says Moore’s Law is dead and GPUs wi replace CPUs&lt;/a&gt;

&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Now, Jensen Huang might be a bit biased here, but he reminded us that &amp;ldquo;GPUs
are advancing at a much faster pace than CPUs&amp;rdquo; and &amp;ldquo;that GPUs will replace
CPUs soon, adding that at this point, designers can hardly work out advanced
parallel instruction architectures for CPUs.&amp;rdquo; So what can a modern GPU do?
Well, apparently &lt;a href=&#34;https://aras-p.info/blog/2017/02/15/Font-Rendering-is-Getting-Interesting/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Font Rendering is still a hard problem&lt;/a&gt;


for GPUs, and a bottleneck in modern browsers. That&amp;rsquo;s not to say it&amp;rsquo;s not
being done - the linked article contains lot of pointers. And an older
article about the
&lt;a href=&#34;https://dolphin-emu.org/blog/2017/07/30/ubershaders/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ubershaders&lt;/a&gt;


basically explains how the
&lt;a href=&#34;https://de.wikipedia.org/wiki/Dolphin_%28Emulator%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dolphin&lt;/a&gt;


GameCube/Wii-Emulator uses modern GPU hardware to live-emulate 2002/2006 GPU
hardware, in realtime (for a short time, while the CPU in the background
creates more optimised precompiled GPU setups and code).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scaling, automatically and manually</title>
      <link>https://blog.koehntopp.info/2017/08/09/scaling-automatically-and-manually.html</link>
      <pubDate>Wed, 09 Aug 2017 10:19:30 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/08/09/scaling-automatically-and-manually.html</guid>
      <description>&lt;p&gt;There is an interesting article by Brendan Gregg out there, about
&lt;a href=&#34;http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the actual data that goes into the Load Average&lt;/a&gt;


metrics of Linux. The article has a few funnily contrasting lines. Brendan
Gregg states&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Load averages are an industry-critical metric – my company spends
millions auto-scaling cloud instances based on them and other metrics
[…]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;but in the article we find Matthias Urlichs saying&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The point of &amp;ldquo;load average&amp;rdquo; is to arrive at a number relating how busy the
system is from a human point of view.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;and the article closes with Gregg quoting a comment by Peter Zijlstra in the
kernel source:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This file contains the magic bits required to compute the global loadavg
figure. &lt;strong&gt;Its a silly number but people think its important.&lt;/strong&gt; We go
through great pains to make it work on big machines and tickless kernels.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s go back to the start. What&amp;rsquo;s the problem to solve here?&lt;/p&gt;
&lt;p&gt;Brendan Gregg wants his company to scale his virtual machines to demand,
because they are paying per use and so they have an incentive to use enough
capacity to hold the service level objectives, but not more.&lt;/p&gt;
&lt;p&gt;The default mechanism to achieve this is a reactive &lt;em&gt;autoscaler&lt;/em&gt; using
&lt;em&gt;loadav&lt;/em&gt; from inside virtual machines as a &lt;em&gt;scale signal&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We need to unpack that. So there is a mechanism that will scale his
deployment by launching more instances of a thing if a condition is true. By
default, the condition is loadav, but Gregg suggests other, less broken
metrics in his article: Different CPU and Scheduler metrics, disk metrics,
or other system metrics.&lt;/p&gt;
&lt;p&gt;In a conversation with Tobias Klausmann, he suggested application level
latencies as a signal. I agree in that these are the best indicator to
signal the existence of a problem. In &lt;a href=&#34;https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html&#34;&gt;Load, Load Testing and
Benchmarking&lt;/a&gt;

,
there is the hockey stick:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Requests/s vs. Response/s (Capacity) and Requests/s vs. Response time
(Latency). As we raise offered load, the system approaches the 100% line
(the vertical saturation line), and a backlog builds.&lt;/p&gt;
&lt;p&gt;The lower graph shows a system under increasing load. Response times will be
almost level while the system is not saturated. If the system reaches
saturation, it is about to receive more requests than it can handle, and
wait time adds to the think time, so response times go up. Sharply.&lt;/p&gt;
&lt;p&gt;Unfortunately, this is a good indicator which is always late. Latency based
autoscaling will react to a system that is saturated when it is saturated,
never before. For a system 10% before saturation and a system 5% before
saturation, the latencies will be almost the same, so that among the jitter
and noise there will be no useful signal to initiate scale-up. Only when we
have saturation the latencies go up to trigger a proper signal, but at that
point the user experience is already going down the drain. And that is kind
of the real problem here.&lt;/p&gt;
&lt;p&gt;The default mechanism to achieve this is a &lt;em&gt;reactive&lt;/em&gt; autoscaler using
loadav from inside virtual machines as a scale signal.&lt;/p&gt;
&lt;p&gt;The scaling mechanism is reactive. It has to be, because any predictive
autoscaling is not generic. It can&amp;rsquo;t be built into the platform. A
predictive autoscaler knows something about the application, or maybe even
the business. For example, you might know from benchmarking that your
application requires an instance of the type &lt;em&gt;Z&lt;/em&gt; for every &lt;em&gt;m&lt;/em&gt; requests/s
going into the system. So you could monitor the request rate and just before
you reach that limit you are ordering the next instance.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/08/Screen-Shot-2017-08-09-at-10.10.06-640x204.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Image from &lt;a href=&#34;%27https://www.slideshare.net/isotopp/boring-dot-com-the-virtues-of-boring-technology&#34;&gt;The virtues of boring technology&lt;/a&gt;

,
Slide #12&lt;/p&gt;
&lt;p&gt;Or you already know the pattern of your business over a year and over a day
and actually will know what the request rate is likely going to be tomorrow
at 9am on August 9, 2017. In that case you can schedule the appropriate
amount of instances in time before the load hits your systems and still have
time to warm up all caches.&lt;/p&gt;
&lt;p&gt;In some environments, supply management is kind of critical: For example,
when you sell hotel rooms, you need to know which trade shows are having
what kind of impact on the availability of beds around the event site and
make sure that you have sufficient supply before the demand materialises.
It&amp;rsquo;s a thing you have to do anyway, for the business.&lt;/p&gt;
&lt;p&gt;But if you are already building demand models for business reasons, you can
also use this data to build demand models for hardware utilisation and use
it to move from reactive autoscaling to predictive autoscaling.&lt;/p&gt;
&lt;p&gt;So here are some alternatives to autoscaling with loadav:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Build predictive models using business data. It will make the business and
your management of it better, and it will make life easier in the machine
room, so it pays for itself over and over.&lt;/li&gt;
&lt;li&gt;Use benchmarking in production to get an idea of the shape of the hockey
stick in your environment. Latencies &amp;gt;&amp;gt; every other metric, Real world
metrics &amp;gt;&amp;gt; any guess you can have.
&lt;ul&gt;
&lt;li&gt;Latency goes up when a thing is saturated. That&amp;rsquo;s the thing your
performance is bound by. You can&amp;rsquo;t survive anything ever, unless you
know precisely what that things is and until it is being monitored
properly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Get a clue about the request pipeline and identify (latency) metrics that
are early warning indicators, if you have any. Then use them for reactive
autoscaling. Also, fix your predictive model if you ever scale reactively.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TL;DR: Reactive autoscaling sucks. Get out of it. Model your shit.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An abundance of IOPS and Zero Jitter</title>
      <link>https://blog.koehntopp.info/2017/07/26/an-abundance-of-iops-and-zero-jitter.html</link>
      <pubDate>Wed, 26 Jul 2017 14:51:55 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/07/26/an-abundance-of-iops-and-zero-jitter.html</guid>
      <description>&lt;p&gt;Two weeks ago, I wrote about
&lt;a href=&#34;https://blog.koehntopp.info/2017/07/07/the-data-center-in-the-age-of-abundance.html&#34;&gt;The Data Center in the Age of Abundance&lt;/a&gt;


and claimed that IOPS are - among other things - a solved problem.&lt;/p&gt;
&lt;p&gt;What does a solved problem look like?&lt;/p&gt;
&lt;p&gt;Here is a benchmark running 100k random writes of 4K per second, with zero
Jitter, at 350µs end-to-end write latency across six switches. Databases
really like reliably timed writes like these. Maximum queue depth would be
48, the system is not touching
that.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/07/pure-storage1.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;and here is iostat on the iSCSI client running the test&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/07/pure-storage2-1024x238.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;100k random writes, 4k write size, inside a 2 TB linux file of random data,
on a 15 TB filesystem with XFS, on an LVM2 volume provided by iSCSI over a
single 10 GBit/s interface, with six switch hops between the linux client
and the array.&lt;/p&gt;
&lt;p&gt;The array claims 150µs latency, on the linux we measure around 350µs. Out of
that, there are less than 50µs from the switches and 150µs or more from the
Linux storage stack (and that is increasingly becoming an issue).&lt;/p&gt;
&lt;p&gt;Tested product was a &lt;a href=&#34;https://www.purestorage.com/products/flasharray-x.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Purestore Flasharray-X&lt;/a&gt;

,
client was Dell PowerEdge R630, 2x E5-2620v4, 128G, 10GBit/s networking.&lt;/p&gt;
&lt;p&gt;Thanks, Peter Buschman!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On cache problems, and what they mean for the future</title>
      <link>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</link>
      <pubDate>Fri, 23 Jun 2017 14:12:04 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/06/ssd-problem.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;This is a disk utilization graph on a heavily loaded Graphite box. In this
case, a Dell with a MegaRAID, but that actually does not matter too much.&lt;/p&gt;
&lt;p&gt;Go-carbon was lagging and buffering on the box, because the SSD was running
at its IOPS limit. At 18:10, the write-back cache and the &amp;ldquo;intelligent
read-ahead&amp;rdquo; are being disabled, that is, the MegaRAID is being force-dumbed
down to a regular non-smart controller. The effect is stunning.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp NORA -l0 -aALL
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp WT -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and also, on top of that,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;Direct IO instead of cached 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp DIRECT -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;Force SSD disk write cache &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;our SSD has super-capacitors, so it safe to &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp -EnDskCache -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What we observe here is part of an ongoing pattern, and we
will see more of it, and at more layers of the persistence-stack in our
systems.&lt;/p&gt;
&lt;h2 id=&#34;iops-are-a-solved-problem&#34;&gt;
    &lt;a href=&#34;#iops-are-a-solved-problem&#34;&gt;
	IOPS are a solved problem
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;At the lowest layers, IOPS are now a solved problem, and will become even
more so. SSD are limited mostly now because of their interfaces, and so we
go from IDE-interfaces to NVME to get rid of that overhead.&lt;/p&gt;
&lt;p&gt;That makes disk-seek operations very cheap - going from 200 IOPS on rotating
rust past 20k IOPS was only the first step, single drives now are offering
200k IOPS and more.&lt;/p&gt;
&lt;p&gt;Bandwidth can also be provided at bus speeds through aggregation, so this is
mostly a package engineering problem.&lt;/p&gt;
&lt;p&gt;Latency is still a problem. Even more than ever, actually, because now the
time to send a packet from a core through the network to a SSD at the other
end of the data center is comparable to or even dominating the time spent
reading or writing that remote media.&lt;/p&gt;
&lt;p&gt;SSD still are disk-like devices. We are reading sectors at a time instead of
individual bytes, and especially in writes we are re-flashing large blocks,
64 KB in size or larger, depending on the hardware. Smart internal
controllers in SSDs are trying to take care of these things in the
background.&lt;/p&gt;
&lt;p&gt;With Optane, this block structure of disks can and will go away. The proper
abstraction for Optane is not a file, but is memory - persistent, byte
addressable memory within an order of magnitude of RAM speed.&lt;/p&gt;
&lt;p&gt;On top of the actual drive sits a large stack of caches and transformation
layers. In this case, one layer, the disk controller and the logic in it,
became a bottleneck: A CPU considerably smaller than the actual system
processor, and with limited memory, was reading ahead file contents that do
not benefit from reading ahead. It was also buffering writes, in order
reorder and merge them, trying to exploit properties of a spinning medium
that was no longer present. The write-pressure from the systems processor
and the data volume became so large that either the CPU on the controller or
the size of the controller-cache became a bottleneck.&lt;/p&gt;
&lt;p&gt;A disk behind the controller would have been even slower than the
controller, but a SSD can actually cope and be faster than the controller
sitting between it and the system CPU. Taking the controller out of the path
speeds things up.&lt;/p&gt;
&lt;p&gt;The commands above take out one layer in the deep and rich storage stack,
but there are many more. Each of them now has the potential to become the
next bottleneck. Or as one of my database colleagues has been known to say
in one form or the other more than once:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Forget caches, just make everything fast all the time.&amp;rdquo; &amp;ndash; Nicolai Plum&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hadoop-in-the-face-of-many-iops&#34;&gt;
    &lt;a href=&#34;#hadoop-in-the-face-of-many-iops&#34;&gt;
	Hadoop in the face of many IOPS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;We will see more of this, and at more levels of the system. Take Hadoop for
example. The two core premises on which Hadoop is built are&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Seeks are expensive. We scan data front to back, and build data
processing on linear I/O (of compressed CSV or JSON files, even!).Even if we
are reading much more data than we need, even if we have to costly
uncompress and parse the data, this method of processing is way faster than
any database could ever be, and we can easily leverage the power of
parallelism.&lt;/li&gt;
&lt;li&gt;Code is smaller than our data. So we create small Java classes with our
code and ship it to the systems where the data we need is stored locally in
order to process it.This is a convoluted way to express our wants within the
rigid framework of Map/Reduce, but it&amp;rsquo;s the only way to code, because
reading all that data and shipping it across the net to where the code lives
is literally impossible.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Premise #2 is no longer valid since
&lt;a href=&#34;https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p183.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupiter Rising&lt;/a&gt;

.
We can disaggregate processing and storage again, because we can build data
center networks that are as fast and wide as system buses, so that any core
in the data center can talk to any disk in the same data center.
&lt;a href=&#34;https://www.youtube.com/watch?v=NfxvjWSgplU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This talk&lt;/a&gt;

 demonstrates this by
creating ephemeral Hadoop processing clusters at the press of a button for
the processing of single queries, by kubernetizing the Hadoop Mappers and
Reducers. In this case, the relationship between the Mapper and the data
this Mapper processes is simply not local at all - the Mapper may in fact
run anywhere in the data center and is no longer tied to where the data is
stored at all. Or, as one of the networking colleagues of mine puts it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Any sufficiently funded technology is indistinguishable from Magic.&amp;rdquo;
(Brian Sayler on the networking underneath a containerized Hadoop and
Compute/Storage disaggregation)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Premise #1 is going out of the window as well. Next year, latest the year
after that, we likely will stop buying rotating rust even for the Hadoop
servers. But that means we could seek again, which means that we could be
using index data structures efficiently to work with data larger than main
memory again. Which means that all these de-normalized, scannable,
inefficiently nested and hard to parse JSON structures will be becoming more
and more of a problem: As I/O takes a smaller percentage of the time spent
on handling the data, we need to optimize the actual data decompression,
parsing and handling more. &lt;em&gt;Hadoop in the current form is a dead man
walking.&lt;/em&gt; There is no alternative piece of software visible at the horizon
at this moment, so these will be interesting times. And there will be more
changes: File I/O is, even at much smaller levels, a lot about reformatting
data from in-memory representations of things to on-disk representations.
In-memory structures are pointered and traversable, aligned to n-byte
boundaries, often lockable structures, because at memory speed these
optimization matter. For persistence, we serialize them in complicated ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Databases like MySQL have all kinds of densely packable data types (1- and
3-byte integers, for example),&lt;/li&gt;
&lt;li&gt;references are IDs, which require lookup, instead of being traversable
pointers&lt;/li&gt;
&lt;li&gt;the process of serialization often requires traversing nested,
multidimensional data structures of ADTs and creating a linear, frozen
representation of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shallow and deep copies need to be considered, depending on the problem.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a fully fledged phase transition where the data is going from a
gaseous, loosely packed form to a densely packed frozen, solid form for
storage. The things beyond SSD, Optane/3D-Xpoint and similar storage, are
more like memory than they are like disks, and hence they likely to some
extent are able to handle &amp;lsquo;gaseous&amp;rsquo; unserialized data and make that
persistent at the same time.&lt;/p&gt;
&lt;p&gt;In the end, the death of the file handle, and hence the death of Unix&lt;/p&gt;
&lt;p&gt;That challenges the fundamental abstraction of Unix, though, because in Unix
everything is a file, which is a linear array of bytes, and is being
accessed through a file handle. Now, with Optane persistent data may be no
longer behind a file handle, but a special kind of memory, and data does not
have to be crystallized into serialized structures before persistence. In
fact, the memory may be so fast that we might not have time to do that. We
require a different compute abstraction instead.&lt;/p&gt;
&lt;p&gt;Which means, when we have it, the result will finally, after five decades,
not really Unix any more.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#34;Usage Patterns and the Economics of the Public Cloud&#34;</title>
      <link>https://blog.koehntopp.info/2017/06/12/usage-patterns-and-the-economics-of-the-public-cloud.html</link>
      <pubDate>Mon, 12 Jun 2017 16:00:10 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/06/12/usage-patterns-and-the-economics-of-the-public-cloud.html</guid>
      <description>&lt;p&gt;The paper (&lt;a href=&#34;http://vita.mcafee.cc/PDF/EconPublicCloud.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;

)
is, to say it in the words of Sascha Konietzko, &lt;a href=&#34;https://www.youtube.com/watch?v=hVgBp5Yu7_w,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eine
ausgesprochene Verbindung von Schlau und
Dumm&lt;/a&gt;

 (&amp;ldquo;a very
special combination of smart and stupid&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;The site mcafee.cc is not related to the corporation of the same
name, but the site of one of the authors, R. Preston McAfee.&lt;/p&gt;
&lt;p&gt;The paper looks at the utilization data from a number of public
clouds, and tries to apply some dynamic price finding logic to
it. The authors are surprised by the level of stability in the
cloud purchase and actual usage, and try to hypothesize why is
is the case. They claim that a more dynamic price finding model
might help to improve yield and utilization at the same time
(but in the conclusion discover why in reality that has not
happened).&lt;/p&gt;
&lt;p&gt;Being AI people with not much Ops experience, they make a number
of weird assumptions. For example, they are looking at CPU usage
data in 5 min aggregation buckets and do math against 100% CPU
utilization. Even if you assume at all or most workloads are
actually CPU bound, 5 minute buckets of CPU usage are way to
coarse to use for 100% as a utilization target. That is, because
all the actual spikes are shorter and invisible. (Workloads are
rarely CPU bound, and especially not in the cloud, which is most
often network bound.) (They do look at 5 min bucket maxima =
100th percentiles in some cases. But even that does not tell you
for how long in a 5 min bucket you hit the roof. But hitting the
roof even for a short time creates latency outliers, which in an
actual cloud native microservice framework propagate and
multiply, turning most of the requests into SLO violations.
Jitter kills).&lt;/p&gt;
&lt;p&gt;They are also for the most part ignore the cost of the cognitive
load of dynamic pricing, or the cost of coding for variable
deployment sizes in traditional workloads.&lt;/p&gt;
&lt;p&gt;Finally, they are looking at a VM based IaaS deployment. VM
based deployments are likely to see traditional bare metal
workloads being forklifted into the cloud. Such deployments do
not scale, because they weren&amp;rsquo;t built for dynamic scaling.
Cloud Native stuff is more likely to be found in environments
such as Amazon Lambda and Athena. This is a lot like looking at
the childrens pool only and coming to the conclusion that most
people can&amp;rsquo;t swim, i.e. there may be selection bias.&lt;/p&gt;
&lt;p&gt;There are useful thoughts in the paper, too. For example, they
find that they can model and predict many workloads and use this
for scaling in advance. In fact, typical reactive autoscalers do
not work properly, because by the time they trigger a scaling
action, demand is already there and latencies lag in violation
of the SLO. The systems created as a reaction to a reactive
autoscaler triggering are slow, because caches are cold, and
will have trouble keeping up, right in the middle of a spike
action.&lt;/p&gt;
&lt;p&gt;Predictive scalers work better and may be safer. Here you
establish an absolute size limit (which usually exists due to
architectural constraints and locks on shared state), and size
down from it to meet predicted demand with a comfortable margin
of error. Then you scale up and down following predicted demand,
correcting the model in time to keep the margin. This should
create capacity in advance, and give it time to warm up.&lt;/p&gt;
&lt;p&gt;Also, reading the paper you could come to the conclusion that
the market is stable and static, because it is stable and
static: Because nobody rocks the demand pressure up and down,
the prices are stable and nobody has a reason to implement
savings by changing the size of the deployment needlessly.&lt;/p&gt;
&lt;p&gt;Of course, once a sufficient number of people start doing this,
demand pressure will vary sufficiently to affect short term
pricing, so that everybody eventually needs to react to the
changed environmental conditions. Noise breeding complexity,
breeding even more noise and complexity, until everything drowns
in chaos and the system needs downtime to clean the noise from
the system.&lt;/p&gt;
&lt;p&gt;TL;DR: Bunch of objectivist hipsters with belief in market
forces and no Ops experience discover in the final paragraphs of
their paper that stability and simplicity are tangible,
priceable assets in themselves and maybe all the dynamic market
shit is not really helpful in all cases, because stability
savings outweigh wins from leveraging dynamic market forces.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The cost of winning…</title>
      <link>https://blog.koehntopp.info/2017/03/10/the-cost-of-winning.html</link>
      <pubDate>Fri, 10 Mar 2017 18:50:38 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/03/10/the-cost-of-winning.html</guid>
      <description>&lt;p&gt;Tech.co has an article titled
&lt;a href=&#34;http://tech.co/ai-startups-winning-cybersecurity-race-2017-03&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Artificial Intelligence Startups Are Winning the Cybersecurity Race&lt;/a&gt;

. The
claim is basically first that old, pattern and signature based malware
recognition is useless, and second, that new, behavior based malware
recognition employing mystery AI technologies fixes things. The article
closes with&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the near future, we predict that AI will be able to effectively fight
against hackers by easily detecting repacked viruses. It’s just a matter
of time. That’s why, more than resources or experience, companies who
actively apply AI, especially cybersecurity companies, will ultimately be
successful.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That will be interesting to see. Here is a data point:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On a computer without any protection installed, unpacking a node.js based
hipster chat application zip into 7500 files inside an application folder
takes 3.5 seconds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So why is this other device from the same maker close to unusable and has
close to zero battery life? Let&amp;rsquo;s see: It has been gifted with the full
package of corporate enterprise security: Junos Pulse Endpoint Security,
FireEye endpoint security and TrendMicro Enterprise protection.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With everything on, it takes 27 seconds (instead of 3 seconds) to unpack
the same archive.&lt;/li&gt;
&lt;li&gt;Getting root and uninstalling FireEye reduces the unpack time to 18
seconds.&lt;/li&gt;
&lt;li&gt;Reading the TrendMicro config file and doing the Unpacking inside a
specific git directory, which is exempt from TrendMicro scanning takes 11
seconds.&lt;/li&gt;
&lt;li&gt;Uninstalling Junos Pulse, and doing it in the exempt git directory takes 8
seconds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The uninstallation or going into exempt directories was based on observing a
system monitor and finding out which processes consume abnormal amounts of
CPU during the operation. In fact, the git directory is exempt because it
can contain on the upside of half a million files and having TrendMicro
active inside that directory simply shuts down the machine, because battery
empty.&lt;/p&gt;
&lt;p&gt;I guess the point I am trying to make here is that &amp;ldquo;more protection&amp;rdquo; is
going to mean &amp;ldquo;more mAh and Watts spent on stuff not related to the primary
purpose of the machine&amp;rdquo;. And we are in an age where consumer devices are
increasingly run on battery, and have thermal budgets limited to 5W and less
because they have no fan.&lt;/p&gt;
&lt;p&gt;So I am going to predict that in the near future we will see a growing
conflict between &amp;ldquo;protection&amp;rdquo; software uselessly wasting performance and
battery and users, who actually want to use their stuff and need to be
vigiliant for things that eat battery capacity and heat the CPU needlessly.
Your phone, your fanless tablet, your 12&amp;quot; Macbook and your tablet-computer
hybrid won&amp;rsquo;t be running much security software because it&amp;rsquo;s mobile, running
on battery and has to live with 5W or less.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OMG, our cybervaccines are failing</title>
      <link>https://blog.koehntopp.info/2017/02/17/omg-our-cybervaccines-are-failing.html</link>
      <pubDate>Fri, 17 Feb 2017 15:37:50 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/02/17/omg-our-cybervaccines-are-failing.html</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.darkreading.com/threat-intelligence/-what-to-do-when-all-malware-is-zero-day/a/d-id/1328155&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dark Reading&lt;/a&gt;


is scared: All new malware is &amp;ldquo;zero-day&amp;rdquo;, for an interesting and wrong
definition of zero-day, because then the article reads much more impressive.&lt;/p&gt;
&lt;p&gt;The actual definition of a Zero Day is a previously unknown exploit that is
being used by some party to compromise a machine. In the article, the term
is used differently, meaning a file that is a known malware, but has changed
itself so that it has a checksum that is not in currently distributed
signature catalogs of known malware. That is of course neither correct, nor
new.&lt;/p&gt;
&lt;p&gt;Mutation engines, for example for viruses, are an old hat. We have known
about them for more than a decade, almost two. The better ones take x86
machine code, auto-dissect it into basic blocks and then re-link these to a
semantically equivalent program in a completely different, random order.
They may also re-compile certain assembly instructions in these basic blocks
to other, semantically equivalent assembly instructions that have different
byte codes: There are many ways to clear a register or to load a value from
memory, after all.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In today&amp;rsquo;s detection industry, one should think of hashing as more of a
shortcut to locate the easy stuff, or rule out known good files
(whitelisting).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&amp;rsquo;s more like the state of the detection reality from 15 years ago. On
the other hand, threat detection software is getting out of hand. A Macbook
I have had access to can unzip a piece of software with some 7000 files just
fine in under 3 seconds to its internal SSD. The same Macbook with a
&lt;a href=&#34;http://docs.trendmicro.com/en-us/enterprise/trend-micro-security-%28for-mac%29-21/agentinstall_ch_intro/agent_install_method.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trendmicro AV solution&lt;/a&gt;


installed takes 11 seconds to do the same, and 18 seconds if it is done in a
directory that is not excluded from scan in the TM config file. Add
&lt;a href=&#34;https://www.fireeye.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FireEye&lt;/a&gt;

 on top of that and the same operation is
now at 27 seconds execution time. The laptop is now secure mostly because
nobody can do anything with it any more. In
&lt;a href=&#34;https://www.heise.de/newsticker/meldung/Sicherheitsforscher-an-AV-Hersteller-Finger-weg-von-HTTPS-3620159.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;many&lt;/a&gt;


&lt;a href=&#34;https://arstechnica.com/information-technology/2017/01/antivirus-is-bad/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;other&lt;/a&gt;


&lt;a href=&#34;https://www.theregister.co.uk/2016/03/31/trend_micro_patches_command_execution_flaw/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;articles&lt;/a&gt;

,
&lt;a href=&#34;https://googleprojectzero.blogspot.nl/2015/09/kaspersky-mo-unpackers-mo-problems.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt;


&lt;a href=&#34;https://bugs.chromium.org/p/project-zero/issues/detail?id=978&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;so&lt;/a&gt;


&lt;a href=&#34;http://www.forbes.com/sites/thomasbrewster/2017/01/25/trend-micro-security-exposed-200-flaws-hacked/#181469e55d68&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;called&lt;/a&gt;


security solutions have been shown to be actually contributing to the
problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Load, Load Testing and Benchmarking</title>
      <link>https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html</link>
      <pubDate>Thu, 16 Feb 2017 21:13:28 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html</guid>
      <description>&lt;p&gt;(This article also available in &lt;a href=&#34;https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html&#34;&gt;german language&lt;/a&gt;

.)&lt;/p&gt;
&lt;p&gt;So you have a new system and want to know what the load limits are. For that
you want to run a benchmark.&lt;/p&gt;
&lt;h2 id=&#34;basic-benchmarking&#34;&gt;
    &lt;a href=&#34;#basic-benchmarking&#34;&gt;
	Basic Benchmarking
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The main plan looks like this:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark_plana.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The basic idea: Find a box, offer load, see what happens, learn.&lt;/p&gt;
&lt;p&gt;You grab a box and find a method to generate load. Eventually the box will
be fully loaded and you will notice this somehow.&lt;/p&gt;
&lt;p&gt;The first mistake: running the load generator and the system to test on the
same box. That won&amp;rsquo;t work.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s our goal to bring the box to its limits. Actually, we want to push it
past that in order to see what it is that is limiting it. That will happen
only when we are able to generate more load than the target system can
actually process. If the load generator and the target system are sharing
any resources that will never happen: The starved resource, for example CPU,
will be slowing down not only the target application but also the load
generator until we are reaching equilibrium at an unknown point below the
actual limit.&lt;/p&gt;
&lt;p&gt;That way we will never see what color the smoke is when the box catches
fire, that is, what the actual system behaviour under overload is. So we
need to separate the load generator and the target system.&lt;/p&gt;
&lt;p&gt;The second mistake: The target system or the load generated are not close
enough to production. In database land, typical mistakes are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The tested system has less memory or a different disk subsystem than production.&lt;/li&gt;
&lt;li&gt;The test data set is smaller than production.&lt;/li&gt;
&lt;li&gt;The test query set or the test data set is biased relative to production.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In all of these cases we will be learning something, but it will not easily
port to production. For example, in 2005 the german computer magazine c&amp;rsquo;t
had a test media shop selling CD and DVD media, and was using this to
benchmark implementations of the system with different databases.
The actual benchmark was an equidistribution of queries, so there have been
no best sellers and no long tail.&lt;/p&gt;
&lt;p&gt;To win the benchmark it was mandatory to disable all caches, because there
was no set of popular media which would have been gaining from caching. That
outcome is the opposite of what is necessary in a real world scenario, where
there is a clear long tail distribution of queries.&lt;/p&gt;
&lt;p&gt;The closer you can bring the test load, the tested system and the test data
to production the besser the results. Which is why at work we are trying
very hard to make testing in production safe, and then we test whatever is
possible in production.&lt;/p&gt;
&lt;h2 id=&#34;saturation&#34;&gt;
    &lt;a href=&#34;#saturation&#34;&gt;
	Saturation
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;When you offer load to a system, the average load on the system will rise.
But load usually is not constant, but will vary, depending on what users are
doing and how expensive the individual requests are: Not all operations are
equally expensive.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark1.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;A system close to saturation: Average load is slightly below the maximum, but
individual peaks spike above the saturation line.&lt;/p&gt;
&lt;p&gt;Consequently we are not pushing the system to a limit, but we are raising a
rolling average in which the actual load is constantly fluctuating and
oscillating around this average until the peaks exceed the point of
saturation.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark3.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;The average offered load is below the 100% saturation line, but the peaks
are already exceeding the limit.&lt;/p&gt;
&lt;p&gt;That is of course nonsense. The saturation limit is a hard limit, the system
can&amp;rsquo;t produce more than that, because a necessary resource is exhausted and
the system is constrained by that resource. So what actually happens is that
the system will be building a backlog whenever the offered load goes above
the 100% line. Requests will pile up in some queue and will only be
processed when the load goes below that limit.&lt;/p&gt;
&lt;p&gt;As we push the system harder, it will exceed the saturation point more and
more and phases where it can gain on the building backlog will become rarer.
But since the costs for an individual request vary, it is hard to overload
the system in a controlled way - harder the higher that variance is.&lt;/p&gt;
&lt;p&gt;That is one of many reasons why we focus on outliers and worst cases first
when we care about optimization: In order to be able to meet any kind of
service level objective we need to handle these extremely bad cases first
and narrow the band of possible response times, even if that does not move
the mean much. Only then we can try to improve the mean response time of the
system.&lt;/p&gt;
&lt;h2 id=&#34;wait-time-and-the-hockey-stick&#34;&gt;
    &lt;a href=&#34;#wait-time-and-the-hockey-stick&#34;&gt;
	Wait time and the hockey stick
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;What actually happens at saturation becomes clearer as we transform the
above graph and take it out of the time domain. We will be graphing offered
load (requests/s) vs. throughput (responses/s) and offered load (requests/s)
vs. response time (latency).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Requests/s vs. Response/s (Capacity) and Requests/s vs. Response time
(Latency). As we raise offered load, the system approaches the 100% line
(the vertical saturation line), and a backlog builds.&lt;/p&gt;
&lt;p&gt;As we increase load, each request will generate a response: the curve in the
capacity graph goes up at a 45deg angle. Even as the load rises, requests
will take approximately the same time to process - we are calling this time
the think time.&lt;/p&gt;
&lt;p&gt;Once we approach saturation, a resource in our system will be starved and
constrain capacity. Even if we are offering more load, this will not
generate more responses. The capacity graph flattens out. Since more
requests are coming in than we have capacity for, these excess requests will
be queued. Wait time is being added on top of the think time.&lt;/p&gt;
&lt;p&gt;And since we are continuing to add more requests than we can handle, the
queue and the wait time will rise rapidly and without bounds. The latency
curve has the shape of a hockey stick.&lt;/p&gt;
&lt;h2 id=&#34;testing-in-production&#34;&gt;
    &lt;a href=&#34;#testing-in-production&#34;&gt;
	Testing in production
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;That is not a theory, but can be shown in real production systems.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/benchmark5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;A typical production setup. User requests are entering the system from the
internet at the top, hitting a load balancer. The request are routed to a
set of web servers behind the load balancer.&lt;/p&gt;
&lt;p&gt;Assuming that you have a minimum size for load testing with production load:
You need to have a sufficient number of users, large enough so that
individual users do not contribute in a meaningful way. You will need a
frontend load balancer in front of a number of webservers, and you need to
be able to modify load distribution weights live in this setup.&lt;/p&gt;
&lt;p&gt;The load tests starts with running an Apache Siege load generator at a very
low setting from the outside against the setup - actually, the Siege is not
running against the load balancer, but against one individual web server
which is the one which we will be trying to overload. This is not done to
generate load, but to measure latency: In normal configuration our system
will not be overloaded, so the baseline latency we are seeing is think time.&lt;/p&gt;
&lt;p&gt;During the benchmark we are playing with weights in the load balancer in
order to direct more load to individual web servers. The load balancing
weight of the web server getting the Siege requests is now being increased
so that it will need to handle more actual user requests than the other
servers. Eventually either timeouts will be showing up in the error log, or
the request latency shown by Siege will be going up dramatically.&lt;/p&gt;
&lt;p&gt;Either signal indicates saturation, and we need to stabilize offered load at
or very slightly below this point in order to find the saturation point.&lt;/p&gt;
&lt;p&gt;Here is a time domain plot of such an event:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/load-test-time.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;A request graph of a MySQL database slave being load tested. Writes are
coming in via replication, and are not subject to load testing, hence
stable. Selects are being load tested and increase at the tests
commence.&lt;/p&gt;
&lt;p&gt;In the test graph above we are looking at query counters of a MySQL database
slave during three load test events. Write queries (insert, update, delete)
are coming in through replication from the upstream master and are not
affected by the load test. Selects are being increased by load balancer
manipulation.&lt;/p&gt;
&lt;p&gt;During the third test there is a spike of update statements
due to a cron script running and affecting the test, invalidating the
results of that run.&lt;/p&gt;
&lt;p&gt;Taking the results from the above run and plotting them in a latency graph
results in the following graph. The hockey stick is clearly visible:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/02/load-test-comparison.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Latency graph: test1 is shown in blue, test2 in orange.&lt;/p&gt;
&lt;p&gt;The graph shows offered load vs. latency of the configurations test1 and
test2 from the run above. Configuration test2 is clearly superior. A variant
of this graph uses larger symbols as the error rate of that measurement
increases to add another dimension. That way the stability of the system
under test in overload is being visualized as well.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hipsterdoom with Mongobingo</title>
      <link>https://blog.koehntopp.info/2017/02/10/hipsterdoom-at-mongobingo.html</link>
      <pubDate>Fri, 10 Feb 2017 04:07:54 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/02/10/hipsterdoom-at-mongobingo.html</guid>
      <description>&lt;p&gt;Felix Gessert does a postmortem of the failed Parse startup and product:
&amp;ldquo;&lt;a href=&#34;https://medium.baqend.com/parse-is-gone-a-few-secrets-about-their-infrastructure-91b3ab2fcf71#.ve5hi5lcd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The AWS and MongoDB Infrastructure of Parse: Lessons Learned&lt;/a&gt;

&amp;rdquo;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Technical problem II: the real problem and bottleneck was not the API
servers but almost always the shared MongoDB database cluster.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;And that was with MongoRocks (Mongo on RocksDB) and replacing the initial
app in Ruby with a Go implementation of said thing, with WriteConcern = 1,
and other horrible presets. All in all, this is like the perfect nightmare
of startup architecture decisions. Felix closes pointing at his current
project:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If this idea sounds interesting to you, have a look at Baqend. It is a
high-performance BaaS that focuses on web performance through transparent
caching and scalability through auto-sharding and polyglot persistence.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bingo. Also, found the Hipster.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dude, where is my memory?</title>
      <link>https://blog.koehntopp.info/2012/11/12/dude-where-is-my-memory.html</link>
      <pubDate>Mon, 12 Nov 2012 14:06:40 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/11/12/dude-where-is-my-memory.html</guid>
      <description>&lt;p&gt;&amp;ldquo;Kris, bitte schau Dir mal unsere Datenbank an.  Wir haben hier einen
Generator für unsere Materialized Views, und auf einer Datenbank von 6 GB
Größe werden 40 GB Speicher gefüllt und wir kommen sogar ins Swappen.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Na, das ist mal interessant.  The fragliche Kiste hat 48 GB RAM, und in der
Tat kaum 6 GB Daten.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data_length&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tables&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;table_schema&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;information_schema&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;performance_schema&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mysql&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;832778930664&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Aber in &amp;ldquo;top&amp;rdquo; sieht das so aus, und wächst:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt; 7552 mysql     15   0 55.1g  43g 6888 S  0.7 91.7 499:13.56 mysqld 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das wird sicher interessant.&lt;/p&gt;
&lt;p&gt;Der Zwilling dieser Maschine zeigt ähnliches Verhalten, aber auf einem niedrigeren Level.&lt;/p&gt;
&lt;p&gt;Wenn es um Speicherprobleme und Swap geht, dann schaue ich routinemäßig erst
mal die &lt;a
href=&#39;http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/&#39;&gt;numa_maps&lt;/a&gt;
der Maschine an.  Aber sie und ihr Zwilling sind gut ausbalanciert.&lt;/p&gt;
&lt;p&gt;Der Zwilling:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; /usr/local/booking-mysql/numa-maps-summary.pl &amp;lt; /proc/25996/numa_maps 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;N0        :      1777572 (  6.78 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;N1        :      1777759 (  6.78 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;active    :           37 (  0.00 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;anon      :      3553604 ( 13.56 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;dirty     :      3553605 ( 13.56 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;mapmax    :          237 (  0.00 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;mapped    :         1783 (  0.01 GB)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wir starten den Server mal neu, um zu sehen, ob das Problem reproduzierbar
ist.  Ich zwinge den InnoDB Buffer Pool auch mal 10 GB kleiner, nur um
sicherzugehen, daß wir da nichts falsch zu groß eingestellt haben.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/memory-problem.png&#34; alt=&#34;Speichersituation&#34;  /&gt;
&lt;/p&gt;


Die alte Speichersituation, und nach einem Neustart eine um 10 GB
verkleinerter &lt;code&gt;innodb_buffer_pool_size&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Das scheint in der Tat das Problem zu beheben, aber wir haben immer noch
eine InnoDB Buffer Pool Nutzung, die um den Faktor 3-4 oberhalb der
Datengröße liegt, und das ist kaum zu erklären.  Auch die Resident Set Size
(RES) in top ist immer noch viel größer als die Datengröße.&lt;/p&gt;
&lt;p&gt;Was passiert hier wirklich?  Wenn ich doch nur in den Buffer Pool
hineinschauen könnte.&lt;/p&gt;
&lt;p&gt;Moment mal. Ich kann:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m9&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tables&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;like&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;innodb_buffer%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;               &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_PAGE_LRU&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_PAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_POOL_STATS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;--------------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Nach dem Nachlesen von &lt;a
href=&#39;http://dev.mysql.com/doc/refman/5.6/en/innodb-buffer-page-table.html&#39;&gt;INFORMATION_SCHEMA.INNODB_BUFFER_PAGE&lt;/a&gt;
bekomme ich&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16384&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_PAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TRX_SYSTEM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01562500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IBUF_FREE_LIST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12500000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INODE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15625000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FILE_SPACE_HEADER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;23437500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;EXTENT_DESCRIPTOR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32812500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IBUF_BITMAP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;45312500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SYSTEM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;03125000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ALLOCATED&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;50000000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UNDO_LOG&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;27&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;75000000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;585&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;70312500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;BLOB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5073&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;81250000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;UNKNOWN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;           &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;21932&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;60937500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;48&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;und vermutlich ein monumentales globales 5-Sekunden-Lock auf dem Buffer
Pool, um dieses Ergebnis zu erzeugen.  UNKNOWN ist in Wahrheit freier
Speicher im Buffer Pool der soeben neu gestarteten Box.  5 GB sind in BLOBs,
und das scheint der Kern unseres Problems zu sein.  INDEX sind die Daten in
den Tabellen (&amp;lsquo;PRIMARY&amp;rsquo;) und die sekundären Indices.  Und der Rest ist
Systemspeicher und sieht nicht krank aus.&lt;/p&gt;
&lt;p&gt;Die Frage ist also: Was ist mit dem ganzen BLOB-Speicher da?  Wo kommt der
her?  Leider nutzen uns table_name und index_name hier gar nix, wenn der
page_type BLOB ist:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16384&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_PAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+-----------------------------+-----------------------+----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+-----------------------------+-----------------------+----------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UNDO_LOG&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                        &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;27&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;75000000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;               &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;141&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;48437500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;               &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;430&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;87500000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;BLOB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                        &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5073&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;81250000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Aber es gibt eine SPACE id, und die kann über INNODB_SYS_TABLESPACES
aufgelöst werden.  Schauen wir mal:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16384&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INNODB_BUFFER_PAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;left&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;innodb_sys_tablespaces&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;space&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;space&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;space&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...............&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;141&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;48437500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;....................&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;430&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;87500000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;BLOB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;....................&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5073&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;68750000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Also haben wir hier eine bestimmte Tabelle, die den ganzen BLOB-Speicher
aufbraucht.  Die Definition legt das nahe:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;G&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_hotel_hotelpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Create&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;Table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mediumint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsigned&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mediumblob&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;digest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;binary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_change&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsigned&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_check&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsigned&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NOT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_check&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_check&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ENGINE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;InnoDB&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;DEFAULT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CHARSET&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;latin1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;row&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;00&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Diese tabelle enthält mehr oder weniger alle Template-Variablen für eine
id/action-Kombination in serialisierter Form, um die Anzahl von Queries pro
Seite zu reduzieren.  Eine normalisierte, live generierte Form der Seite
braucht eine dreistellige Anzahl von Queries, ein Zugriff auf die
vorgerechneten Daten generiert dieselbe Seite mit weniger als 7 Queries.&lt;/p&gt;
&lt;p&gt;Wir schließen unser Debugging ab:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Kristian&amp;gt; Diese Blobs, werden die oft neu berechnet?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;SimonB&amp;gt; Im Moment ja, weil ich sie immer aktualisiere.  Normalerweise
würde ich das nur tun, wenn sich der Digest ändert.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Kristian&amp;gt; Resident Set Size ist jetzt bei 15 GB und stabil.  Das heißt,
wenn ich den Buffer Pool klein genug halte wird die Maschine nicht
swappen.  Wir verbrauchen eine Menge Network Buffer zusätzlich, wegen der
ganzen Blobs, und das ist weswegen wir so einen großen Speicher-Overhead
pro Connection haben&amp;hellip;  Jedenfalls ist das grad meine operative Theorie.
MySQL &amp;amp; BLOBs = ganz übler Mist.&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;md2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kb_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+-------------------+-------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+-------------------+-------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3002&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;478883&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24968&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2430&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------------+-------------------+-------------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das heißt, ich vermute, daß das ständige neu Schreiben der BLOBs in InnoDB
die Storage Engine dazu bringt, vorübergehend eine große Menge BLOB-Speicher
(neben dem eigentlichen Row-Speicher) zu allozieren.  Und der Per-Connection
Overhead ist größer, weil InnoDB BLOBs in den SQL-Teil von MySQL dupliziert
werden, um dann über die Network Buffer zum Client gesendet zu werden.
Böser Overhead.&lt;/p&gt;
&lt;p&gt;MySQL ist nicht sehr gut drain mit großen BLOBs umzugehen.  Vielleicht
sollten wir die SQL-Schicht mit HandlerSocket oder etwas anderem umgehen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Enemy Action</title>
      <link>https://blog.koehntopp.info/2012/10/31/enemy-action.html</link>
      <pubDate>Wed, 31 Oct 2012 15:30:14 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/10/31/enemy-action.html</guid>
      <description>&lt;p&gt;&amp;ldquo;Kris, guck mal, connection surge auf $WICHTIGER_MASTER, davor kurzer Activity drop. Alle anderen Graphen sehen normal aus.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;![Graph: Connection Surge]({{ site.baseurl }}/uploads/screenshot-kris-20121031-1.png)&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;![Graph: QPS Drop]({{ site.baseurl }}/uploads/screenshot-kris-20121031-2.png)&lt;/p&gt;
&lt;p&gt;Ich gucke.&lt;/p&gt;
&lt;p&gt;Alle anderen Graphen sehen in der Tat normal aus. Aber um 13:20 kommt für kurze Zeit alles Processing zum Stillstand.&lt;/p&gt;
&lt;p&gt;Wir haben ja &lt;a href=&#39;http://blog.wl0.org/2011/02/log_processlist-sh-script-for-monitoring-mysql-instances/&#39;&gt;log_processlist.pl&lt;/a&gt;. Falls es sich also um irgendein wildgewordenes Lock handeln sollte, würde ich das also in den 13_20 und 13_21 Dateien sehen. Beide sind in der Tat größer: Statt 250 Connections zeichnen wir deutlich über 400 Connections in diesen beiden Minuten auf.&lt;/p&gt;
&lt;p&gt;Aber: In der Processlist sind keine Irregularitäten zu sehen. Es handelt sich, wenn unser Monitoring keine Löcher hat, nicht um einen Stall und Pileup im Datenbankserver, sondern eine externe Ursache.&lt;/p&gt;
&lt;p&gt;Dies ist ein Master. Der hat sein Datadir auf einer NetApp. Mein Rat an den Fragesteller: Sprich mal mit den Filer-Leuten. Vielleicht haben die da grad an ihren Spielzeugen gebastelt. Während der Fragesteller davon zieht, wühle ich weiter in den Logs - wir haben ja genug davon.&lt;/p&gt;
&lt;p&gt;Und dann:&lt;/p&gt;
&lt;p&gt;&lt;tt&gt;Oct 31 13:20:10 master kernel: bnx2 0000:03:00.0: eth0: NIC Copper Link is Down
Oct 31 13:20:20 master kernel: bnx2 0000:03:00.0: eth0: NIC Copper Link is Up, 1000 Mbps full duplex, receive &amp;amp; transmit flow control ON&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;Aha. Die Filer-Leute sind also freigesprochen, wir haben stattdessen freundliches Feuer von den Zauberschraubern bekommen. Ich nehme an, jemand dort ist so konzentriert am Zeugs racken gewesen, daß für sie inzwischen alle Server gleich sind - sehen ja auch alle gleich aus.&lt;/p&gt;
&lt;p&gt;Diese Person muß gefunden und auf das Lesen von Serverlabels aufmerksam gemacht werden. Manchmal ist die Datenbank halt nicht schuld.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL Replication Load Monitor</title>
      <link>https://blog.koehntopp.info/2012/09/28/mysql-replication-load-monitor.html</link>
      <pubDate>Fri, 28 Sep 2012 11:26:04 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/09/28/mysql-replication-load-monitor.html</guid>
      <description>&lt;p&gt;Mein Kollege Dennis Kaarsemaker hat jetzt einen
&lt;a href=&#34;//www.kaarsemaker.net/blog/2012/09/27/monitoring-replication-load-graphite/&#34;&gt;Artikel&lt;/a&gt;


zu dem
&lt;a href=&#34;http://github.com/seveas/MysqlPerfCollector&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Replication Load Monitor&lt;/a&gt;


von Booking.com gebloggt.  Der Monitor basiert auf Arbeiten von
&lt;a href=&#34;http://www.markleith.co.uk/2012/07/24/a-mysql-replication-load-average-with-performance-schema/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mark Leith&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;Möge er Euch allen nützen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>House und Heisenberg revisited</title>
      <link>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</link>
      <pubDate>Tue, 25 Sep 2012 11:11:06 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/09/25/house-und-heisenberg-revisited.html</guid>
      <description>&lt;p&gt;Ich habe heute an dem Problem weiter geforscht und wir haben etabliert,
dass die Ursache nicht der Quelltext des betreffenden Diamond-Collectors sein kann.&lt;/p&gt;
&lt;p&gt;Auf allen betroffenen Kisten habe ich dann gesehen,
das die entsprechenden Queries gegen Performance-Schema ein&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;performance_schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Empty&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;zurück liefern.&lt;/p&gt;
&lt;p&gt;Weitere Untersuchung stellt heraus: P_S ist aber an.
Jedoch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;performance_schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setup_instruments&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Empty&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;03&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;performance_schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setup_timers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Empty&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;performance_schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setup_consumers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Empty&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;02&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;und das bleibt auch so, sogar über Server-Restarts hinweg.&lt;br&gt;
Warum ist das so?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; /mysql/*/data/performance_schema/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; ls -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;total 1840
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw-rw---- 1 mysql mysql  8624 Oct  6  2011 cond_instances.frm
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw-rw---- 1 mysql mysql 98304 Oct  6  2011 cond_instances.ibd
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw-rw---- 1 mysql mysql    61 Oct  6  2011 db.opt
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw-rw---- 1 mysql mysql  9220 Oct  6  2011 events_waits_current.frm
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw-rw---- 1 mysql mysql 98304 Oct  6  2011 events_waits_current.ibd
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;und ein &lt;code&gt;SHOW CREATE TABLE&lt;/code&gt; bestätigt das:
Die betreffenden Tabellen sind gar keine &lt;code&gt;P_S&lt;/code&gt;-Tabellen, sondern InnoDB.
Das soll nicht so sein.&lt;/p&gt;
&lt;p&gt;Damit ist klar, wieso es überhaupt zu Transaktionen kommen kann:&lt;/p&gt;
&lt;p&gt;Der Code im Diamond-Collector setzt nur Queries gegen &lt;code&gt;performance_schema&lt;/code&gt; ab.
Da dort normal keine Tabellen vorhanden sind, die Transaktionen unterstützen, kann es auch nie zu Transaktionen kommen.
In den defekten Kisten wurden die Tabellen in &lt;code&gt;performance_schema&lt;/code&gt; fälschlicherweise als InnoDB erzeugt.
Das alleine hätte kein Problem erzeugt,
weil jedes Kommando in MySQL eine Transaktion in sich selbst ist- &lt;code&gt;AUTOCOMMIT = 1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Aber:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Starting with 1.2.0, MySQLdb disables autocommit by default, as required
by the DB-API standard (PEP-249)&amp;quot;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In diesem Fall generiert das Lesen von InnoDB-Tabellen den Start einer r/o Transaktion
und erzeugt einen Stable View auf alle InnoDB Tabellen.
Dieser wird gehalten bis zum Ende der Transaktion, das niemals kommt, außer der Collector disconnected.&lt;/p&gt;
&lt;p&gt;Die immer weiter wachsende Größe des Undo-Logs verlangsamt den Server bis zum Stillstand.
Ein KILL auf die Verbindung bringt nur vorübergehende Linderung.&lt;/p&gt;
&lt;p&gt;Der Fix ist in der Tat&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BNe&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;select 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;  concat(&amp;#39;drop table &amp;#39;, table_name, &amp;#39;;&amp;#39;) 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;from 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;  information_schema.tables 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;where 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;  table_schema = &amp;#39;performance_schema&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;performance_schema&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql_upgrade&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;…&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;und alles wird gut - sogar ohne Neustart.&lt;/p&gt;
&lt;p&gt;Die Ursache für das Seltsame Verhalten™ der betroffenen Büchsen
bei einer automatisierten Installation verbleibt weiter unklar.&lt;br&gt;
Der betreffende Collector läuft jetzt jedoch auch auf diesen Maschinen und liefert Daten.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Der Herr House und der Herr Heisenberg haben Replication Delay</title>
      <link>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</link>
      <pubDate>Mon, 24 Sep 2012 19:24:19 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/09/24/der-herr-house-und-der-herr-heisenberg-haben-replication-delay.html</guid>
      <description>&lt;p&gt;Heute erreicht mich eine Mail,
in der ein DBA sich über steigende Replication Delay in einer bestimmten Replikationshierarchie beschwert.&lt;/p&gt;
&lt;p&gt;Das ist schlecht, denn die betreffende Hierarchie ist wichtig.
Also die &amp;lsquo;Wenn die nicht geht schlafen Leute unter Brücken&amp;rsquo;-Art von wichtig.&lt;/p&gt;
&lt;p&gt;Die Theorie war, dass die Änderungsrate in dieser Hierarchie so hoch ist,
dass die Schreiblast von MySQL Replikation, die ja Single Threaded ist, nicht mehr bewältigt werden kann.
Für diese Theorie sprach nach dem ersten Augenschein,
dass alle betroffenen Kisten keine lokalen Platten hatten, sondern auf einem Filer lagen,
und Filer sterben wegen der hohen Kommunikationslatenz im SAN bei uns in der Regel weit vor lokalen Platten,
wenn es um Replikation geht:
Filer sind mehr so beim parallelen Schreiben mit mehreren Threads gut.&lt;/p&gt;
&lt;p&gt;Wenn dem so wäre, wäre das schon einen Seufzer wert,
denn die betreffende Replikationshierarchie war gerade beim Reengineering auf dem OP
und sollte eigentlich derzeit kaum auswertbare Technical Debt haben.&lt;br&gt;
Wenn die trotzdem Replication Delay akkumuliert, dann haben wir ein ernstes Problem.&lt;/p&gt;
&lt;p&gt;Nun bin ich jemand, der Lügen gewohnt ist.&lt;br&gt;
Leute lügen.&lt;br&gt;
Und Maschinen lügen auch.
Aber schauen wir erst mal ins
&lt;a href=&#34;http://graphite.wikidot.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monitoring&lt;/a&gt;


und schauen wie schlimm es ist.
Ich greife mir einen Host aus der angeblich kränkelnden Hierarchie:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay1.png&#34; alt=&#34;Graph: Replication Delay Monitor&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Der brandneue Replication Load Monitor ist ein tolles Spielzeug.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wir sehen eine Weiterentwicklung einer
&lt;a href=&#34;http://www.markleith.co.uk/2012/07/24/a-mysql-replication-load-average-with-performance-schema/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Idee&lt;/a&gt;


von Mark Leith:
Mit Hilfe des Performance Schema überwachen wir,
womit der SQL Thread der MySQL Replikation denn so seine Zeit verbringt
und wieviel Prozent einer jeden Zeitscheibe er idle ist.&lt;/p&gt;
&lt;p&gt;Mein SQL Thread auf der von mir zufällig herausgesuchten Maschine bringt etwa 20% seiner Zeit mit InnoDB Log IO zu
und weitere 10-20% mit InnoDB Data IO.
60% sind Idle.
Montag irgendwann nach 13 Uhr hat jemand dann in Panik &amp;lsquo;innodb_flush_log_at_trx_commit = 2&amp;rsquo; gesetzt
und damit fällt die InnoDB Log IO-Wartezeit komplett weg (Data IO natürlich nicht).&lt;/p&gt;
&lt;p&gt;Wie dem auch sei, &lt;em&gt;so&lt;/em&gt; sieht der Graph einer überlasteten Hierarchie nicht aus.
Wir haben möglicherweise ein Problem auf einigen Servern der Hierarchie,
aber definitiv nicht auf diesem.
Damit ist aber auch klar, daß das Problem nicht vom Master her kommen kann.
Gute Nachrichten!&lt;/p&gt;
&lt;p&gt;Weiteres Nachbohren ergibt eine Liste von betroffenen Servern.
Zwei von denen sind Qualitätssicherungssysteme, die haben keinen Speicher und interessieren mich nicht.
Eines ist eine potentielle Produktionskiste, die derzeit aber vor sich hin idled.
Die hat Speicher und ist trotzdem langsam.&lt;/p&gt;
&lt;p&gt;Seit wann?&lt;br&gt;
Ich schnappe mir den Replication Delay Graph und zoome einmal raus.
Das Problem besteht seit dem 20-Sep nachmittags, sagt der Graph.&lt;/p&gt;
&lt;p&gt;Also zoome ich mich durch alle Graphen dieser Kiste für den 20-Sep und schaue einmal was mir da noch entgegen kommt.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay2.png&#34; alt=&#34;Graph: Betroffener Rechner&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Krankheitsbild: Akute und lebensbedrohliche DML-Schwäche seit Mitte des 20-Sep.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Es ist offensichtlich, daß der Eimer ein Problem hat:
Irgendwann am 20-Sep Nachmittags ist der von 150/250/50 I/U/D auf infinitesimal kleine Werte runter,
und zwar nicht ruckartig wie bei einer Konfigurationsänderung, sondern in einer Entladungskurve,
als ob sich irgendetwas zu zieht.
Irgendwann am 21-Sep ist es der kranken Box dann noch mal ruckartig besser gegangen
und wieder zieht sie sich dann bis zum Stillstand zu.&lt;/p&gt;
&lt;p&gt;Das ist doch schon mal ein guter Hinweis:
Erstens suchen wir fast sicher nicht nach einem direkten Config Change
und zweitens sehen wir an dem Spike dahinter, daß Recovery möglich ist.&lt;/p&gt;
&lt;p&gt;Wir suchen nicht nach einem direkten Config Change, und das ist gut so,
denn es hat in letzter Zeit auch keine solchen gegeben:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;master&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;01&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dba&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;report_date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v_global_variables&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v_global_variables&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;on&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;and&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_variable&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_variable&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;and&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;report_date&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;interval&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;day&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;report_date&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;like&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;and&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;like&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;and&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;and&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;old&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;report_date&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;now&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;interval&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;month&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------+----------------------------+--------------+--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;report_date&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_variable&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config_value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------+----------------------------+--------------+--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2012&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;04&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;thread_cache_size&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2012&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;05&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;innodb_max_dirty_pages_pct&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;           &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;75&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;           &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-------------+----------------------------+--------------+--------------+
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;rows&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;82&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Wir archivieren alle Configuration Variables von MySQL von allen Instanzen in regelmäßigen Abständen in…
einer Datenbank!
Damit kann man sinnvolle Fragen stellen.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Weiteres Wühlen im Graphite bringt Erleuchtung, denn wir finden das Inverse des Activity Patterns hier:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay3.png&#34; alt=&#34;Graph: InnoDB Undo-Log Length&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Wir wissen aus früheren Incidents schon, daß ein großes Undo-Log MySQL langsam macht.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Die Causa:
Der InnoDB Purge Thread hat seine Arbeit Mitte des 20-Sep eingestellt,
zuckt noch einmal kurz und idled dann lustig weiter.
Sollte
&lt;a href=&#34;https://blog.koehntopp.info/2011/04/28/mysql-undo-log.html&#34;&gt;Captain Undo-Log&lt;/a&gt;


wieder unterwegs sein und mit dem Baseballschläger ausgeloggt werden wollen?&lt;/p&gt;
&lt;p&gt;Eine kurze Inspektion der Prozeßliste zeigt nur zwei andere Kandidatenprozesse,
einer ist ein root-User und einer ist ein cacti-Login.
Mein Geld wette ich auf den root-user,
ein kurzes Rumfragen auf dem Jabber und danach ein KILL auf die Connection-ID von dem Gesellen wird mir zeigen,
ob ich Recht habe oder nicht:
Wer nicht im Live-Channel auf dem Jabber ist wird sich schon melden, wenn ihm die Verbindungen wegfliegen.&lt;/p&gt;
&lt;p&gt;Der Effekt ist…  Null.&lt;/p&gt;
&lt;p&gt;Also gut.&lt;br&gt;
Dann kriegt halt der Cacti auf&amp;rsquo;s Maul, weil ich grad schlechte Laune habe.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay4.png&#34; alt=&#34;Graph: QPS &amp;amp; Undo-Log Size&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Nach Zufuhr einer passenden Dosis Laxativ (DBA KILL forte N) spontane Erholung,
aber nach kurzer Linderung ein Wiedereinsetzen der Symptomatik.&lt;/p&gt;
&lt;p&gt;Herzallerliebst.&lt;br&gt;
Wir haben das Gegenteil eines Stehaufmännchens - ein Fallumchen.
Immer wenn der Cacti User eine Kelle kriegt, fällt das Undo-Log wunschgemäß in sich zusammen
und die Performance geht rauf.
Danach zieht es sich in kürzester Zeit wieder zu und wir fallen auf das alte Niveau runter.&lt;/p&gt;
&lt;p&gt;Der alte Trick mit der Processlist klappt auch hier wieder:
Das Login kommt von&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;| 6694419 | cacti | &amp;lt;hostname&amp;gt;:44467 | performance_schema | 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Moment.
performance_schema?
Cacti?&lt;/p&gt;
&lt;p&gt;Nein.
Das ist nicht cacti.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; lsof -i -n -P &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep &lt;span class=&#34;m&#34;&gt;44467&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt; mysqld 17242 mysql 178u # IPv6 3599986352 TCP ...:3306-&amp;gt;...:44467 (ESTABLISHED)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;diamond 18596 root    1u   IPv4 3599986351 TCP ...:44467-&amp;gt;...:3306 (ESTABLISHED) 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ja.  Das ist diamond, der Datenkollektor für Graphite.&lt;/p&gt;
&lt;p&gt;Und welches Modul von Diamond/Graphite ist am 20-Sep nachmittags global ausgerollt worden?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; /etc/graphite/collectors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt; ls -l MySQL*conf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;…
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-r-------- 1 root root 471 Sep 20 14:19 MySQLPerfCollector.conf 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Der Replication Load Monitor.
Ja, der da ganz oben im ersten Bild.&lt;/p&gt;
&lt;p&gt;Der liest zwar nur, aber aus irgendeinem Grund macht er das auf einigen Promille aller Boxen,
und nur in dieser Replikationshierarchie,
in einer REPEATABLE READ read-only Transaction.&lt;/p&gt;
&lt;p&gt;Und die macht Diamond beim Login einmal auf und hält sie dann für immer und ewig,
es sei denn, die Diamond-MySQL-Verbindung kippt um,
aus welchen Gründen auch immer.
Und da die Verbindung auch nie Idle ist, timed sie auch nie aus.&lt;/p&gt;
&lt;p&gt;Kurze Zeit nachdem Puppet dem Diamond die &lt;code&gt;MySQLPerfCollector.conf&lt;/code&gt; auf &lt;code&gt;enabled = false&lt;/code&gt; gesetzt hat
haben wir eine dauerhafte Recovery:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay5.png&#34; alt=&#34;Graph: Replication Delay&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Natürliche Recovery nach Beseitigung der Ursache, ganz ohne KILL.&lt;/p&gt;
&lt;p&gt;Wir lernen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Monitoring kann Performance-Effekte haben.  Okay,
&lt;a href=&#34;http://blog.wl0.org/2012/09/checking-procnuma_maps-can-be-dangerous-for-mysql-client-connections/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keine neue Erkenntnis&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;So ein Undo-Log und langlaufende Transaktionen können einen ganz schön runter ziehen.&lt;br&gt;
Okay, auch keine neue Erkenntnis.&lt;/li&gt;
&lt;li&gt;Es lag nicht an der Replikationslast, und auch nicht am Filer, auch wenn das gerade Mode ist,
in diese Richtung zu blamen.&lt;/li&gt;
&lt;li&gt;Und Graphite ist meine Hündin.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/replication-delay6.jpg&#34; alt=&#34;House: Everybody lies&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Was House sagt.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Morgen schauen wir dem &lt;code&gt;MySQLPerfCollector.py&lt;/code&gt; mal tiefer in die Eingeweide.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Load, Load Testing und Benchmarks</title>
      <link>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</link>
      <pubDate>Tue, 28 Aug 2012 10:01:00 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2012/08/28/load-load-testing-und-benchmarks.html</guid>
      <description>&lt;p&gt;(Diesen Artikel gibt es auch in &lt;a href=&#34;https://blog.koehntopp.info/2017/02/16/load-load-testing-and-benchmarking.html&#34;&gt;englischer Sprache&lt;/a&gt;

.)&lt;/p&gt;
&lt;p&gt;So. Du willst also wissen, was genau die Leistungsgrenzen Deines Systems
sind.  Und dazu möchtest Du einen Lasttest fahren, um Ergebnisse zu
ermitteln.&lt;/p&gt;
&lt;p&gt;Die Grundidee Deines Plans sieht so aus:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark_plana.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Du nimmt Deine Kiste und findest eine Methode, um Last zu generieren.  Dann
wirst Du schon merken, wie weit das geht und wann die Kiste ausgelastet ist.&lt;/p&gt;
&lt;p&gt;Der erste Fehler: Den Lastgenerator auf der zu testenden Kiste laufen
lassen.  Das geht nicht.  Unser Ziel ist es ja, die Kiste bis an ihre
Lastgrenze zu bringen.  Genau genommen wollen wir sie sogar darüber hinaus
drücken, und das geht nur genau dann, wenn wir mehr Last erzeugen können,
als die zu testende Kiste abarbeiten kann.&lt;/p&gt;
&lt;p&gt;Teilen sich der Lastgenerator und die zu testende Anwendung irgendwelche
kritischen Ressourcen, gelingt das nicht: Die Ressource, etwa CPU, wird
knapp und verlangsamt nicht nur die zu testende Anwendung, sondern auch den
Lastgenerator, bis sich das System an einem unbekannten Punkt unterhalb der
Überlast einschwingt.  Auf diese Weise werden wir niemals lernen, welche
Farbe der Rauch hat, wenn es zu Explosion kommt, d.h.  wie genau das
Systemverhalten an der Lastgrenze aussieht.&lt;/p&gt;
&lt;p&gt;Wir trennen also die Lastquelle und das zu testende System.&lt;/p&gt;
&lt;p&gt;Der zweite Fehler: Das getestete System oder die Last sind nicht nahe genug
an der realen Last.  Typische Fehler sind: Eine zu testende Datenbank hat
weniger RAM als das Produktivsystem, es wird mit einem kleineren
Datenbestand getestet als das Produktivsystem hat, oder die Formulierung der
Queries oder die relative Verteilung der Anfragen auf den Daten ist nicht
identisch mit den Verhältnissen im Produktivsystem.&lt;/p&gt;
&lt;p&gt;In allen diesen Fällen wird man von einem Lasttest etwas lernen, aber es
wird nicht unbedingt sinnvoll auf das Produktivsystem übertragbar sein.&lt;/p&gt;
&lt;p&gt;Ein klassisches Beispiel ist etwa der
&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;http://www.heise.de/ct/artikel/Gute-Nachbarschaft-290110.html&#34; alt=&#34;Datenbank-Contest&#34;  /&gt;
&lt;/p&gt;


der c&amp;rsquo;t von Mitte/Ende 2005 gewesen (Die Auflösung ist
&lt;a href=&#34;https://www.heise.de/artikel-archiv/ct/2006/13/190&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;leider kostenpflichtig&lt;/a&gt;

.
In diesem Benchmark wird die Datenbankstruktur eines CD-Verleih/Verkaufs
simuliert, jedoch werden in der Lastgenerierung des Benchmarks alle Titel
gleichverteilt nachgefragt.  Es gibt also keine Bestseller und keine
Lastkurve mit der Form eines &amp;rsquo;long tail&amp;rsquo;, wie sie in einem echten
Ladengeschäft aufträte.  Daher ist es für den Gewinn des Benchmarks wichtig,
alle Caches zu deaktivieren, während das Vorhandensein dieser Caches für den
Betrieb mit echter Last essentiell gewesen wäre.&lt;/p&gt;
&lt;p&gt;Je näher man mit seiner Lastgenerierung, dem Testsystem und dem Testbestand
an das Echtsystem herankommt, um so besser ist sichergestellt, daß man
Ergebnisse erzielt, die in der realen Welt auch Bestand haben.&lt;/p&gt;
&lt;p&gt;Am Besten wäre also, man testete auf dem Produktivsystem und mit echten
Usern.  Damit man das aber sicher tun kann, muß man erst einmal wissen, was
genau man hier tut.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark1.png&#34; alt=&#34;Load over Time&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Wenn wir in ein System Last einwerfen, dann geht die Last im Mittel nach
oben, aber sie ist nicht konstant, sondern schwankt je nachdem, welche
Aktivitäten im System wir gerade aufrufen oder wie der Mix an gerade im
System beantworteten Anfragen biased ist: Nicht alle Operationen in unserem
System sind gleich teuer.&lt;/p&gt;
&lt;p&gt;Wir fahren das System also nicht &lt;em&gt;an&lt;/em&gt; die Lastgrenze, sondern wir schieben
eine fluktuiierende und oszillierende Systemlast immer weiter nach oben, bis
ihre Spitzen weiter und weiter über die &amp;lsquo;100%&amp;rsquo;-Marke hinausreichen.  Das
sieht so aus:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark3.png&#34; alt=&#34;Load and Overload&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Wann immer das System über die 100%-Marke gepusht wird, baut es ein Backlog
auf: Es bekommt mehr Last hereingedrückt als es abarbeiten kann und Anfragen
beginnen, sich auf der Eingangsseite zu stapeln.  Indem wir eine variable
Load immer weiter erhöhen, befindet sich das System in immer längeren Phasen
des Backlog-Aufbaus und in immer kürzeren Phasen, in denen es Backlog
abarbeiten kann.  Da die Last aber je nach Art der Generierung zufällig
schwankt, ist es sehr schwierig, die Überlastung des Systems kontrolliert
durchzuführen, wenn die Kosten für einen einzelnen Request sehr variabel
sind.&lt;/p&gt;
&lt;p&gt;Das ist einer der Gründe, warum man sich bei der Optimierung von Systemen
nicht so sehr um die Verbesserung der guten oder auch nur der
durchschnittlichen Fälle kümmert.  Stattdessen wird man sich zunächst einmal
um die Outlier und schlimmsten Fällen kümmern müssen.  Das ist auch, warum
gute Systemarchitekten sich im Grunde nur für die Worst-Case-Performance
eines Systems oder eines Changes interessieren (siehe
&lt;a href=&#34;https://blog.koehntopp.info/2008/05/30/the-importance-of-fail.html&#34;&gt;The Importance of FAIL&lt;/a&gt;

,
oder jede 2.  Diskussion auf der Linux Kernel Mailingliste).&lt;/p&gt;
&lt;p&gt;Es geht zunächst einmal also darum, die Variabilität in der Antwort des
Systems zu verkleinern, bevor man daran gehen kann, sein Verhalten als
Ganzes zu verbessern.&lt;/p&gt;
&lt;p&gt;Was genau geschieht wird noch besser deutlich, wenn wir die Graphen von dort
oben nicht als Last-über-Zeit zeichnen, sondern einmal als &amp;lsquo;Last, die wir
ins System drücken&amp;rsquo; (offered load) gegen &amp;lsquo;Durchsatz&amp;rsquo; (reponses), und
zugleich auch als &amp;lsquo;Last, die wir ins System drücken&amp;rsquo; (offered load) gegen
&amp;lsquo;Antwortzeit&amp;rsquo; (latency).&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark2.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Wenn wir ein System unter Last hoch fahren, dann wird für jeden Request, den
wir in das System schicken, eine Antwort generiert.  Die Kurve zwischen
offered load und response geht also als 45-Grad Gerade nach oben, bis wir
den Sättigungspunkt erreichen.  Dort wird sie dann bei einem ideal
konfigurierten System als horizontale Gerade weiter laufen: Wir drücken zwar
mehr Load in das System hinein, bekommen aber nicht mehr Antworten heraus,
weil das System nicht schneller kann.&lt;/p&gt;
&lt;p&gt;Die Frage ist: Was passiert mit diesen zusätzlichen Anfragen.  Die Antwort
gibt der zweite Graph.  Wir drücken Anfragen in das System hinein, und diese
haben eine bestimmte Basis-Bearbeitungszeit - die think time.  Die think
time geht unter Last nicht viel nach oben, wenn unser System gut konstruiert
ist.  Sobald wir jedoch den Sättigungspunkt erreichen, stapeln sich die
Anfragen in der Eingangswarteschlange unseres Systems, da das System nicht
ausreichend Kapazität bereitstellen kann, um die Masse der Requests zu
beantworten.  Auf die think time müssen wir noch Wartezeit - wait time -
oben drauf rechnen.  Und da wir laufend und dauerhaft mehr Last in das
System schicken als es abarbeiten kann, explodiert diese Warteschlange und
damit auch die Menge an wait time, die ein Request auf sich nehmen muß.&lt;/p&gt;
&lt;p&gt;Das ist keine Theorie, sondern real einsetzbar: Man kann kontrolliert
realistische Lasttests an Produktivsystemen durchführen, wenn einige
Voraussetzungen gegeben sind.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark5.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Vorraussetzung ist eine Mindestgröße des zu testenden Systems, sodaß eine
stabile externe Last anliegt.  Will sagen, man muß zunächst einmal
ausreichend User haben, damit man das System überhaupt unter Last setzen
kann und bei denen die durch einen einzigen User generierte Last nicht
nennenswert ins Gewicht fällt.  In solchen Fällen hat man dann auch ein
Frontend mit mehr als einem Webserver und einem Load Balancer vorne dran.&lt;/p&gt;
&lt;p&gt;Der Lasttest muß zu einer Zeit mittlerer Last stattfinden: In der ruhigsten
Phase des Tages ist die verfügbare Gesamtlast oft nicht ausreichend, um
Überlast zu erzeugen und in der heißesten Phase des Tages will man
wahrscheinlich nicht testen.  Wo ich arbeite ist die Lastkurve so, daß
vormittags eine gute Zeit zum Testen ist.  Außerhalb der Haupt- und
Nebensaison ist es so, daß wir unter Umständen Kapazität ganz abschalten
müssen, um ausreichend Gesamtlast zu haben, die wir konzentrieren können, um
Überlast zu haben.&lt;/p&gt;
&lt;p&gt;Der Lasttest beginnt nun damit, daß wir die Base Load der zu testenden
Systeme aufnehmen und daß wir einen Apache Siege in das System legen, um
Base Latency zu messen: Dies ist die think time eines nicht überlasteten
Systems.&lt;/p&gt;
&lt;p&gt;Jetzt kann man am Load Balancer spielen und die Gewichte des zu testenden
Systems (eine einzelne Frontend-Maschine oder eine Clusterzelle) langsam
hochdrehen, um mehr Last zu erzeugen.  Sobald entweder Fehler im Error Log
auftauchen oder die Latenz des Siege steil nach oben geht, hat man Sättigung
erreicht.  Jetzt muß man die Last leicht unter dem Sättigungspunkt
stabilisieren und halten (wir drehen das Gewicht am LB gerade so weit
runter, daß auch die Spitzen unserer Last aus dem Überlastbereich heraus
gehalten werden) und kann dann in sehr, sehr kleinen Schritten das System
gezielt überlasten.&lt;/p&gt;
&lt;p&gt;Auf dem getesteten System kann das dann so aussehen:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark-load-test-time.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Man erkennt deutlich drei Testdurchläufe mit unterschiedlichen
Konfigurationen, und eine fiese Lastspitze eines Cronscriptes, die da im 3.
Lasttest plötzlich reinspiked und auf den Monitoren der Überwacher die
Alarme kurz aufblitzen läßt - ein typischer Outlier, der
behandlungsbedürftig ist.&lt;/p&gt;
&lt;p&gt;Man sieht auch, daß der 2.  Lasttest längere Zeit sehr vorsichtig gefahren
ist, jedenfalls aus der Sicht der Datenbank.  Das Ergebnis war am Ende, daß
die Limitierung dieses Mal nicht in der Datenbank, sondern in der CPU der
Frontend-Systeme liegt.&lt;/p&gt;
&lt;p&gt;Die Messungen der Last kann man dann noch als offered-load vs.  latency
aufzeichnen, und bekommt dann Graphen, die so aussehen können:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/benchmark-load-test-comparison.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Der Graph zeigt den Vergleich zweier unterschiedlicher Konfigurationen und
man erkennt, daß die Ergebnisse in der realen Welt ziemlich genau so
aussehen wie oben in der Theorie diskutiert.  Eine Variante dieses Graphen
macht die einzelnen Symbole um so größer, je mehr Fehler an diesem Meßpunkt
aufgetreten sind.  Auf diese Weise ist dann auch die Art und Weise des
Systemversagens und der Punkt der letzten Stabilität gut erkennbar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nachtrag:&lt;/strong&gt; Alexander Aulbach fragte in der Diskussion zum Artikel oben:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Es wäre mal interessant zu schauen, welchem physikalischen Modell das am
ehesten gehorcht.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Guckst Du hier:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Raj Jain, &lt;a href=&#34;http://www.amazon.de/The-Computer-Systems-Performance-Analysis/dp/0471503363&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and   Modeling&lt;/a&gt;

, Wiley and Sons, 1992&lt;/li&gt;
&lt;li&gt;Neil J Gunter, &lt;a href=&#34;http://www.amazon.de/Analyzing-Computer-System-Performance-ebook/dp/B001FB6DP4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Analyzing Computer System Performance with Perl::PDQ&lt;/a&gt;

, (Springer, Kindle Edition)&lt;/li&gt;
&lt;li&gt;Neil J Gunter, &lt;a href=&#34;https://www.amazon.de/Guerrilla-Capacity-Planning-Tactical-Applications/dp/3540261389&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Capacity Planning: A Tactical Approach to Planning for Highly Scalable Applications and Services&lt;/a&gt;

 (Springer, 2006)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Viele der Modellierungsansätze werden aber durch Testing in Production und
das beschriebene Lasttestverfahren obsolet.  Die Modellierung kann dennoch
sinnvoll sein, um obskure Bottlenecks oder absolute Kapazitätsgrenzen besser
sichtbar zu machen.  In meiner Praxis habe ich sie bisher jedoch nie
gebraucht, außer um Offensichtliches aus der Messung im Modell zu
bestätigen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
