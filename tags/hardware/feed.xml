<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hardware on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/hardware.html</link>
    <description>Recent content in Hardware on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>kris-blog@koehntopp.de (Kristian Köhntopp)</managingEditor>

    
    <webMaster>kris-blog@koehntopp.de (Kristian Köhntopp)</webMaster>

    
    <lastBuildDate>Tue, 22 Jul 2025 14:27:55 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/hardware/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>d = a*b&#43;c at scale</title>
      <link>https://blog.koehntopp.info/2017/11/25/d-abc-at-scale.html</link>
      <pubDate>Sat, 25 Nov 2017 20:44:52 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2017/11/25/d-abc-at-scale.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/11/dabc.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://haifux.org/lectures/267/Introduction-to-GPUs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to GPUs&lt;/a&gt;

 (PDF)&lt;/p&gt;
&lt;p&gt;So you already know how your CPU works, basically, and want to understand
what your GPU does differently. Ofer Rosenberg has you covered:
&lt;a href=&#34;http://haifux.org/lectures/267/Introduction-to-GPUs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to GPUs&lt;/a&gt;

 does what it
says on the tin.&lt;/p&gt;
&lt;p&gt;The NVIDIA take on this can be found in &lt;a href=&#34;http://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Introduction to Modern GPU
Architecture&lt;/a&gt;


by Ashu Rege, but because this is from 2008, it&amp;rsquo;s showing it&amp;rsquo;s age. The
first 15 slides or so focus more on the gaming aspect and less on the
technology, but are full of matching screenshots.&lt;/p&gt;
&lt;p&gt;The following slides then show how GPU evolved from specialised graphics
processing units to a general parallel instruction execution architecture -
what you get is basically a single chip supercomputer. Starting at slide 60
we go into Aliasing and sub-pixel addressing. Only the final three slides
mention CUDA.&lt;/p&gt;
&lt;p&gt;Kayvon Fatahalian again takes us on a tour through history, from 1993
onwards to 2011, in
&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15462-f11/www/lec_slides/lec19.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How a GPU works&lt;/a&gt;

.
The key innovation, &amp;ldquo;unified shaders&amp;rdquo;, seems to be from 2006. The slideset
seems to have considerable overlap with the Ofer Rosenberg set.&lt;/p&gt;
&lt;p&gt;Andy Glew explains the ideas and possible optimisations inside the typical
GPU architectures in a large slideset at
&lt;a href=&#34;https://parlab.eecs.berkeley.edu/sites/all/parlab/files/20090827-glew-vector.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Coherent Threading: Microarchitectures between SIMD and MIMD&lt;/a&gt;

.
One point he makes is that there is a spectrum between classical multicore
CPUs (MIMD) and classical vector CPUs (SIMD), and that seems to be the space
that GPUs occupy. He lists that as SIMT (Single Instruction, Multiple
Threads), and then at length explains how this enables optimisations that
keep all cores (hundreds) busy by switching between even more threads (tens
of thousands) in hardware.&lt;/p&gt;
&lt;p&gt;So what does all of this give you? Well, here is an overview of the
evolution of graphics 2000-2015, as seen by NVIDIA.
&lt;a href=&#34;https://www.youtube.com/watch?v=6QJvAiCHXqc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Now, all of this is even relevant if you do not want to blow up pixels,
because the very same operations are being executed at scale for
&lt;a href=&#34;https://www.youtube.com/watch?v=df2_72wjEdw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;routing packets&lt;/a&gt;

 or running classifiers
in neural networks. Google does this at
&lt;a href=&#34;https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scale with custom hardware&lt;/a&gt;


that is not quite GPU.&lt;/p&gt;
&lt;p&gt;A remarkable takeaway is that they are using 8-bit integers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A TPU contains 65,536 8-bit integer multipliers. The popular GPUs used
widely on the cloud environment contains a few thousands of 32-bit
floating-point multipliers. As long as you can meet the accuracy
requirements of your application with 8-bits, that can be up to 25X or
more multipliers.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Their design is basically a monster 8-bit matrix multiplier with neural
network specific postprocessing.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/11/tpu-15.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

]&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Google Tensorflow Processor&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;The Postprocessing is a non-linear function, or as they state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Neural network models consist of matrix multiplies of various sizes -
that’s what forms a fully connected layer, or in a CNN, it tends to be
smaller matrix multiplies. This architecture is about doing those things -
when you’ve accumulated all the partial sums and are outputting from
the accumulators, everything goes through this activation pipeline. The
nonlinearity is what makes it a neural network even if it’s mostly
linear algebra.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The large matrix multiplier is implemented as a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Systolic_array&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Systolic Array&lt;/a&gt;

, which makes it even
less general, more specialised than the SIMT units of a GPU -  a Single
Function, Multiple Data, Merged Results processor or a Domain Specific
Processor. That is, this part of the operation of the TPU is not
programmable, but hardwired in silicon - producing 65536 8-bit matrix
multiplication/addition results every cycle at very low power cost.&lt;/p&gt;
&lt;p&gt;Google claims to be 83x more power efficient than a CPU and 29x more power
efficient than a GPU. A more in-depth look at the TPU is available from the
&lt;a href=&#34;https://arxiv.org/abs/1704.04760&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;April 2017 TPU Paper&lt;/a&gt;

 and a
&lt;a href=&#34;https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matching article&lt;/a&gt;


on The Next Platform. The Google article is remarkable, because it
demonstrates how the Google custom hardware wipes the floor even with
contemporary GPU-based architectures, in terms of performance and even more
so in terms of performance/Watt.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nextplatform.com/2017/04/12/googles-tpu-investment-make-sense-going-forward/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA reacted to these chips&lt;/a&gt;


by enabling lower precision math (= less memory needed) and by producing
GPUs better usable for machine learning, both training and inference (using
the trained models as classifiers for data). So we see 16-bit float and
8-bit integers being used in NVIDIAs Pascal chips for this. NVIDIA claims to
be able to catch up to Google TPU performance with this generation of
hardware, but at more power consumption.&lt;/p&gt;
&lt;p&gt;Google &lt;a href=&#34;https://blog.google/topics/google-cloud/google-cloud-offer-tpus-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kind of counters&lt;/a&gt;


with a &lt;a href=&#34;https://www.nextplatform.com/2017/05/22/hood-googles-tpu2-machine-learning-clusters/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2nd generation TPU&lt;/a&gt;

.
We also see that hardware development innovation cycles in this area are
currently much faster than the deprecation time for said hardware (see also
the changes in the Knights-anything lineup from Intel), so this is a
classical rent-don&amp;rsquo;t-buy situation for the aspiring cloud user who also
happens to have their own data center.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Was ist eigentlich Firewire DMA?</title>
      <link>https://blog.koehntopp.info/2011/07/27/was-ist-eigentlich-firewire-dma.html</link>
      <pubDate>Wed, 27 Jul 2011 15:32:03 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2011/07/27/was-ist-eigentlich-firewire-dma.html</guid>
      <description>&lt;p&gt;Der Spiegel entdeckt:
&lt;a href=&#34;http://www.spiegel.de/netzwelt/gadgets/0,1518,776971,00.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Verräterische Firewire-Verbindung: Kauf-Software knackt Mac-Passwörter&lt;/a&gt;

.
In dem Artikel geht es um die Entdeckung, daß Firewire ein Busprotokoll ist,
das DMA erlaubt.&lt;/p&gt;
&lt;p&gt;DMA ist ein Kürzel, das für
&lt;a href=&#34;http://en.wikipedia.org/wiki/Direct_memory_access&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Direct Memory Access&lt;/a&gt;


steht. Normalerweise ist Computerperipherie über die CPU an den Rechner
angebunden: Wenn eine Eingabe oder eine Ausgabe zu machen ist, dann
schaufelt einer der Kerne des Rechners ein Byte aus einem speziellen
I/O-Register oder einer magischen Speicheradresse, die statt mit einem
RAM-Baustein mit einem I/O-Baustein verbunden ist, in die CPU und von der
CPU dann an die Zieladresse - die wiederum entweder eine normale
Speicheradresse oder wiederum eine magische Ein-/Ausgabeleitung ist.&lt;/p&gt;
&lt;p&gt;Moderne CPUs haben eine Einbaukomponente, die
&lt;a href=&#34;http://en.wikipedia.org/wiki/Memory_Management_Unit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Memory Management Unit&lt;/a&gt;

.
Das war früher mal ein extra Baustein, ist aber vor 20 Jahren oder so mit in
die CPU integriert worden. Die MMU hat die Aufgabe, die Speicher- und
I/O-Zugriffe eines jeden Prozesses zu kontrollieren und zu verhindern, daß
ein Benutzerprozeß auf privilegierten Speicher zugreift oder auf Speicher
anderer Prozesse. Die MMU implementiert also die Sicherheit in modernen
Betriebssystemen.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/io-mit-cpu.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Jeder Speicher- und I/O-Zugriff wird von der MMU überwacht.&lt;/p&gt;
&lt;p&gt;Wie man sich aus der Beschreibung von DMA leicht überlegen kann, umgeht DMA
die MMU komplett: Das I/O-Gerät wird nicht von der CPU abgefragt, sondern es
meldet sich auf denselben Adreßleitungen (dem &amp;ldquo;Bus&amp;rdquo;), auf dem auch die CPU
liegt an und greift dann selber wie eine zweite CPU auf diesen Bus und alle
darauf liegenden Geräte zu - also auch auf allen Speicher. Da es selber wie
eine CPU agiert, umgeht es die eigentliche CPU des Systems und damit auch
die darin liegende MMU.&lt;/p&gt;
&lt;p&gt;Firewire ist ein Bus, der DMA-Geräte erlaubt. Darum ist er lange Zeit
schneller als USB gewesen und Firewire-Geräte haben außerdem das System
weniger ausgebremst als USB-Geräte: Die Firewire-Devices mußten sich halt
nicht von der CPU byteweise die Daten füttern lassen, sondern haben
stattdessen parallel zur CPU ihre Daten ins System gebulldozert.&lt;/p&gt;
&lt;p&gt;Wenn man also am Firewire-Port von Rechner a keine normale Festplatte
anschließt, sondern etwa einen zweiten Rechner b, dann kann dessen CPU ein
beliebiges Programm auf Rechner b ausführen, das auf beliebige Bytes von
Rechner a lesend oder schreibend zugreift.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/io-mit-dma.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;DMA ist ein Mechanismus, der anderen Geräten an CPU und MMU vorbei
Speicherzugriff erlaubt. Dadurch sind alle Speicherinhalte dem externen
Gerät ungeschützt zugänglich.&lt;/p&gt;
&lt;p&gt;Ist das überraschend? Nein.&lt;/p&gt;
&lt;p&gt;Ist das neu? Nein. Software dafür ist seit 2003 als Open Source zu bekommen.&lt;/p&gt;
&lt;p&gt;Ist die Empfehlung aus dem Spiegel-Artikel sinnvoll?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Allerdings, merkt Passware selbst an, kann man dem Passwortklau mit zwei
simplen Maßnahmen einen Riegel vorschieben. Zum einen sollte man die
Funktion &amp;ldquo;Automatische Anmeldung&amp;rdquo; im &amp;ldquo;Kontrollfeld Benutzer &amp;amp; Gruppen&amp;rdquo;
deaktivieren. Zum anderen sollte man den Computer in Pausen komplett
abschalten, statt ihn nur in den Ruhezustand zu versetzen. Dann haben auch
gut ausgerüstete Passwortdiebe keine Chance mehr.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Geht so. Zwar ist es sinnvoll, die automatische Anmeldung zu deaktivieren,
um die Systemsicherheit zu erhöhen (alternativ den Bildschirmschoner mit
einem Paßwort zu versehen) und auch den Rechner abzuschalten statt suspend
zu verwenden.&lt;/p&gt;
&lt;p&gt;Aber solange der Rechner läuft ist nicht der Klau des Paßwortes die
eigentliche Gefahr. Sondern die Tatsache, daß einem ein wildgewordenen
Firewire Device, das man anschließt, jedes beliebige Byte auslesen oder
übermalen kann. Mit Paßworten muß sich da keiner aufhalten, wenn man das
ganze System ersetzen oder verändern kann.&lt;/p&gt;
&lt;p&gt;Siehe auch &lt;a href=&#34;http://blog.fefe.de/?ts=b32cb04e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hier&lt;/a&gt;

 für andere Zugriffe mit DMA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neues Werkzeug</title>
      <link>https://blog.koehntopp.info/2008/06/11/neues-werkzeug.html</link>
      <pubDate>Wed, 11 Jun 2008 08:24:20 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2008/06/11/neues-werkzeug.html</guid>
      <description>&lt;p&gt;Neuer Job, neues Werkzeug. Diesmal ein MacBook Pro 15&amp;quot;, mit 3 GB RAM und der 200 GB 7200rpm Platte und MacOS X 10.5.3.
Ab Werk ist das System nahezu unbenutzbar.&lt;/p&gt;
&lt;p&gt;Damit das bewohnbar wird, kommen bei mir die folgenden Sachen drauf:&lt;/p&gt;
&lt;p&gt;Für die Shell:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sshkeychain.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SSHKeyChain für iTerm&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://iterm.sf.net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;iTerm Terminal Client&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cyberduck.ch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cyberduck sftp/ssh client&lt;/a&gt;

 (Fish ist ja so viel besser, aber ein Mac kann das noch nicht)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://rudix.sf.net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rudix&lt;/a&gt;

, damit die Kommandozeile nicht so stinkt.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Für die Arbeit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mysql.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ein aktuelles MySQL&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.neooffice.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeoOffice&lt;/a&gt;

, das StarOffice für den Mac&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://caminobrowser.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Camino&lt;/a&gt;

, ein Firefox für den Mac&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Für die Kommunikation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://skype.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Skype&lt;/a&gt;

, funktioniert ganz ausgezeichnet ohne Headset und mit der eingebauten Kamera, ich bin beeindruckt.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.adiumx.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adium&lt;/a&gt;

, kann alles außer Skype&lt;/li&gt;
&lt;li&gt;Colloquy IRC Client, aber ich nehme weiter mein irssi im Screen auf dem Dedi, glaube ich.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.barebones.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Text Wrangler&lt;/a&gt;

, der Editor der Wahl für uns Nicht-Emacs-Benutzer&lt;/li&gt;
&lt;li&gt;NetNewsWire Feed Reader, jedenfalls solange Akregator noch nicht geht&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Von Till:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eine KDE 4 Beta mit kmail und dem Rest von Kontact auf Native-Qt-KDE ohne X11. Das ist leider noch ein wenig broken und schlecht integriert. Ich will mein Amarok!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Zum Gucken:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://perian.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Perian&lt;/a&gt;

, die Codec-Sammlung für Quicktime, damit es nicht mehr saugt.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.videolan.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VLC&lt;/a&gt;

 für den Mac ist echt gut&lt;/li&gt;
&lt;li&gt;MPlayer OS X, eher nicht so stabil&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://handbrake.fr/?article=download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Handbrake&lt;/a&gt;

, weil niemand so viele DVDs mit sich herumschleppen will, und man das Zeugs ja auch mal auf dem iPod haben will&lt;/li&gt;
&lt;li&gt;Transmission, als Bittorrent Client der Wahl&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Weiteres Zeugs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.tunnelblick.net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tunnelblick VPN Controller&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.growl.info&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Growl&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://journler.com/download/index.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journler&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;Nokia E90 iSync Conduit, von Nokia&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Jetzt fehlt noch ein sinnvoller Windowmanager, der Focus-Follow-Mouse richtig kann, und der die Fenster nach Dokumenten und nicht nach Anwendungen gruppiert.
So geht das jedenfalls gar nicht.
Oh, und ein Tastatur-Layout-Editor, denn die Belegung von dem Ding hier ab Werk ist mal so richtig kaputt.
In Englisch und in Deutsch.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Es war einmal...</title>
      <link>https://blog.koehntopp.info/2008/02/13/es-war-einmal.html</link>
      <pubDate>Wed, 13 Feb 2008 11:42:29 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2008/02/13/es-war-einmal.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Es war einmal &lt;a href=&#34;http://rzflaeche.de&#34;&gt;das web.de Rechenzentrum&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Weil mich ein paar Leute gefragt haben, was denn nun einmal war:
Dies ist die alte Pfaff Nähmaschinenfabrik in der Amalienbadstraße in Durlach.
Der Laden ist von web.de damals gekauft und renoviert worden.
Nach dem Verkauf des Portalgeschäftes von web.de an 1&amp;amp;1 ist die web.de AG als Combots AG umfirmiert und in den Räumen in der Amalienbadstraße mit einer Rumpfmannschaft verblieben.
Die meisten ehemaligen web.de-Mitarbeiter sind mit dem Geschäft an 1&amp;amp;1 verkauft worden.
Nachdem sich das Produkt von Combots nicht hat durchsetzen können, hat Combots nun die Entwicklung ihres Chatsystems eingestellt und die Anlage hat wohl Platz über.&lt;/p&gt;
&lt;p&gt;Daher die Domain &amp;ldquo;rzflaeche.de&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Zum Thema Renovierung hier der Porn:&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals1.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals2.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals3.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals4.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals5.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/webde-damals6.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hardware für ein MySQL</title>
      <link>https://blog.koehntopp.info/2007/07/28/hardware-f-r-ein-mysql.html</link>
      <pubDate>Sat, 28 Jul 2007 18:38:38 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2007/07/28/hardware-f-r-ein-mysql.html</guid>
      <description>&lt;p&gt;&amp;ldquo;Ich muß Hardware für einen Rechner kaufen, auf dem dediziert nur ein MySQL laufen soll. Was soll ich beschaffen?&amp;rdquo; ist eine Frage, die ich recht oft höre. Hier ist die lange Antwort.&lt;/p&gt;
&lt;p&gt;Bevor man sich mit dem freundlichen Hardwarehöker des geringsten Mißtrauens in Verbindung setzen kann, muß man sich erst einmal ein paar Dinge überlegen.&lt;/p&gt;
&lt;h2 id=&#34;datenbank-zielgröße-bestimmen&#34;&gt;
    &lt;a href=&#34;#datenbank-zielgr%c3%b6%c3%9fe-bestimmen&#34;&gt;
	Datenbank-Zielgröße bestimmen
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Die allererste Überlegung ist die erwartete Zielgröße der Datenbank: Werden wir einen Bestand von 1G, 10G, 100G oder 1000G haben? Daraus und aus dem allgemeinen Gesundheitszustand des Geldbeutels ergibt sich schon die erste wichtige Erkenntnis. Nämlich: Werden wir es schaffen, eine speichergesättigte Datenbank zu bauen, oder bekommen wir eine Datenbank, die für Lesezugriffe auf die Platte zugreift?&lt;/p&gt;
&lt;h3 id=&#34;folgerung-1-speichergesättigte-datenbanken-sind-ein-bevorzugtes-designziel&#34;&gt;
    &lt;a href=&#34;#folgerung-1-speicherges%c3%a4ttigte-datenbanken-sind-ein-bevorzugtes-designziel&#34;&gt;
	Folgerung 1: Speichergesättigte Datenbanken sind ein bevorzugtes Designziel
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Mechanische Festplatten sind unerträglich langsam.&lt;/p&gt;
&lt;p&gt;Speicher-Zugriffszeiten werden in Nanosekunden angegeben. Milli (10E-3), Mikro (10E-6), Nano (10E-9), Pico (10E-12), Femto (10E-15), Atto (10E-18) - Speicher hat also Zugriffszeiten in der Größenordnung von einer Millardstelsekunde pro Byte. Platten-Zugriffszeiten liegen dagegen im Bereich von Millisekunden, wenn Seeks involviert sind. Von einer durchschnittlichen Serverplatte kann man nicht mehr als 200 Seeks pro Sekunde (5ms pro Zugriff) erwarten, die 7200rpm Hitachi HTS72108 in meinem Laptop schafft nach iozone und iostat ziemlich genau 125 Seeks pro Sekunde (8ms pro Zugriff).&lt;/p&gt;
&lt;p&gt;In diese Zeit geht die Average Seek Time für die horizontale Positionierung des Kopfes und die Rotational Delay mit ein - also die Zeit, die wir warten müssen, bis die richtigen Daten unter dem fertig positionierten Kopf auch mal durchrutschen. Die Datentransferzeit zur tatsächlichen Übertragung der Daten ist im Vergleich dazu eher zu vernachlässigen.&lt;/p&gt;
&lt;p&gt;Andererseits hat eine Platte im Vergleich zum RAM eine größere Zugriffsgranularität - während wir beim RAM für jedes Byte eine Access Time abrechnen, tun wir das bei einer Platte für einen Block (512 Byte, aber wir können hier gerne mit 1000 Byte rechnen, es spielt nicht wirklich eine Rolle). Im Endeffekt ist der Geschwindigkeitsunterschied zwischen RAM und Random-I/O einer Festplatte jedenfalls nicht 1E6 (eine Million), sondern nur etwa 1E4 (Zehntausend) bis 1E5 (Hundertausend), abhängig davon wie breit unsere Rows im Schnitt sind.&lt;/p&gt;
&lt;p&gt;Wird eine Platte nicht mit Random-I/O betrieben, sondern mit linearer Ein-/Ausgabe, dann können wir so um die 50 MB/sec von einer Platte bekommen. Je nach Rowsize sind das zwischen Hundertausend und einer Million Rows pro Sekunde. Das ist immer noch langsamer als RAM, aber viel schneller als die im pessimalen Fall 200 Rows/sec vom Random-I/O (Hmm, auch da kommen wir noch drunter, wenn wir auch den Index nicht cachen können).&lt;/p&gt;
&lt;p&gt;Wenn es einem also gelingt, speichergesättigte Datenbanken zu bauen, dann sind Reads für viele Anwendungsfälle schon kein Problem mehr und teilweise fällt sogar schlechtes SQL nicht mal mehr auf, weil die entsprechenden Operationen zwar ineffizient sein mögen, aber dank schnellem RAM-Zugriff dennoch schnell genug sind.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-2-64-bit-sind-mandat&#34;&gt;
    &lt;a href=&#34;#folgerung-2-64-bit-sind-mandat&#34;&gt;
	Folgerung 2: 64 Bit sind Mandat
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;MySQL hat eine Ein-Prozeß-Architektur. Ein einzelner Datenbankserver enthält eine Reihe von datenbankinternen Service-Threads und einen Handlerthread pro Connection, die sich alle den gemeinsamen Speicher des Prozesses teilen.&lt;/p&gt;
&lt;p&gt;Wir brauchen also nicht nur jede Menge RAM, sondern wir brauchen das RAM auch in einer Form, die es uns erlaubt, innerhalb eines einzelnen Prozesses darauf zugreifen zu können. Das bedeutet in 2007: Eine 64 Bit CPU, ein 64 Bit Betriebssystem und eine 64 Bit Version von MySQL, falls wir Speicher von mehr als 3G (in Windows: 2G) im Server haben.&lt;/p&gt;
&lt;p&gt;32 Bit-Code kann in Linux nur etwas unter 3G in einem Prozeß adressieren, und in Windows sind es sogar nur etwas unter 2G. Es ist also vollkommen sinnlos, einen Rechner mit 8G RAM hinzustellen und dann nur ein 32 Bit-Betriebssystem und ein 32 Bit-MySQL drauf zu installieren. Das gibt zwar einen schönen File System Buffer Cache und das ist besser als nix, aber es wäre sehr viel interessanter, den Speicher direkt in MySQL zur Verfügung zu haben. Ein Datenbankserver wird also immer fett RAM bekommen und das zieht dann relativ schnell die 64 Bit nach sich.&lt;/p&gt;
&lt;p&gt;Es gibt zwar so was wie
&lt;a href=&#34;http://en.wikipedia.org/wiki/Physical_Address_Extension&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PAE&lt;/a&gt;

/
&lt;a href=&#34;http://en.wikipedia.org/wiki/Address_Windowing_Extensions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWE&lt;/a&gt;

, aber reden wir da nicht drüber - wir haben 2007, und es gibt keinen Grund, mit gefesselten Beinen über die Ziellinie zu hüpfen, wenn man stattdessen richtig rennen kann. Es gibt zwar PAE-Code in MySQL, aber der ist per Default nicht enabled, in den MySQL-eigenen Binaries nicht vorhanden und schlecht getestet. Selbst wenn das alles anders wäre, würde man PAE nicht wollen, sondern gleich richtig 64 Bit machen wollen - PAE ist langsam und hat haarige Tatzen.&lt;/p&gt;
&lt;h3 id=&#34;schreibleistung-vs-leseleistung&#34;&gt;
    &lt;a href=&#34;#schreibleistung-vs-leseleistung&#34;&gt;
	Schreibleistung vs. Leseleistung
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Eine andere Sache, die man sich frühzeitig bewußt machen muß ist die Überlegung, daß Leseleistung sehr viel leichter zu optimieren ist als Schreibleistung.&lt;/p&gt;
&lt;p&gt;Datenbanken, die überwiegend Reads sehen und wenig Schreiboperationen haben sind sehr leicht zu skalieren: Wir ersticken das Problem nach Möglichkeit erst einmal mit Speicher und wenn das nicht mehr reicht, setzen wir eine ausreichende Anzahl von Replication-Slaves auf. Die Reads verteilen wir dann gleichmäßig über die Slaves. Das können wir je nach Problemgröße leicht bis auf 1000 Slaves pro Master ausdehnen, wenn wir wollen.&lt;/p&gt;
&lt;p&gt;Writes dagegen sind sehr viel unhandlicher. Wir können Schreibzugriffe zwar Delayen, Batchen und Sortieren, aber am Ende muß der Write auf irgendein persistentes Medium. Wenn wir mehr Schreibzugriffe haben als eine Platte wegstecken kann, dann müssen wir ein Array hinstellen. Wenn wir mehr Schreibzugriffe haben als man sinnvoll über ein Array verteilen kann, dann müssen wir die Datenbank partitionieren mit all den unangenehmen Designentscheidungen, die mit solchen
&lt;a href=&#34;https://blog.koehntopp.info/2006/07/30/leben-mit-fehlern-der-schluessel-zum-scaleout.html&#34;&gt;verteilten, lose gekoppelten Systemen&lt;/a&gt;

 einher gehen.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-3-locality-erzeugen-um-schreibzugriffe-zu-minimieren&#34;&gt;
    &lt;a href=&#34;#folgerung-3-locality-erzeugen-um-schreibzugriffe-zu-minimieren&#34;&gt;
	Folgerung 3: Locality erzeugen um Schreibzugriffe zu minimieren
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Datenbanken speichern Daten in Speicherseiten ab. In InnoDB zum Beispiel ist eine solche Speicherseite mit 16K relativ groß. In einer solchen Seite liegen in der Regel mehrere Rows, und InnoDB liest und schreibt immer ganze Seiten.&lt;/p&gt;
&lt;p&gt;Wenn wir unsere Datenbank gut designed haben, dann haben wir Locality Of Reference erzeugt. Das bedeutet, daß wir ziemlich oft den Fall haben, daß die Rows, die wir zur gleichen Zeit bearbeiten auch räumlich dicht gepackt sind, also in derselben Speicherseite stehen. Das bedeutet, daß wir mit dem ersten Zugriff auf eine neue Seite schon die Rows, auf die wir gleich zugreifen werden mit in den Speicher bringen und daß wir beim Schreiben wahrscheinlich eine Seite nicht nur einmal verändern, sondern mehrere Rows in der Seite verändern werden.&lt;/p&gt;
&lt;p&gt;Wir wissen, daß InnoDB Daten im Primary Key in B+-Bäumen abspeichert, d.h. in den Blättern des Primary Key stehen die Daten selbst, nicht Zeiger auf die Daten. Daten sind also physikalisch in Primary Key-Reihenfolge angeordnet und Daten mit einem ähnlichen Primary Key stehen wahrscheinlich physikalisch dicht zusammen auf der Platte. Sekundärschlüssel enthalten eine Kopie des Primary Key als Row Pointer. Ein &amp;ldquo;INDEX(a)&amp;rdquo; wird von InnoDB also intern als &amp;ldquo;INDEX(a, id)&amp;rdquo; interpretiert und realisiert. InnoDB und der Optimizer wissen das auch, und ein &amp;ldquo;SELECT id FROM t WHERE a = &amp;hellip;&amp;rdquo; wird entsprechend aus dem Sekundärschlüssel ohne Primärdatenzugriff abgearbeitet.&lt;/p&gt;
&lt;p&gt;Mit diesem Wissen können wir jetzt über die Wahl des Primärschlüssels einer InnoDB-Tabelle die physikalische Anordnung von Daten in einer InnoDB-Tabelle beeinflussen und die Locality verbessern.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oft erzeugen hierarchische Primärschlüssel ausgezeichnete Locality. In einer Tabelle, die Mails für einen Maildienst verwaltet wäre (userid, folderid, messagenummer) zum Beispiel ein sehr guter Primärschlüssel für die Mailtabelle, weil Informationen über neue Mails im aktuellen Folder des aktuellen Users dicht beieinander gespeichert werden.&lt;/li&gt;
&lt;li&gt;Ein &lt;em&gt;INTEGER UNSIGNED NOT NULL PRIMARY KEY auto_increment&lt;/em&gt; erzeugt eine zeitliche Reihung von Daten nach dem Erzeugungsdatum und das ist für viele Daten, die neu heiß sind und dann mit der Zeit abkühlen genau der richtige Schlüssel.&lt;/li&gt;
&lt;li&gt;Ein Zufallswert, ein MD5 oder SHA1-Hash oder eine UUID ist ein furchtbarer Primärschlüssel, weil Daten im Endeffekt zufällig gestreut werden und keine Locality erzeugt werden kann.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Locality ist nicht nur für Schreibleistung wichtig, sondern auch wenn wir eine Datenbank haben, die nicht speichergesättigt sein kann und wir Lesezugriffe zur Disk senden müssen. Mit einer guten Locality können wir unter Umständen viele Lesezugriffe im RAM cachen auch wenn die Gesamtdatenbank sehr viel größer als der Verfügbare Hauptspeicher ist.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-4-beschriebene-rows-schmal-halten-um-schreibzugriffe-zu-minimieren&#34;&gt;
    &lt;a href=&#34;#folgerung-4-beschriebene-rows-schmal-halten-um-schreibzugriffe-zu-minimieren&#34;&gt;
	Folgerung 4: Beschriebene Rows schmal halten um Schreibzugriffe zu minimieren
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Schreibzugriffe ändern Seiten. Wenn wir eine gute Locality haben und wir außerdem Schreibzugriffe von beschriebenen Seiten zur Disk verzögern können, dann werden wir viele Rows in einem Block ändern können, bevor wir diesen Block zur Disk senden. Indem wir die Rows von Tabellen schmal halten, die beschrieben werden, bekommen wir mehr Rows in einen Block und haben so weniger Schreibzugriffe.&lt;/p&gt;
&lt;p&gt;Wenn wir zum Beispiel eine Benutzertabelle haben, dann enthält diese überwiegend statische Daten wie zum Beispiel den Benutzernamen, das Paßwort, die Benutzeranschrift und andere Stammdaten. Sie enthält aber vielleicht auch sehr dynamische Daten wie zum Beispiel das Datum des letzten Logins. Datenbanktheoretisch gehört diese Information auch in die User-Tabelle, aber wegen der physikalischen Implementierung wird es sehr sinnvoll sein, eine künstliche 1:1 Relation einzuführen und das Paar (userid, lastlogin) in eine Extratabelle abzuspalten.&lt;/p&gt;
&lt;p&gt;Hier haben wir nun 8 Byte breite Rows in 16K großen Records, also bis zu 2048 Records pro Speicherseite (in Wirklichkeit wird die Seite nicht vollständig genutzt sein) oder ca. 500-700 stark veränderliche Speicherseiten (8M-12M) für die Lastlogindaten von einer Million Usern. Wenn man einen Usereintrag von um die 300 Byte inklusive Stammdaten annimmt, dann würden eine Million User ohne diese Aufspaltung stattdessen um die 18000-25000 (280M-400M) veränderliche Seiten erzeugen, d.h. wir hätten etwa 36 mal mehr veränderte Speicherseiten zu schreiben, nur weil die veränderlichen Daten weniger dicht gepackt sind.&lt;/p&gt;
&lt;p&gt;Dazu kommt, daß jeder Schreibzugriff auch alle Resultsets im MySQL Query Cache löscht, die von der beschriebenen Tabelle abstammen. Indem man häufig beschriebene Daten in Extratabellen isoliert bekommt man unter Umständen eine bessere Query Cache Hit Ratio und so bessere Performance.&lt;/p&gt;
&lt;p&gt;Aus dem gleichen Grund und noch einigen anderen Gründen will man auch unbedingt alle Spalten abtrennen, in denen Typen verwendet werden, die &amp;ldquo;TEXT&amp;rdquo; oder &amp;ldquo;BLOB&amp;rdquo; im Namen haben. Zu den &amp;ldquo;anderen Gründen&amp;rdquo; gehört hier in MySQL auch die Handhabung von &amp;ldquo;temp tables&amp;rdquo; in Queryplänen, bei denen &amp;ldquo;using temporary&amp;rdquo; bei &lt;em&gt;EXPLAIN&lt;/em&gt; gelistet wird.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-5-writes-delayen-batchen-und-sortieren&#34;&gt;
    &lt;a href=&#34;#folgerung-5-writes-delayen-batchen-und-sortieren&#34;&gt;
	Folgerung 5: Writes delayen, batchen und sortieren
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Bei einem COMMIT schreibt InnoDB die geänderte 16K Seite nun nicht sofort zurück in den Tablespace, sondern notiert die Änderung erst einmal im Redo-Log und markiert die InnoDB-Seite als Dirty. Später wird die Dirty Page zur Disk gesendet und der entsprechende Redo-Log Pointer kann vorwärts bewegt werden um den Platz im Redo-Log wieder frei zu geben.&lt;/p&gt;
&lt;p&gt;Dadurch, daß alle Änderungen so erst einmal im Redo-Log landen, werden Schreibzugriffe, die eigentlich Random-Writes wären vorübergehend erst einmal als Lineare Writes abgehandelt: Wir hatten weiter oben ja schon etabliert, daß lineare Writes schneller sind. Außerdem spekuliert diese Aktion natürlich darauf, daß eine eben veränderte InnoDB Seite wegen Locality gleich noch einmal geändert wird und wir so Random I/O-Schreibzugriffe einsparen können.&lt;/p&gt;
&lt;p&gt;Wir können Locality abschätzen, indem wir die Größe des Redo-Logs mit der Menge der Pages vergleichen, die dirty sind. In &lt;em&gt;SHOW ENGINE INNODB STATUS\G&lt;/em&gt; finden wir:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;LOG
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Log sequence number 0 1994670731
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Log flushed up to   0 1994670268
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Last checkpoint at  0 1993477319
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;----------------------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;BUFFER POOL AND MEMORY
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;----------------------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Modified db pages  278
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Unser Redo-Log hat also bisher Null (0) Umdrehungen gemacht, und der Schreibzeiger steht bei Offset 1994670731, während der hintere Lesezeiger bei Offset 1993477319 steht. Es sind also 1994670731-1993477319 = 1193412 (ca. 1.1M) Redo-Log belegt. Dem stehen 278 16K große Seiten (ca. 4.4M) gegenüber, die als Dirty markiert sind. Wenn es uns gelingt, durch Umstrukturierung dieses Verhältnis zu verbessern, also die Anzahl der Seiten, die als Dirty markiert werden zu verkleinern, dann bekommen wir weniger Random-I/O und eine bessere Schreibleistung.&lt;/p&gt;
&lt;p&gt;MySQL wird die &amp;ldquo;modified db pages&amp;rdquo; dann verzögert und im Batch auf die Platte schreiben, wenn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;das Redo-Log droht, vollzulaufen&lt;/li&gt;
&lt;li&gt;&lt;em&gt;innodb_max_dirty_pages_pct&lt;/em&gt; Prozent aller Pages im Buffer Pool als Dirty markiert sind&lt;/li&gt;
&lt;li&gt;oder InnoDB eine Pause zum Atemholen bekommt und einen Checkpoint fährt.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das Schreiben der Dirty Pages erfolgt derzeit &lt;a href=&#34;http://www.mysqlperformanceblog.com/2007/07/18/how-innodb-flushes-data-to-the-disk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;leider noch nicht sortiert&lt;/a&gt;

, obwohl das echt nützlich wäre.&lt;/p&gt;
&lt;p&gt;Wir können uns, wenn uns unsere Daten nicht so wichtig sind, sogar noch die Writes ins Redo-Log delayen. Indem wir innodb_flush_log_at_trx_commit auf den Wert 2 oder gar 0 setzen, erlauben wir es der Datenbank auch Einträge ins Redo-Log zu verzögern und zu batchen und können so die Schreibleistung noch weiter erhöhen.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-6-mehr-spindeln&#34;&gt;
    &lt;a href=&#34;#folgerung-6-mehr-spindeln&#34;&gt;
	Folgerung 6: Mehr Spindeln
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Wir können so mit verschiedenen Tricks bei der Gestaltung des Datenbankschemas die Anzahl der notwendigen Schreibzugriffe unter Umständen drastisch verringern und wir können uns mit Hilfe des Redo-Log unter Umständen einige Random-I/Os sparen, indem wir stattdessen vorübergehend lineare Schreibzugriffe machen. Am Ende aber müssen die Blöcke auf die Platte.&lt;/p&gt;
&lt;p&gt;Eine einzelne Platte, so haben wir gelernt, gibt uns nicht mehr als 200 Seeks pro Sekunde. Auch ein RAID-1 Paar bekommt nicht mehr Daten auf die Platte, da ja jede Hälfte des Spiegelpaares dieselben Operationen durchführen muß. Von 14 Platten in einem RAID-10 (einem Stripe aus Mirrors) würden wir also ca. 7 mal 200 Seeks/sec = 1400 Seeks/sec erwarten.&lt;/p&gt;
&lt;p&gt;In einem RAID-5 ist es weitaus schlechter. Da Datenbanken ausschließlich RAID-5 &amp;ldquo;Short Writes&amp;rdquo; machen, wird jede einzelne logische Schreiboperation zu vier physikalischen Schreiboperationen: Zwei Reads und zwei Writes. Mit einem großen Cache kann man die beiden Reads weg cachen, aber die beiden Writes bleiben. Hat der RAID-5 Controller außerdem einen großen batteriegepufferten Cache, kann es sein, daß auch die Schreibzugriffe in akzeptabler Zeit abgewickelt werden, aber die sichere Empfehlung für eine Datenbank ist in der Regel &amp;ldquo;RAID-5 ist böse, man will RAID-10&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Für eine Datenbank wollen wir also ein Plattenarray kaufen, daß aus möglichst vielen kleinen Disks zusammen gesetzt ist - uns interessiert ausschließlich die Anzahl der Seeks pro Sekunde, die wir von dem Array bekommen können. MB/sec sind von untergeordneter Bedeutung.&lt;/p&gt;
&lt;p&gt;Die Sun Performance Blueprint &lt;a href=&#34;http://www.sun.com/blueprints/1000/layout.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wide Thin Disk Striping&lt;/a&gt;

 erklärt wie man mit Partitionen auf Arrays umgehen sollte: Sie sollten sich immer über alle vorhandenen Platten des Array erstrecken und es sollten &lt;em&gt;keine&lt;/em&gt; dedizierten Disks für Logs, Indices oder einzelne Tabellen verwendet werden. Ab 6 Platten wird diese Strategie sinnvoll, ab 10 Platten ist sie dedizierten Disks auf jeden Fall überlegen.&lt;/p&gt;
&lt;p&gt;In großen Arrays will man sich nicht mehr mit Disks abgeben, sondern &amp;ldquo;Storage managen&amp;rdquo; - Partitionen sollten daher immer über alle Disks gehen und das Array gleichmäßig aufheizen, sodaß man keine Hotspots mehr bekommt. Wenn das Array überlastet wird, kauft man dann eben einfach mehr Platten und reorganisiert. &lt;em&gt;sar -d&lt;/em&gt;, &lt;em&gt;iostat -x&lt;/em&gt; oder &lt;em&gt;dstat&lt;/em&gt; sind des Storage- und des Datenbankadmins treue Freunde. Man sollte eine gewisse Nähe zu ihnen aufbauen.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-7-software-raid-ist-nix-schlimmes&#34;&gt;
    &lt;a href=&#34;#folgerung-7-software-raid-ist-nix-schlimmes&#34;&gt;
	Folgerung 7: Software-Raid ist nix schlimmes
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Wenn wir ein RAID-10 bauen, dann ist die Realisierung des RAID sehr wenig aufwendig: Ein Write-Request wird einfach zu zwei verschiedenen Platten gesendet und endet erst dann, wenn beide Platten ihn bestätigt haben. Das ist sehr leicht in Software realisieren. Ein Hardware-RAID bringt hier nur wenig Gewinn.&lt;/p&gt;
&lt;p&gt;Bei RAID-5, wenn man durch äußere Umstände dazu gezwungen wird, sieht da schon anders aus: Die meisten Software-RAID-5 Implementierungen sind ziemlich schäbig und RAID-5 profitiert ganz enorm von einem batteriegepufferten RAM als Cache. Hier ist ein (guter, teurer) RAID-Controller mit einem fetten batteriegepufferten Cache wahrscheinlich von Vorteil.&lt;/p&gt;
&lt;p&gt;Ein Software-RAID hat gegenüber einem Hardware-RAID dann verschiedene Vorteile: Zum Beispiel braucht man sich nicht mit einem proprietären Treiber zu prügeln, kann das RAID zuverlässig über /proc/mdstat in Linux oder das entsprechende Windows-Äquivalent monitoren und kann zumindest in Linux auf die einzelnen Platte auch nach dem Splitten des Mirrors einzeln ohne RAID zugreifen, da Linuxraid die Metadaten hinten auf die Platten malt - eine RAID-Hälfte ohne RAID sieht dann zumindest read-only für einen Nicht-RAID-Zugriff ganz normal aus.&lt;/p&gt;
&lt;p&gt;Sogar &lt;a href=&#34;http://michael.fuckner.net/me/blog/index.php?/archives/367-SAS-Raid-mit-multipathing-unter-Linux.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;multipathen&lt;/a&gt;

 kann man das.&lt;/p&gt;
&lt;h3 id=&#34;cpu-leistung-verblaßt-neben-plattenleistung&#34;&gt;
    &lt;a href=&#34;#cpu-leistung-verbla%c3%9ft-neben-plattenleistung&#34;&gt;
	CPU Leistung verblaßt neben Plattenleistung
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Die oben angestellten Betrachtungen haben an keiner Stelle die Leistung der Prozessoren des Systems gewürdigt. Das ist deswegen so, weil Datenbanken in der Regel kaum CPU-Probleme haben. Eine CPU mit 3 GHz Takt arbeitet pro Sekunde und Core 3 Milliarden Prozessorzylen ab, und moderne CPUs sollten eigentlich größenordnungsmäßig bei jedem Zyklus auch einen Befehl fertigstellen. Wenn man also von Disk Seeks von einer 200stel Sekunde ausgeht, dann werden in der Wartezeit auf die Platte um die 15 Millionen Wartezyklen pro Core in der CPU freigesetzt.&lt;/p&gt;
&lt;p&gt;Oder anders gesagt: Eine Datenbank kann nur in zwei Fällen wirklich CPU-Probleme bekommen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;Wir haben etwas ganz wildes mit Stored Procedures oder anderem Code in der Datenbank gemacht. Das hätten wir besser gelassen.&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Die Datenbank ist speichergesättigt und fräst nun wie wild mit der CPU durch ihre Speicherbänke, weil sie niemals auf die Platte warten muß. Klagen über &amp;ldquo;CPU ausgelastet&amp;rdquo; sind in diesem Fall wahrscheinlich Beschwerden auf sehr hohem Niveau.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In MySQL ist es außerdem so, daß wir in der Regel eine Query in einem Thread abarbeiten und wir eine bestimmte Menge an Concurrency benötigen, um ausreichend viele CPUs sättigen zu können.&lt;/p&gt;
&lt;p&gt;Insbesondere Replikation ist derzeit strikt seriell und kann nicht nennenswert mehr als einen Thread belegen.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-8-ein-reiner-backup-slave-braucht-nur-einen-maximal-2-cores&#34;&gt;
    &lt;a href=&#34;#folgerung-8-ein-reiner-backup-slave-braucht-nur-einen-maximal-2-cores&#34;&gt;
	Folgerung 8: Ein reiner Backup-Slave braucht nur einen, maximal 2 Cores
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Da Replikation strikt seriell ist, kann ein Slave der nur repliziert und nicht auch noch Read-Queries abarbeitet oder Reports generiert niemals nennenswert mehr als einen Core busy halten. Es lohnt überhaupt nicht, hier viel Geld in Cores zu investieren. RAM oder Platten sind bessere Investitionsziele.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-9-concurrency-schätzen-und-begrenzen&#34;&gt;
    &lt;a href=&#34;#folgerung-9-concurrency-sch%c3%a4tzen-und-begrenzen&#34;&gt;
	Folgerung 9: Concurrency schätzen, und begrenzen
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;MySQL ist eine Datenbank die klar auf Commodity Hardware hin entwickelt worden ist und die durch die überall verfügbare und leicht zu konfigurierende Replikation bevorzugt horizontal zu skalieren ist. Es ist in vielen Fällen eher lohnend, einen zweiten Server aufzusetzen statt den einzigen Server weiter zu vergrößern.&lt;/p&gt;
&lt;p&gt;MySQL funktioniert derzeit recht gut mit 4 oder 8 Cores, aber 16 Cores wären schon grenzwertig und es wäre zu beweisen, daß eine 16 Core-Maschine mit MySQL tatsächlich besser funktioniert als zwei 8 Core-Maschinen. Speichergrößen von 32G und 64G können gut gehandhabt werden, aber für wesentlich größere Pools müßte nachgewiesen werden, daß keine Lockingprobleme existieren. Mit MySQL 5.0.30 und MySQL 5.0.37 wurden verschiedene Lockingprobleme für sehr große InnoDB Buffer Pools behoben, sodaß es unbedingt lohnend ist ein Upgrade durchzuführen wenn man sehr große Speichermengen hat und noch kleinere Versionen einsetzt. Aber selbst dann kann &lt;a href=&#34;http://www.mysqlperformanceblog.com/2007/07/27/more-gotchas-with-mysql-50/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;intensives Monitoring&lt;/a&gt;

 noch Locking triggern. Dieses Problem wird derzeit bearbeitet.&lt;/p&gt;
&lt;h3 id=&#34;recovery-gleich-mit-planen&#34;&gt;
    &lt;a href=&#34;#recovery-gleich-mit-planen&#34;&gt;
	Recovery gleich mit planen
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Im Falle einer Katastrophe oder eines Administrationsfehlers wird der eigene Chef rüberkommen und die üblichen drei Fragen haben:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Werden wir wieder online gehen können?&lt;/li&gt;
&lt;li&gt;Haben wir Daten verloren?&lt;/li&gt;
&lt;li&gt;Wie lange wird das alles dauern?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Der vorausschauende Admin hat für alle drei Fragen schon Antworten parat. Das kann er nur, wenn er die Recovery seiner Datenbank geplant, geübt und gebenchmarkt hat.&lt;/p&gt;
&lt;h3 id=&#34;folgerung-10-platz-um-sich-zu-bewegen&#34;&gt;
    &lt;a href=&#34;#folgerung-10-platz-um-sich-zu-bewegen&#34;&gt;
	Folgerung 10: Platz um sich zu bewegen
    &lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Ein Backup-Slave, so vorhanden, sollte genug Platz und Power haben, um eine Recovery in endlicher Zeit durchführen zu können. In den meisten Fällen plant man 3 bis 5 mal mehr Plattenplatz ein als die Datenbankzielgröße ist. Teile dieses Platzes können langsamer sein (weniger Spindeln haben, also aus größeren Platten zusammengesetzt sein) als die eigentliche aktive Datenbank.&lt;/p&gt;
&lt;p&gt;Ein Test- oder Scratchrechner, etwa der Backup-Slave oder eine dritte Kiste, können sehr handlich sein, um Dinge zu testen, Datenextraktionen oder Loads vorzubereiten oder andere administrative Dinge zu stagen.&lt;/p&gt;
&lt;h2 id=&#34;der-einkaufszettel&#34;&gt;
    &lt;a href=&#34;#der-einkaufszettel&#34;&gt;
	Der Einkaufszettel
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Schätzhilfen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Die Zielgröße der Datenbank.&lt;/li&gt;
&lt;li&gt;Die erwartete Schreiblast.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prüfung: Lohnt es eine speichergesättigte Datenbank zu bauen?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ja:&lt;/strong&gt; Dies ist der Fall, wenn wir die benötigten Daten komplett ins RAM bekommen und die Schreibrate angemessen niedrig ist.&lt;/p&gt;
&lt;p&gt;In diesem Fall stecken wir alles Geld ins RAM und bauen Platten an die Datenbank, um die Schreibrate zu bewältigen und um unseren RAM-Cache beim Hochfahren voll zu saugen. Wir brauchen aber unter Umständen keine dicken Arrays mit vielen Spindeln.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nein:&lt;/strong&gt; Wenn wir eine hohe Schreibrate haben oder unser Datenbestand so dick ist, daß wir mit den üblichen RAM-Größen keine Chance haben das alles weg zu cachen, nehmen wir das RAM eine Größe kleiner und stecken das frei werdende Geld in ein dickes Array mit vielen Spindeln. Das Array setzen wir als RAID-10 auf.&lt;/p&gt;
&lt;p&gt;Je nach zu erwartendem Grad von Concurrency bauen wir uns ein 2, 4 oder 8-Core-System. Richtig spannend wird die CPU-Nutzung aber aller Voraussicht nur bei speichergesättigten Datenbanken oder in spezialgelagerten Sonderfällen.&lt;/p&gt;
&lt;p&gt;Weil wir erwarten mehr als 2-4G Speicher zu verwenden, achten wir darauf, daß die CPU, das Betriebssystem und die Datenbank in 64 Bit-Versionen installiert werden.&lt;/p&gt;
&lt;p&gt;Konfigurationen, die ich beim Kunden gesehen habe waren etwa Dell 1950 mit einem MD1000 oder MD3000 hinten dran, HP DL 385 und DL 585 mit einem oder zwei MSA 30 hinten dran oder ähnliche Kisten von anderen Herstellern. Davor liegende Webserver waren oft Blades, zum Teil ohne Platten, mit 2G RAM und 32 Bit Betriebssystemen - für Webserver ist dies idR ausreichend und hier ist ein breites Array von Servernodes wichtiger als leistungsstarke einzelne Knoten, sobald die Latenz bei der Abarbeitung der Requests niedrig genug ist.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RAID-5</title>
      <link>https://blog.koehntopp.info/2007/06/05/raid-5.html</link>
      <pubDate>Tue, 05 Jun 2007 12:36:29 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2007/06/05/raid-5.html</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;R&amp;gt; Ich hoffe, Isotopp wirft den Text aus #offtopicana nachher noch ins Blog.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Okay, hiermit getan.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;O&amp;gt;&lt;/strong&gt;
Tu ich in den Ersatz-Server nun 2 oder 4 500er-Platten?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;R&amp;gt;&lt;/strong&gt;
Machs richtig.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;B&amp;gt;&lt;/strong&gt; Nimm 4. Oder 5, wenn es geht. Vier im Raid, eine als Hot Spare.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt; Raid-5 nur mit Hot Spare (außer bei mir daheim). Raid-5 im Degraded Mode hat einen tierischen Overhead. So hoch, daß man sich die Frage &amp;ldquo;Prio auf normale Accesses oder Prio auf Reconstruct&amp;rdquo; nicht stellen muss.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;B&amp;gt;&lt;/strong&gt;
I: ah? Danke für den Hinweis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Raid-5 undegraded mit 4 platten: Du hast Chunks von x kb (etwa 64k), und zwar 1. Chunk auf Disk A, 2. Chunk auf Disk b, 3. Chunk auf Disk C und Parity auf Disk 4.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Das ist eine Raidline, hier mit Size = 3x64k = 192k.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Nächste Raidline hat 4. chunk auf A, 5. chunk auf B, Parity auf C und 6. Chunk auf D.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Nächste dann 7=A, Parity=B, 8=C und 9=D&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Dann Parity=A, 10=B, 11=C und 12=D.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Parity läuft also um. Da bei jedem Write auch Parity geschrieben wird, verteilen sich so die Parity Writes auf alle Spindeln.&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;td&gt;A&lt;/td&gt;&lt;td&gt;B&lt;/td&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;D&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;P&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;p&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;p&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;p&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Ein long write ist ein Rewrite einer ganzen Raidline, also hier 192k am Stück auf einer 192k-Grenze.
Passiert oft bei Fileservern, die etwa Mediafiles schreiben.
Das sind drei logische Writes: write 1, write 2, write 3.
Die werden zu 4 physikalischen writes: write 1, write 2, write 3 und write p = 1 xor 2 xor 3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Ein short write ist jeder andere write.
Passiert oft bei Datenbanken.
Ein LOGISCHER write (write 1) wird hier zu 4 physikalischen Disk Operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read 1,&lt;/li&gt;
&lt;li&gt;read parity,&lt;/li&gt;
&lt;li&gt;(parity xor 1 xor 1neu = parity_neu),&lt;/li&gt;
&lt;li&gt;write 1neu,&lt;/li&gt;
&lt;li&gt;write parity_neu.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Mit Caches kann ein Raid-5 2 von den 4 physikalischen Operations eliminieren (die beiden Reads).
Daher sind Raid-5 sehr schlecht bei Datenbanken und allem anderen Zeugs mit kleinen Writes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Reads skalieren fein: ein 4-Disk Raid-5 performt beim Read wie ein 3-Disk Raid-0. Das ist gut&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Das sind die &amp;ldquo;undegraded&amp;rdquo; Fälle.
Jetzt failed eine Platte, sei es disk C.
Wir lesen 1 → read A.
Wir lesen 2 → read B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Wir lesen 3 → Read D, (cacheable) read A, (cacheable) read B und deliver 3 = p xor a xor b.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Wenn wir short Reads haben, wird also jeder Read auf die failed Disk zu einem Read ALLER anderen Disks.
Mit Caches geht es dann wieder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Mit einem Hot Spare geht das Array bei einem Failure sofort in den Reconstruct und sollte so konfiguriert sein, daß es so viel Power als möglich in den Reconstruct steckt:
Alle Idlezeit und garantierte Mindestbandbreite so konfiguriert, daß Wirkbetrieb gerade noch erträglich geserved wird.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
Sobald das hotspare dann in sync ist, kann der Wirkbetrieb wieder ohne degraded Performance sauber geliefert werden.
Und die Redundanz ist wieder hergestellt, Plattenfehler treten oft als Doppelfehler auf, das ist wie bei Glühbirnen, die haben ja auch dieses Gruppen-Fehlerverhalten.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;O&amp;gt;&lt;/strong&gt;
Und um die Lehrstunde komplett zu machen, sagst Du mir, wie ich mit 4 Platten möglichst gut fahre.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I&amp;gt;&lt;/strong&gt;
3 Platten ist minimum für Raid-5.
Also 3+hotspare nach Lehrbuch, oder 4+keine spare und volles Risiko.
Offiziell würde man immer 3+hotspare bauen und bei entsprechender Verfügbarkeitsanforderung auch noch Hotplug-Rahmen nehmen.
Vielleicht mal mit Micha von &lt;a href=&#34;http://www.deltacomputer.de&#34;&gt;Delta Computer&lt;/a&gt; reden.
Die Plattengehäuse von Supermicro find ich jedenfalls gut.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/server.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Die Wahrheit über Wi-Fi</title>
      <link>https://blog.koehntopp.info/2007/05/29/die-wahrheit-ueber-wifi.html</link>
      <pubDate>Tue, 29 May 2007 08:32:13 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2007/05/29/die-wahrheit-ueber-wifi.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/wireless-devices-small.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Dieser
&lt;a href=&#34;http://www.wellingtongrey.net/miscellanea/archive/2007-05-27--the-truth-about-wireless-devices.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Comic&lt;/a&gt;


ist mir wichtig.
Ich bin ja auch eines dieser bedauernswerten Strahlungsopfer, ein schlafgestörter, geistig zurückgebliebener, zwergenwüchsiger Kümmerling:
Ich wäre eigentlich 4.50 m groß geworden, hätte Feuer speien können und die Weltherrschaft an mich gerissen, aber durch die Strahlenexperimente meines Vaters bin ich halt klein und schwach geblieben und muss meine Software unter der GPL verschenken.
Danke, Papa!&lt;/p&gt;
&lt;p&gt;Der Comic irrt jedoch, wenn er die Gefahr bei der Strahlung verortet.
Es ist nicht die Strahlung, die gefährlich ist, sondern die Antenne.
Ein Mobilfunkprovider, bei dem ich mal gearbeitet habe, hat das in einer Doppelblindstudie erforscht:
Antennen die mit Basisstations-Containern aufgestellt wurden erzeugen bei den Anwohnern exakt dieselben medizinischen Beschwerden wie Antennen, die unangeschlossen aufgestellt werden.
Muss irgendwie die Kristallstruktur in den Antennenmetallen sein.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MuT 64er 10/86</title>
      <link>https://blog.koehntopp.info/2006/10/26/mut-64er-10-86.html</link>
      <pubDate>Thu, 26 Oct 2006 06:37:57 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2006/10/26/mut-64er-10-86.html</guid>
      <description>&lt;p&gt;Im März 1983 bekam ich meinen ersten eigenen Computer, einen Commodore 64.
Meiner war das alte Modell mit braunen statt schwarzen Funktionstasten und dem VIC I, bei dem die linken Ränder von Sprites immer flackerten.
Im Sommer 1983 kam dann eine 1541 dazu.&lt;/p&gt;
&lt;p&gt;Irgendwann in dieser Zeit zog ich außerdem aus der Probsteier Pampa in die tosende Großstadt, nach Kiel.
Dort lernte ich irgendwo an den üblichen Diskettentauschstellen Daniel kennen.
Das war gut, denn so kannte ich jemanden, der wie ich im Gegensatz zu den üblichen Kopierkiddies auch selber was machte.
Ob das, was wir da gemacht haben überhaupt technisch möglich war, hat uns nur am Rande interessiert.&lt;/p&gt;
&lt;p&gt;Irgendwann im Sommer 1985 haben wir dann gelernt, daß ein Monitorlautsprecher knackst, wenn man die SID-Lautstärke verstellt, und zwar proportional zur Änderung der Lautstärke.
Wenn man also einige tausendmal pro Sekunde die Lautstärke umstellt, kann man eine beliebige Wellenform erzeugen.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/64er-titel.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Daniel nahm also seinen Lötkolben und einen Haufen Drähte und verband den LED-Output des Levelmeters seiner Stereoanlage mit dem Joystick-Input seines C64.
Eine recht haarsträubende Schaltung zählte dabei die angeschalteten LEDs und generierte so die Bitkombinationen 00, 01, 10 und 11.&lt;/p&gt;
&lt;p&gt;Ich schrieb eine kleine Endlosschleife, mit der ich die Zwei-Bit-Codes vom Port abholte und mehr als 18.000-mal pro Sekunde in irgendwelche plötzlich gar nicht mehr so reichhaltig vorhandenen Bytes im Speicher shiftete.
Weil für eine Prüfung einer Abbruchbedingung keine Zyklen mehr übrig waren, mußte ich die Schleife in einem NMI-Handler zerpoken, um sie zu verlassen.
Programmabbruch durch Drücken der &amp;ldquo;Restore&amp;rdquo;-Taste, die direkt mit dem NMI-Input des Prozessors verbunden war.&lt;/p&gt;
&lt;p&gt;All das hat fast gut funktioniert, nur der Klang war grauenhaft.
Daniel wurmte das, und irgendwann hatte er alles so satt, daß er für den monströsen Betrag von DM 250 ein russisches Exil-Oszilloskop mit einem ca. 5 cm Schirm auf dem Gebrauchtmarkt erhökerte.
Schon 15 Minuten nach dem Anschluss des Gerätes war das Problem klar:
Das Levelmeter schneidet die Kurven unten ab, sodass wir immer nur das Intervall zwischen 0 Volt und +x Volt einer Kurve gesampled haben, aber niemals die negativen Teile der Welle.&lt;/p&gt;
&lt;p&gt;Die Einführung einer Potentialkorrektur (Nullpunkt und Amplitude) hat das Problem schnell gelöst und ich schrieb eine Kalibrierungsfunktion:
Die gelesenen Zwei-Bit-Werte wurden mit einer Lookuptable in C64 Farbcodes übersetzt und dann in die Kontrollregister für die Hintergrundfarbe geschrieben.
Vor der Aufnahme konnte man also an den Kalibrierungspotentiometern drehen und den Farbenrausch auf dem Monitor beeinflussen.
Wenn alle Farben in etwa gleich häufig zu sehen waren, war die Aufnahme korrekt ausgesteuert.
Der Klang war - zwei Bit oder nicht - großartig!&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/kris_pubertaet.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Ich bastelte meine Aufnahmefunktion in etwas Benutzbares, und darunter verstand ich zur damaligen Zeit eine Basic-Erweiterung für das C64 Basic,
&lt;a href=&#34;http://www.npsnet.com/danf/cbm/languages.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Speech Basic&lt;/a&gt;

.
Wir machten eine Demo-Diskette und zogen damit auf der CeBit &amp;lsquo;86 von Zeitschriftenstand zu Zeitschriftenstand.
Die Markt und Technik &amp;ldquo;64er&amp;rdquo; Redaktion machte den Sale, und plötzlich stand ich nicht nur vor dem Problem, eine Anleitung für Speech Basic und einen Artikel schreiben zu müssen, sondern auch ein für eine Veröffentlichung geeignetes Foto zu finden.
Ersteres Problem war lösbar, das zweite nicht, und so ist der Artikel in der 64er 10/86 mit dem wahrscheinlich hässlichsten Foto gedruckt worden, das je von mir gemacht worden ist.&lt;/p&gt;
&lt;p&gt;Der Speech Basic-Artikel war mein erstes selbst verdientes Geld.
Aber damit hörte das nicht auf:
Da Speech Basic ja nur mit der Hardware sinnvoll war, die Daniel inzwischen in eine kleine handliche Platine umgewandelt hatte, die an den Joystick-Port zu stecken war, mussten die Leser diese Platine entweder selber bauen oder kaufen.
Daniel ließ im Artikel seine Adresse abdrucken und für nur 60 DM konnte man einen Digitizer und eine Diskette mit Speech Basic kaufen.
Einige tausend Bestellungen später waren wir, zwei Oberstufenschüler, nach unseren Maßstäben plötzlich verdammt reich.
Irgendwann Ende &amp;lsquo;86 hatte ich dann also keinen C64 mehr, sondern konnte auf eine Commodore Amiga umsteigen.&lt;/p&gt;
&lt;p&gt;Und so kommt es, dass mich das ganze Rechnerzeugs in diesem Monat seit 20 Jahren ernährt.
Und in
&lt;a href=&#34;http://groups.google.com/group/sub.test/msg/1b2b1a01e36f92e9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ein paar Jahren&lt;/a&gt;


blogge ich Euch dann im Rahmen der Reihe &amp;ldquo;Alter Sack bloggt&amp;rdquo; mal, wie es kommt, daß ich seit 20 Jahren online bin.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kris vs. 2xMSA 30</title>
      <link>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</link>
      <pubDate>Wed, 04 Oct 2006 17:20:35 +0000</pubDate><author>kris-blog@koehntopp.de (Kristian Köhntopp)</author>

      <guid>https://blog.koehntopp.info/2006/10/04/kris-vs-2xmsa-30.html</guid>
      <description>&lt;p&gt;&amp;lt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/msa30-prod.gif&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ein MSA-30 Array mit 14 Platten.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Liebes Tagebuch!&lt;/p&gt;
&lt;p&gt;Heute bin ich gegen eine HP 585 und zwei MSA 30 angetreten und ich bin mir nicht ganz sicher, wer gewonnen hat.
Aber laß mich von vorne erzählen.&lt;/p&gt;
&lt;p&gt;Wie Du weißt, liebes Tagebuch, berechnet sich die Anzahl der Zugriffe, die man von einer einzelnen Platte pro Sekunde erwarten kann, wie folgt: 1000 ms/(Average Seek Time in ms + Rotational Delay in ms + Transfer Time in ms).
Die Average Seek Time kann bei einer guten Platte schon mal 4 ms klein sein, bei schlechten Platten auch mal 8 ms groß.&lt;/p&gt;
&lt;p&gt;Die Rotational Delay ist bei 18000 rpm bei 300 Umdrehungen pro Sekunde, als 600 Halbdrehungen pro Sekunde oder 1/600 Sekunde = 1.6 ms.
Bei Laptop-Platten mit 6000 rpm ist sie dreimal größer, also 5 ms.
Die Transfer Time kann man für den Rest der Betrachtungen auch getrost vergessen.
Somit haben wir eine Access Time von insgesamt 5 ms bis 12 ms rauf.
Das übersetzt sich zu 200 bis 80 Writes/Seeks/Commits pro Sekunde.
Von so einer Platte aus einem MSA 30 würde ich eher 200 als 80 Operationen pro Sekunde erwarten.&lt;/p&gt;
&lt;p&gt;Da stand sie nun also, die Hardware:
Eine HP 585 mit 32 GB RAM und 2 Dual-Core Opteron @ 2.6 GHz, zwei 6402 Controllern und zwei Dual-Channel MSA 30 mit jeweils 14 72 GB Platten.
Und wegen der spezifischen Verteilung der Controller und Channels ließen sich die beiden MSA 30 nicht zu einem 28 Disk Hardware RAID-10 zusammenfassen.
Also haben wir angefangen zu experimentieren und zu messen.
Die Ergebnisse waren sehr merkwürdig.&lt;/p&gt;
&lt;p&gt;Wir haben uns das so überlegt, liebes Tagebuch:
Wenn man schon kein Hardware RAID-10 mit allen 28 Platten bauen kann, dann kann man sich immerhin 14 Hardware-RAID-1 Paare stricken und die dann in ein Linuxraid als RAID-0 stopfen.
Gesagt, getan:
Ins Menü, durch die Controller jongliert und die Plattenarrays wie wild blinken lassen - HP macht ja sehr unmissverständlich klar, welche Platte man gerade wie am Wickel hat.&lt;/p&gt;
&lt;p&gt;Am Ende ins Linux booten und da waren sie dann: &lt;code&gt;/dev/cciss/c1d0-c1d6&lt;/code&gt; und &lt;code&gt;/dev/cciss/c2d0-c2d6&lt;/code&gt;:
14 RAID-1 Paare.
Ein &lt;code&gt;mdadm -C -l0 --chunk=128k /dev/md0 --raid-devices 14 /dev/cciss/c[12]d*&lt;/code&gt; später hatten wir dann ein &lt;code&gt;/dev/md0&lt;/code&gt; mit 14 Paaren.
Das wollten wir nun nackig machen, also &lt;code&gt;mkfs /dev/md0&lt;/code&gt; und &lt;code&gt;mount /dev/md0 /data0&lt;/code&gt; und dann
&lt;code&gt;[iozone](http://www.iozone.org) -i0 -i2 -O -I -s4g -r128k -f /data0/blah&lt;/code&gt; da drauf.&lt;/p&gt;
&lt;p&gt;Stell Dir unsere Enttäuschung vor, liebes Tagebuch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;iozone -i0 -i1 -i2 -O -I -s4g -r128k -f /data0/blah
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Iozone: Performance Test of File I/O
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                Version $Revision: 3.263 $
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                Compiled for 64 bit mode.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                Build: linux
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                     Randy Dunlap, Mark Montague, Dan Million,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                     Jean-Marc Zucconi, Jeff Blomberg,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                     Erik Habbinga, Kris Strecker, Walter Wong.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;        Run began: Fri Feb 17 03:20:20 2006
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;        OPS Mode. Output is in operations per second.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        O_DIRECT feature enabled
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        File size set to 4194304 KB
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Record Size 128 KB
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Command line used: iozone -i0 -i1 -i2 -O -I -s4g -r128k -f /data0/blah
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Time Resolution = 0.000001 seconds.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Processor cache size set to 1024 Kbytes.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        Processor cache line size set to 32 bytes.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;        File stride size set to 17 * record size.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;                                                            random  random
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;              KB  reclen   write rewrite    read    reread    read   write
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;         4194304     128     999    1165     1126     1131     246    1107
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ich meine, wenn ich pro Platte 200 w/s rechne und von einem RAID-1 mit serieller Write-Policy ausgehe, dann erwarte ich auch von einem RAID-1 Paar mal eben 200 w/s, oder von 14 Paaren also 2800 w/s.
Bekommen habe ich nur 1107 w/s Random-I/O.
Das ist aber mächtig schlapp, nur 40 % der projektierten Performance.&lt;/p&gt;
&lt;p&gt;Wir haben dann mal ein wenig gespielt:&lt;/p&gt;
&lt;p&gt;1 Paar (Hardware RAID, ohne Linuxraid) bringt 198 w/s, also genau wie die theoretische Vorhersage.
2 Paare (Hardware RAID, interner Controller, ohne Linuxraid) bringt nur 336 w/s (84%).
Keine Ahnung, was die Chunksize hier war.
7 Paare linear vom ersten /dev/cciss/c1d* genommen bringen 808 w/s (57%).
7 Paare sortiert (c1d0, c2d0, c1d4, c2d4, c1d2, c2d2, c1d6) bringen 1382 w/s (99%). Fein!
14 Paare linear (/dev/cciss/c[12]d*) bringen wie gesagt nur 1107 w/s (40%).
14 Paare sortiert (c1d0, c2d0, c1d6, c2d6, c1d1, c2d1, c1d5, c2d5, usw) bringen immerhin 1434 w/s (51.2%).&lt;/p&gt;
&lt;p&gt;Aber damit nicht genug, liebes Tagebuch!
Ich habe noch ein weiteres Mysterium für heute: &lt;code&gt;iostat -x&lt;/code&gt; meint während des 7 Paare Linear-Tests so Dinge wie&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Device:    rrqm/s wrqm/s   r/s   w/s  rsec/s  wsec/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c0d0   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d0   0.00   3.00  0.00 307.00    0.00 38696.00     0.00 19348.00   126.05     0.14    2.22   0.46  14.20
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d0   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;md0          0.00   0.00  0.00 2275.00    0.00 283392.00     0.00 141696.00   124.57     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d1   0.00   6.00  0.00 320.00    0.00 38608.00     0.00 19304.00   120.65     0.21    0.65   0.63  20.20
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d2   0.00   9.00  0.00 342.00    0.00 42416.00     0.00 21208.00   124.02     0.23    0.66   0.64  22.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d3   0.00   0.00  0.00 335.00    0.00 44280.00     0.00 22140.00   132.18     0.23    0.69   0.67  22.60
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d4   0.00   0.00  0.00 318.00    0.00 39904.00     0.00 19952.00   125.48     0.22    0.70   0.68  21.60
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d5   0.00   5.00  0.00 309.00    0.00 39568.00     0.00 19784.00   128.05     0.21    0.68   0.66  20.40
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d6   0.00   9.00  0.00 311.00    0.00 39920.00     0.00 19960.00   128.36     0.27    0.86   0.84  26.10
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d1   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d2   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d3   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d4   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d5   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d6   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das heißt in Deutsch:
Man kann sehen, wie die Platte &lt;code&gt;c1d0-c1d6&lt;/code&gt; hier angeblich um die 320 w/s machen und damit dann noch schon ganze 20 % ausgelastet sind (nein, die ganzen CPUs sind nicht busy).
Die angeblich 2275 w/s zu 128k average request size übersetzen sich dann aber in &lt;code&gt;iozone&lt;/code&gt; nachher zu 808 w/s.&lt;/p&gt;
&lt;p&gt;Dasselbe hier:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;Device:    rrqm/s wrqm/s   r/s   w/s  rsec/s  wsec/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c0d0   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d0   0.00   4.33  0.00 387.33    0.00 48373.33     0.00 24186.67   124.89     0.20    0.51   0.50  19.20
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d0   0.00   5.67  0.00 402.67    0.00 51010.67     0.00 25505.33   126.68     0.19    0.47   0.45  18.23
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;md0          0.00   0.00  0.00 2825.67    0.00 352170.67     0.00 176085.33   124.63     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d1   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d2   0.00   5.67  0.00 404.00    0.00 50626.67     0.00 25313.33   125.31     0.21    0.52   0.50  20.17
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d3   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d4   0.00   6.67  0.00 417.00    0.00 51613.33     0.00 25806.67   123.77     0.21    0.49   0.47  19.80
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d5   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c1d6   0.00   6.00  0.00 386.33    0.00 49277.33     0.00 24638.67   127.55     0.27    0.69   0.68  26.20
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d1   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d2   0.00   6.00  0.00 386.33    0.00 49557.33     0.00 24778.67   128.28     0.18    0.48   0.47  17.97
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d3   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d4   0.00   4.00  0.00 404.00    0.00 51712.00     0.00 25856.00   128.00     0.19    0.48   0.47  18.93
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d5   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;cciss/c2d6   0.00   0.00  0.00  0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das ist die lustige nicht lineare 7-Paar Config in Aktion.
Wir sehen 2825 w/s auf dem md0, die später als 1382 w/s vom &lt;code&gt;iozone&lt;/code&gt; bilanziert werden.
Nun frage ich mich, liebes Tagebuch: Wer hat recht?&lt;/p&gt;
&lt;p&gt;Ach ja, und außerdem, liebes Tagebuch, das dritte Mysterium dieses Tages:
Wieso saugt meine Read-Performance so?
Ich meine, 246 r/s sind echt kaputt, -I (O_DIRECT) oder nicht.&lt;/p&gt;
&lt;p&gt;Morgen, liebes Tagebuch, machen wir dann mal ein Hardware RAID-10 mit einem Array und einem Controller, also 7 Paare Hardware RAID-0 in einer linearen Config.
Mal sehen, was wir dann so für Messwerte bekommen.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
