<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hadoop on Die wunderbare Welt von Isotopp</title>
    <link>https://blog.koehntopp.info/tags/hadoop.html</link>
    <description>Recent content in hadoop on Die wunderbare Welt von Isotopp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Dec 2022 20:37:46 +0000</lastBuildDate><atom:link href="https://blog.koehntopp.info/tags/hadoop/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>On cache problems, and what they mean for the future</title>
      <link>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</link>
      <pubDate>Fri, 23 Jun 2017 14:12:04 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2017/06/23/on-cache-problems-and-what-they-mean-for-the-future.html</guid>
      <description>&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/2017/06/ssd-problem.jpg&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;This is a disk utilization graph on a heavily loaded Graphite box. In this
case, a Dell with a MegaRAID, but that actually does not matter too much.&lt;/p&gt;
&lt;p&gt;Go-carbon was lagging and buffering on the box, because the SSD was running
at its IOPS limit. At 18:10, the write-back cache and the &amp;ldquo;intelligent
read-ahead&amp;rdquo; are being disabled, that is, the MegaRAID is being force-dumbed
down to a regular non-smart controller. The effect is stunning.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp NORA -l0 -aALL
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp WT -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and also, on top of that,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;Direct IO instead of cached 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp DIRECT -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;#&lt;/span&gt;Force SSD disk write cache &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;our SSD has super-capacitors, so it safe to &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp -EnDskCache -l0 -aALL 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What we observe here is part of an ongoing pattern, and we
will see more of it, and at more layers of the persistence-stack in our
systems.&lt;/p&gt;
&lt;h2 id=&#34;iops-are-a-solved-problem&#34;&gt;
    &lt;a href=&#34;#iops-are-a-solved-problem&#34;&gt;
	IOPS are a solved problem
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;At the lowest layers, IOPS are now a solved problem, and will become even
more so. SSD are limited mostly now because of their interfaces, and so we
go from IDE-interfaces to NVME to get rid of that overhead.&lt;/p&gt;
&lt;p&gt;That makes disk-seek operations very cheap - going from 200 IOPS on rotating
rust past 20k IOPS was only the first step, single drives now are offering
200k IOPS and more.&lt;/p&gt;
&lt;p&gt;Bandwidth can also be provided at bus speeds through aggregation, so this is
mostly a package engineering problem.&lt;/p&gt;
&lt;p&gt;Latency is still a problem. Even more than ever, actually, because now the
time to send a packet from a core through the network to a SSD at the other
end of the data center is comparable to or even dominating the time spent
reading or writing that remote media.&lt;/p&gt;
&lt;p&gt;SSD still are disk-like devices. We are reading sectors at a time instead of
individual bytes, and especially in writes we are re-flashing large blocks,
64 KB in size or larger, depending on the hardware. Smart internal
controllers in SSDs are trying to take care of these things in the
background.&lt;/p&gt;
&lt;p&gt;With Optane, this block structure of disks can and will go away. The proper
abstraction for Optane is not a file, but is memory - persistent, byte
addressable memory within an order of magnitude of RAM speed.&lt;/p&gt;
&lt;p&gt;On top of the actual drive sits a large stack of caches and transformation
layers. In this case, one layer, the disk controller and the logic in it,
became a bottleneck: A CPU considerably smaller than the actual system
processor, and with limited memory, was reading ahead file contents that do
not benefit from reading ahead. It was also buffering writes, in order
reorder and merge them, trying to exploit properties of a spinning medium
that was no longer present. The write-pressure from the systems processor
and the data volume became so large that either the CPU on the controller or
the size of the controller-cache became a bottleneck.&lt;/p&gt;
&lt;p&gt;A disk behind the controller would have been even slower than the
controller, but a SSD can actually cope and be faster than the controller
sitting between it and the system CPU. Taking the controller out of the path
speeds things up.&lt;/p&gt;
&lt;p&gt;The commands above take out one layer in the deep and rich storage stack,
but there are many more. Each of them now has the potential to become the
next bottleneck. Or as one of my database colleagues has been known to say
in one form or the other more than once:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Forget caches, just make everything fast all the time.&amp;rdquo; &amp;ndash; Nicolai Plum&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hadoop-in-the-face-of-many-iops&#34;&gt;
    &lt;a href=&#34;#hadoop-in-the-face-of-many-iops&#34;&gt;
	Hadoop in the face of many IOPS
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;We will see more of this, and at more levels of the system. Take Hadoop for
example. The two core premises on which Hadoop is built are&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Seeks are expensive. We scan data front to back, and build data
processing on linear I/O (of compressed CSV or JSON files, even!).Even if we
are reading much more data than we need, even if we have to costly
uncompress and parse the data, this method of processing is way faster than
any database could ever be, and we can easily leverage the power of
parallelism.&lt;/li&gt;
&lt;li&gt;Code is smaller than our data. So we create small Java classes with our
code and ship it to the systems where the data we need is stored locally in
order to process it.This is a convoluted way to express our wants within the
rigid framework of Map/Reduce, but it&amp;rsquo;s the only way to code, because
reading all that data and shipping it across the net to where the code lives
is literally impossible.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Premise #2 is no longer valid since
&lt;a href=&#34;https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p183.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupiter Rising&lt;/a&gt;

.
We can disaggregate processing and storage again, because we can build data
center networks that are as fast and wide as system buses, so that any core
in the data center can talk to any disk in the same data center.
&lt;a href=&#34;https://www.youtube.com/watch?v=NfxvjWSgplU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This talk&lt;/a&gt;

 demonstrates this by
creating ephemeral Hadoop processing clusters at the press of a button for
the processing of single queries, by kubernetizing the Hadoop Mappers and
Reducers. In this case, the relationship between the Mapper and the data
this Mapper processes is simply not local at all - the Mapper may in fact
run anywhere in the data center and is no longer tied to where the data is
stored at all. Or, as one of the networking colleagues of mine puts it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Any sufficiently funded technology is indistinguishable from Magic.&amp;rdquo;
(Brian Sayler on the networking underneath a containerized Hadoop and
Compute/Storage disaggregation)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Premise #1 is going out of the window as well. Next year, latest the year
after that, we likely will stop buying rotating rust even for the Hadoop
servers. But that means we could seek again, which means that we could be
using index data structures efficiently to work with data larger than main
memory again. Which means that all these de-normalized, scannable,
inefficiently nested and hard to parse JSON structures will be becoming more
and more of a problem: As I/O takes a smaller percentage of the time spent
on handling the data, we need to optimize the actual data decompression,
parsing and handling more. &lt;em&gt;Hadoop in the current form is a dead man
walking.&lt;/em&gt; There is no alternative piece of software visible at the horizon
at this moment, so these will be interesting times. And there will be more
changes: File I/O is, even at much smaller levels, a lot about reformatting
data from in-memory representations of things to on-disk representations.
In-memory structures are pointered and traversable, aligned to n-byte
boundaries, often lockable structures, because at memory speed these
optimization matter. For persistence, we serialize them in complicated ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Databases like MySQL have all kinds of densely packable data types (1- and
3-byte integers, for example),&lt;/li&gt;
&lt;li&gt;references are IDs, which require lookup, instead of being traversable
pointers&lt;/li&gt;
&lt;li&gt;the process of serialization often requires traversing nested,
multidimensional data structures of ADTs and creating a linear, frozen
representation of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shallow and deep copies need to be considered, depending on the problem.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a fully fledged phase transition where the data is going from a
gaseous, loosely packed form to a densely packed frozen, solid form for
storage. The things beyond SSD, Optane/3D-Xpoint and similar storage, are
more like memory than they are like disks, and hence they likely to some
extent are able to handle &amp;lsquo;gaseous&amp;rsquo; unserialized data and make that
persistent at the same time.&lt;/p&gt;
&lt;p&gt;In the end, the death of the file handle, and hence the death of Unix&lt;/p&gt;
&lt;p&gt;That challenges the fundamental abstraction of Unix, though, because in Unix
everything is a file, which is a linear array of bytes, and is being
accessed through a file handle. Now, with Optane persistent data may be no
longer behind a file handle, but a special kind of memory, and data does not
have to be crystallized into serialized structures before persistence. In
fact, the memory may be so fast that we might not have time to do that. We
require a different compute abstraction instead.&lt;/p&gt;
&lt;p&gt;Which means, when we have it, the result will finally, after five decades,
not really Unix any more.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HDFS - billig im Cluster speichern</title>
      <link>https://blog.koehntopp.info/2012/06/11/hdfs-billig-im-cluster-speichern.html</link>
      <pubDate>Mon, 11 Jun 2012 17:26:44 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/06/11/hdfs-billig-im-cluster-speichern.html</guid>
      <description>&lt;p&gt;Wer Clustern will, der muß erst mal einen solchen haben.  Also, einen
Cluster von möglichst vielen Rechnern.  Die Anforderungen sind dabei klar:
Man möchte Hardware haben, die möglichst billig ist - für Serverplatten,
Speicher mit Fehlerkorrektur (ECC), und dergleichen Luxus ist kein Geld da,
denn man möchte das gesparte Geld lieber in mehr Rechner stecken.&lt;/p&gt;
&lt;p&gt;Also Billighardware kaufen?  Nein!  Denn auch die laufenden Kosten möchte
man niedrig halten - der Rechner sollte also klein sein, und möglichst
geringe laufende Kosten haben, also möglichst wenig Strom aufnehmen und bei
möglichst hohen Zuluft-Temperaturen noch funktionieren.  Die oben
angedeutete Desktop-Kiste wird in dieser Form und mit diesem Formfaktor also
niemandem Freude bereiten.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Klein&amp;rdquo; heißt in unserem Fall, daß wir mehr Schachteln in ein Standard-Rack
hinein bekommen, wenig Strom aufnehmen heißt, daß wir wenig Strom bezahlen
müssen und wenig Strom dazu verbrauchen, um den in Wärme umgewandelten Strom
nach dem Verbrauch per Klimaanlage wieder nach draußen zu schaffen.  Und
hohe Zuluft-Temperaturen heißt, daß wir dicht packen können und daß wir die
Klimaanlage so klein als möglich dimensionieren können, also weniger Strom
für Kühlung und mehr Strom für das Rechnen ausgeben können.&lt;/p&gt;
&lt;p&gt;Wenn man das Ganze groß genug betreibt - also mit n-stelliger Anzahl von
Kisten, dann lohnt es sich, Metriken in Operations/Euro und Operations/Watt
sowie Operations/Grundfläche bzw.  Kubikmeter aufzustellen und dann auf dem
Problem ein wenig linear zu optimieren, damit man möglichst viel Bumms pro
Euro kauft.&lt;/p&gt;
&lt;p&gt;Wenn man eher mittelständische Haushaltsgrößen ins Auge faßt, dann geht man
zu seinem Standard-Hersteller für RZ-Hardware und schaut mal, was die an
möglichst einfachen Pizzaschachteln im Angebot haben.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/dl160g6.png&#34; alt=&#34;HP DL 160 Gen 6&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Pizzablech &amp;ldquo;HP DL160 Generation 6&amp;rdquo; für 4 Sorten Käse.&lt;/p&gt;
&lt;p&gt;Dieses Blech wiegt etwas über 12 Kilo, ist die üblichen 19&amp;quot; breit, eine
Höheneinheit im Rack hoch und etwas unter 70cm tief.  Eine
Beispielkonfiguration enthielte etwa eine 6-Core CPU, 24 GB RAM, 4 Platten
mit jeweils einem Terabyte als JBOD und einen bzw. zwei
Gigabit-Netzwerkports, und sie kommt mit ein wenig Gehampel für unter 2000
EUR/Stück.  Eine doppelt so hohe Kiste könnte statt 4 Platten deren 12
fassen, und ein damit aufgebauter Cluster hätte weniger CPU und mehr
Plattenspeicher.&lt;/p&gt;
&lt;p&gt;Das ist sehr unangestrengte Hardware - wenn man ein wenig mehr Hardcore
shoppen geht, dann bekommt man leicht etwas mit größeren Platten für wenig
Geld, wahrscheinlich aber auch mit einer schlechteren Ausfallrate.  Das
ganze Gelöt kommt nun in einige Racks, die wir mit Top-of-Rack Switches
sinnvoll in einem separaten Netz zusammenknoten.&lt;/p&gt;
&lt;h2 id=&#34;hdfs---hadoop-filesystem&#34;&gt;
    &lt;a href=&#34;#hdfs---hadoop-filesystem&#34;&gt;
	HDFS - Hadoop Filesystem
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Jetzt haben wir billige Platten von schlechter Qualität als JBOD ohne das
geringste bischen Redundanz, die wir einzeln und lokal in irgendein
Verzeichnis unsers Servers mounten.  HDFS, das Hadoop Filesystem, ist ein
verteiltes Dateisystem - es verwendet das vorhandene lokale Dateisystem auf
Einzelplatten schlechter Qualität, um daraus schnellen, parallel
ansprechbaren und redundanten Speicher im Cluster zu bauen.&lt;/p&gt;
&lt;p&gt;HDFS setzt dabei nur eine begrenzte Zahl von Operationen um - ein HDFS ist
kein vollwertiges Dateisystem im Sinne des Posix-Standards, sondern man kann
es sich mehr als eine Art verteilten und massiv parallelen FTP-Server
vorstellen: Das Dateisystem hat die Operationen GET, PUT und DELETE, sowie
neuerdings auch noch APPEND, um Daten an eine bestehende Datei anhängen zu
können.  Ein SEEK, READ oder WRITE existieren jedoch nicht, Locking auch
nicht.&lt;/p&gt;
&lt;p&gt;Entsprechend gibt es HDFS FUSE-Plugins, aber eben nur im Rahmen der Grenzen
der Operationen von HDFS.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/hadoop_disks.png&#34; alt=&#34;Ein Hadoop Datanode&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Ein Hadoop-Datanode&lt;/p&gt;
&lt;p&gt;HDFS startet zu diesem Zweck auf jedem Rechner mit nutzbaren Platten einen
Prozeß namens Datanode, und an zentraler Stelle einen Verwaltungsprozeß
namens NameNode.  Die Namenode kümmert sich um die Verwaltung von Dateinamen
und um das Wiederfinden von Blöcken.  Sie zerteilt sehr große Dateien in
vergleichsweise grobe Schnetzel von 128 MB Größe und speichert dann jeden
dieser &amp;ldquo;Blöcke&amp;rdquo; genannten 128 MB-Schnetzel mehrfach auf unterschiedlichen
Datanodes ab.  Dabei ist es wichtig, sich nicht von der Nomenklatur &amp;ldquo;Block&amp;rdquo;
ablenken zu lassen: Ein Block ist ein Stück Datei, das bis zu 128 MB groß
sein kann, aber bei kleineren Dateien eben auch kürzer.  Es handelt sich
nicht um Blöcke fester Größe wie bei einem richtigen Dateissystem.&lt;/p&gt;
&lt;p&gt;HDFS speichert die Daten auch nicht selbst ab: Es verwendet ein lokales
Dateisystem, zum Beispiel Linux ext4 oder xfs, um Dateien lokal zu verwalten
und liefert nur eine einheitliche Clustersicht auf die Dinge.  HDFS kümmert
sich also nur um die verteilten Aspekte des Dateisystems, und überläßt jedem
lokalen Knoten die Arbeit, das tatsächlich irgendwo auf eine Platte zu
malen.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gp&#34;&gt;[root@hadoop-115 finalized]#&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;pwd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;/srv/hadoop/data01/dfs/dn/current/BP-1321238634-10.196.68.149-1338912643577/current/finalized
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gp&#34;&gt;[root@hadoop-115 finalized]#&lt;/span&gt; ls -lh blk_1025864654234871634*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw------- 1 hdfs hdfs 128M Jun  6 13:37 blk_1025864654234871634
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;-rw------- 1 hdfs hdfs 1.1M Jun  6 13:37 blk_1025864654234871634_8941.meta
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Das Mountschema im Beispiel ist /srv/hadoop/data{n}.  Auf jeder lokalen
Platte gibt es einen Ordner /dfs/dn (Distributed Filesystem, Datanode), in
dem die Blöcke abgelegt werden.  Wir sehen hier irgendeinen namenlosen 128
MB Block und die Metadaten zu diesem Block.  Man braucht die Daten der
Namenode, um aus diesen Dateifetzen wieder sinnvoll benannte und eingereihte
Dateien zusammenzusetzen.&lt;/p&gt;
&lt;p&gt;Dabei geht das System durchaus pfiffig vor.&lt;/p&gt;
&lt;p&gt;Zum einen will man ja, daß die Daten redundant gespeichert sind.  Daher
werden per Default 3 Kopien von jedem Block angelegt, und natürlich liegt
jede Kopie auf einer anderen Maschine.  Tatsächlich kann man in die Namenode
einen Rackverteilungsplan einpflegen und dann sorgt die Namenode auch dafür,
daß zwei der Kopien vergleichsweise dicht beeinander liegen und eine weiter
entfernt, in einem anderen Rack.  So ist sichergestellt, daß immer
mindestens eine Kopie der Daten erhalten bleibt - auch dann, wenn mal ein
ganzes Rack umfällt, der Switch oben im Rack verendet oder ein Sack
fehlgeschlagener Kernelupdates einen Teil der Rechenzentrums-Population
auslöscht.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/hadoop-write.png&#34; alt=&#34;Schreibzugriff&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Ein Schreibzugriff in ein HDFS hinein.&lt;/p&gt;
&lt;p&gt;Zum anderen will man auch, daß der ganze Kram parallel abläuft.  Daher führt
die Namenode die Schreibvorgänge weder durch noch koordiniert sie diese.
Sie dient lediglich als Verzeichnisdienst: Sie sagt dem Client, wo ein Block
hingeschrieben wird, und der Client sendet diesen Block an die entsprechende
Datanode.  Diese schreibt ihn lokal und reicht in an die zweite Datanode
weiter - dieser Traffic ist aber Rack-intern.  Die zweite Datanode schreibt
sich den Block ebenfalls auf eine Platte und reicht ihn nun über die
Rackgrenze und die damit involvierten Switches hinweg an eine Node in einem
anderen Rack weiter, die den Block ebenfalls noch ein drittes Mal schreibt.
Die Bestätigungen für diese Operationen laufen denselben Weg den sie
gekommen sind wieder zurück (und gehen parallel dazu auch noch einmal an die
Namenode) und so weiß der Client, wenn er eine Bestätigung gesehen hat, daß
alles geklappt hat und der Block jetzt redundant und persistent gespeichert
ist.&lt;/p&gt;
&lt;p&gt;Da wir von jedem Block 3 Kopien anlegen, bedeutet das natürlich, daß wir für
ein Terabyte Nutzdaten 3 Terabyte Plattenplatz (und ein wenig Metadaten)
wegnaschen.&lt;/p&gt;
&lt;p&gt;Hadoop versucht außerdem, die Blöcke einer Datei möglichst breit über den
Cluster zu schmieren, also eine Datei über möglichst viele Datanodes zu
verteilen.  Das hat einerseits Geschwindigkeitsvorteile, wenn man parallel
schreibt, andererseits macht es die spätere Verarbeitung der Daten
schneller.&lt;/p&gt;
&lt;p&gt;So können wir eine Datei zum Beispiel lesen, indem wir bei der Namenode eine
Blockliste für die gesuchte Datei anfordern und dann parallel von allen
Nodes, die die Daten haben, aus dem Netzwerk laden.  Mehr Knoten bedeutet
hier mehr CPUs und mehr Plattenspindeln, also mehr Speed.  Das ist besonders
dann interessant, wenn Daten von einem Cluster zu einem anderen kopiert
werden - so eine massiv parallele Datenverschiebung bringt jede
Netzwerkinfrastruktur an die Sättigungsgrenze.  Und das, obwohl wir billige
Einzelkomponenten eingekauft haben.&lt;/p&gt;
&lt;p&gt;Der Punkt ist, daß HDFS diesen Komponenten nicht traut: Datanodes müssen
sich alle paar Sekunden bei ihrer Namenode per TCP Heartbeat melden, und in
regelmäßigen Abständen auch Blockreports machen - dadurch weiß die Namenode,
welche Blocks zu welcher Platte in einer Datanode gehören, wieviel freier
Platz vorhanden ist usw.&lt;/p&gt;
&lt;p&gt;Fällt eine von den Datanodes um oder geht auch nur eine Platte in der
Datanode offline, geht die Namenode los und weist die überlebenden Datanodes
für einen Block an, die notwendige Anzahl von Blockkopien wieder
herzustellen - der Cluster flackert kurz mit den Plattenlampen und alles ist
wieder gut - sogar, falls irgend möglich, im Rahmen der Redundanzregeln des
Rackverteilungsplans.&lt;/p&gt;
&lt;p&gt;Irgendwann später schickt man einen Azubi mit einem Einkaufskorb voller
Austauschplatten, Gehörschutz und dem Auftrag auszumisten in das RZ und
danach stimmt die Clusterkapazität wieder.&lt;/p&gt;
&lt;p&gt;Was passiert, wenn eine Platte in einer Datanode nicht umfällt, sondern
schimmelig wird und die Daten darauf verändert?  HDFS speichert großzügig
Prüfsummen an jedem Objekt und würde dies vergleichsweise schnell
mitbekommen - entweder beim nächsten Zugriff oder wenn der Cluster sich
langweilt und aus Verlegenheit sowieso mal seine Prüfsummen durchprüft.
Blöcke mit kaputten Prüfsummen werden kurzerhand abgemurkst, dann stimmt
aber die Anzahl der Kopien für diesen Block nicht mehr und die Namenode wird
tätig wie oben, um diese Situation zu korrigieren.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://blog.koehntopp.info/2012/05/28/logging.html</link>
      <pubDate>Mon, 28 May 2012 11:12:25 +0000</pubDate>
      
      <guid>https://blog.koehntopp.info/2012/05/28/logging.html</guid>
      <description>&lt;p&gt;&amp;ldquo;Kris&amp;rdquo;, fragt man mich, &amp;ldquo;Kris, gibt es außer &amp;lsquo;Volltextsuche&amp;rsquo; noch andere
Gründe, für neue Anwendungen noch MyISAM zu verwenden?  Im konkreten Fall
geht es um eine verhältnismäßig einfache Datenstruktur, in die nur streng
sequenziell geschrieben wird, nie gelöscht wird und viel und kreativ gelesen
wird.&amp;rdquo; Na, das ist doch mal ein weites Feld.&lt;/p&gt;
&lt;p&gt;Teile davon habe ich in
&lt;a href=&#34;https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html&#34;&gt;Ein paar Gedanken zu Zeitreihendaten&lt;/a&gt;


und
&lt;a href=&#34;https://blog.koehntopp.info/2012/03/12/wie-man-einen-graph-plottet.html&#34;&gt;Wie man einen Graph plottet&lt;/a&gt;


ja schon beackert.&lt;/p&gt;
&lt;p&gt;Aber gut.  &amp;lsquo;Streng sequentiell geschrieben&amp;rsquo; heißt, wir haben eine
Datenstruktur, die immer genau am &amp;lsquo;Ende&amp;rsquo; einer Tabelle Daten anfügt, also
eine Logtabelle.  &amp;lsquo;Nie gelöscht&amp;rsquo; heißt nur &amp;lsquo;Wir haben uns noch keine
Gedanken über Data Lifecycle Management gemacht&amp;rsquo;.  Und &amp;lsquo;kreativ gelesen&amp;rsquo;
heißt nur &amp;lsquo;Wir haben uns unter anderem deswegen noch keine Gedanken über
Data Lifecycle Management gemacht, weil unsere Metriken noch nicht definiert
sind&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Das ist legitim.  Aber fangen wir rückwärts an.&lt;/p&gt;
&lt;h2 id=&#34;data-lifecycle-management&#34;&gt;
    &lt;a href=&#34;#data-lifecycle-management&#34;&gt;
	Data Lifecycle Management
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Die meisten Systeme arbeiten transaktional und generieren Daten in einem
Online Transaction Processing System.  Das sind Systeme, in denen Daten
normalerweise halbwegs normalisiert vorliegen.  Meistens in der Nähe der
&lt;a href=&#34;http://de.wikipedia.org/wiki/Normalisierung_%28Datenbank%29#Dritte_Normalform_.283NF.29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3NF&lt;/a&gt;


(Internet-kompatible Erklärung
&lt;a href=&#34;http://mysqldump.azundris.com/archives/20-Nermalisation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mit Katzen&lt;/a&gt;

.
Diese Strukturen sind populär, weil sie zum Verändern und Beschreiben
optimiert sind.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/orderlog.png&#34; alt=&#34;Ein Orderlog&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;In den meisten dieser Systeme stecken kleine Data Warehouses, die über die
Zeit wachsen und dann heraus wollen.  Zum Beispiel hat ziemlich jeder
Webshop ein Orderlog mit Bestellungen, die in normalisierter Form auf den
Besteller in der Kundentabelle und die bestellten Artikel in der
Artikeltabelle verweisen würden.  Nach der Bearbeitung der Bestellung, der
Auslieferung und der Bezahlung werden diese Einträge inaktiv und brauchen
eigentlich nicht mehr in der Shopdatenbank zu stehen.&lt;/p&gt;
&lt;p&gt;Genau so hat ein Monitoring-System eine Datenstruktur, in der
Testvorschriften in Testergebnisse umgewandelt werden, fehlgeschlagene Tests
in Alarme umgesetzt werden und versendete offene Alarme durch Markierung
durch die Admins in erledigte Alarme umgewandelt werden.  Am Ende der
Lebensdauer eines solchen Vorfalls braucht der Alarm eigentlich nicht mehr
im Alarmlog des Monitoringsystems zu stehen.&lt;/p&gt;
&lt;p&gt;Anfangs ist das kein Problem, da es nur wenige Bestellungen oder erledigte
Alarme gibt, aber über die Lebensdauer und das Wachstum des Systems werden
das mehr und mehr Daten, die sich ansammeln.  Generell kann man solche Daten
leicht identifizieren, indem man sich das Datenmodell anschaut und sich
überlegt, welche Tabellen wachsen, wenn alle Eingangsparameter (Anzahl der
Kunden, Anzahl der Artikel, oder Anzahl der überwachten Rechner, der
fehlgeschlagenen Tests usw) gleich bleiben.  Solche wachsenden Tabellen
haben oft eine Primärschlüsselkomponente, die eine Zeitangabe oder ein
Zähler ist.&lt;/p&gt;
&lt;p&gt;Für diese Tabellen braucht man einen Prozeß, der erledigte Fälle erkennt und
aus dem primären System in regelmäßigen Intervallen entfernt.&lt;/p&gt;
&lt;p&gt;Die Daten müssen dabei außerdem denormalisiert werden.  Denn Anschriften von
Kunden, Preise und Beschreibungen von Artikeln oder die Funktionen von
überwachten Systemen ändern sich.  In unseren Auswertungen wollen wir aber
wissen, wohin wir den Artikel damals geliefert haben und was wir damals
kassiert haben und nicht, wo der Kunde jetzt wohnt oder was das Teil jetzt
gerade kostet.  Und so können wir nicht die kunde_id, artikel_id oder
system_id archivieren, sondern wir müssen diese Dinge auflösen und die
tatsächliche Kundenanschrift (oder seine Postleitzahl) archivieren, und die
tatsächliche Artikelbezeichnung, Farbe und so weiter.&lt;/p&gt;
&lt;p&gt;Dabei läuft man in eine Reihe von interessanten Problemen, weil die Daten,
die man speichern und auswerten will, eventuell gar nicht die Daten sind,
die nach der Denormalisierung vorliegen: In den Auswertungen interessiert
gar nicht, daß der Kunde damals im Knooper Weg 46, 24103 Kiel gewohnt hat,
sondern nur, daß er in 24xxx gewohnt hat, weil man am Ende eine Statistik
von Umsätzen nach Postleitzahlen über Zeit haben will.  Und es interessiert
auch nicht, daß eine &amp;lsquo;viktorianische Damenbluse&amp;rsquo; in &amp;lsquo;Aprikose&amp;rsquo; verkauft
worden ist, sondern die Auswertung will nach Blusen oder gar nur nach
Damenoberbekleidung gruppieren.  Und in der Auswertung gibt es vielleicht
nur 16 Farben und Aprikose ist eine Frucht, also muß man auch hier die
Modenamen von Farben in jeder Saison auf irgendwelche RGB-Codes mappen und
diese dann in Töpfen gruppieren.&lt;/p&gt;
&lt;p&gt;Diesen Prozeß der Denormalisierung, Attributextraktion und Neugruppierung
nennt man man
&lt;a href=&#34;http://de.wikipedia.org/wiki/ETL-Prozess&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extract, Transform, Load&lt;/a&gt;

,
und er ist etwas, mit dem man sich beim Schreiben einer
OLTP-Anwendung beim besten Willen nicht befassen kann und will, weil man
ganz andere Probleme hat und ja auch mal fertig werden will, damit man dem
Kunden endlich seine Blusen und Monitoring SMS andrehen kann (Ein
&lt;a href=&#34;https://blog.koehntopp.info/2006/07/23/mein-privates-datawarehouse-sparen-mit-mysql.html&#34;&gt;primitives Beispiel&lt;/a&gt;

).&lt;/p&gt;
&lt;p&gt;Es ist also nicht nur üblich, daß in jeder OLTP-Anwendung ein Data Warehouse
steckt, das raus will, sondern auch vollkommen normal und gut so.&lt;/p&gt;
&lt;p&gt;Dennoch geht so etwas auf die Performance, und außerdem will ein Betrieb mit
funktionierenden Managementstrukturen irgendwann auch mal
&lt;a href=&#34;http://www.cmmilevels.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;quantitativ gemanagete Prozesse&lt;/a&gt;


haben und braucht dafür geeignete Metriken.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/orderlog2.png&#34; alt=&#34;Ein Orderlog, eine Faktentabelle&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;ETL des Orderlogs in eine Faktentabelle, dabei Denormalisierung (Binning
nicht eingezeichnet).&lt;/p&gt;
&lt;p&gt;Dann setzt man sich hin, überlegt sich, was man für Zeugs aus dem
OLTP-System ETL&amp;rsquo;t gekommt und was man davon in welcher Form archivieren
will.  Im Ergebnis bekommt man einen Strom von zu archivierenden Attributen,
die sich aus der Auflösung von Primärschlüsseln in der OLTP-Datenbank
ergeben: artikel_ids werden zu Bezeichnungen, Preisen und Warengruppen von
Artikeln, kunden_ids werden zu Anschriften, Postleitzahlen, server_ids
werden zu Leistungsdaten und Systemgruppen von Servern, und Fehlercodes
werden zu Fehlermeldungen und Fehlergruppen von Störungen.&lt;/p&gt;
&lt;p&gt;Alle diese Dinge gehen in Faktentabellen, die in der Regel eine
Zeitdimension haben.  Häufig wendet man dabei schon Key Compression an, wie
in &lt;a href=&#34;https://blog.koehntopp.info/2009/10/28/ein-paar-gedanken-zu-zeitreihendaten.html&#34;&gt;Ein paar Gedanken zu Zeitreihendaten&lt;/a&gt;


beschrieben, um das Volumen der Daten halbwegs überschaubar zu halten.&lt;/p&gt;
&lt;p&gt;Und in einem nächsten Schritt erzeugt man dann Aggregationen, die die
relativ freien Faktendaten gruppieren und in Zählkörbe entlang einer
Maßdimension verteilen (&amp;lsquo;binning&amp;rsquo;).&lt;/p&gt;
&lt;p&gt;Bei dem Shop kann man entlang Warengruppen vereinfachen (&amp;lsquo;viktorianische
Bluse&amp;rsquo; -&amp;gt; DOB), entlang Größen (S/M/L/XL), Preisgruppen (&amp;lt;10 EUR, &amp;lt;20 EUR,
&amp;hellip;) und Farben (Aprikose -&amp;gt; Rot-Töne, Frühlingspalette, &amp;hellip;).  Ebenso kann
man
&lt;a href=&#34;http://fp.itwm.fhg.de/pp/vortraege/dmIII-web.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kunden klassifizieren und aggregieren&lt;/a&gt;

,
damit man überhaupt eine statistische Basis für eine Auswertung bekommt.&lt;/p&gt;
&lt;p&gt;Häufig wird man die Faktendaten nach dem Binning gar nicht mehr brauchen,
außer man nimmt Veränderungen an der Definition der Bins vor oder will gar
eine ganz neue Dimension erzeugen.  Dann ist es für eine solche
Reklassifizierung unabdingbar, daß man die Fakten noch einmal durchlaufen
läßt, um die Aggregate zu aktualisieren.  In den meisten Data Warehouses
geht man Speicherkompromisse ein, und hält die Aggregate &amp;lsquo;unbegrenzt&amp;rsquo; (also
länger als 10 Jahre :-) und die Fakten kürzer (je nach Storage-Kapazität -
am Ende muß jemand das Geld für den Plattenplatz bewilligen und man muß
ökonomische Kompromisse eingehen).&lt;/p&gt;
&lt;p&gt;Mit den Fakten kann man dann manuelle Analysen fahren oder
&lt;a href=&#34;http://erichsieht.wordpress.com/2012/02/26/datenkrake-google-17-einleitung/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Machine Learning&lt;/a&gt;


anwerfen, um zu versuchen, Korrelationen zu finden und einen
Klassifikator zu bauen.&lt;/p&gt;
&lt;p&gt;Den Fall &amp;rsquo;nie gelöscht&amp;rsquo; gibt es in der Regel bei nennenswerten
Datensammlungen eher nicht, oder wenn doch, dann liegen die eigentlichen
Fakten relativ wenig genutzt irgendwo in einer Backup-Ecke (und niemand
würde sie vermissen, löschte man sie), weil man sich eher mit den
generierten Klassifikatoren beschäftigt oder allenfalls noch einmal mit den
Dimensionen, entlang derer man versucht, eine solche Korrelation zu finden.&lt;/p&gt;
&lt;h2 id=&#34;logging-locking-und-myisam&#34;&gt;
    &lt;a href=&#34;#logging-locking-und-myisam&#34;&gt;
	Logging, Locking und MyISAM
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Man will so ein Logging in Faktentabellen unbedingt von dem operativen
Betrieb des OLTP-Systems trennen.  Die Datenbanken mit Lognatur sind also
von den Datenbanken mit wahlfreiem Zugriff trennen, denn zu unterschiedlich
sind die physischen Zugriffsmuster, der Speicherbedarf, die Anforderungen an
Verfügbarkeit und viele andere Dinge, die auf die Systemleistung Einfluß
haben.  &amp;lsquo;Trennen&amp;rsquo; heißt hier idealerweise &amp;lsquo;anderes Blech&amp;rsquo;, weil es sonst
auch hintenrum durch die Virtualisierung hindurch zu unangenehmen
Übersprecheffekten kommen kann.  Um so etwas auseinander zu sortieren
braucht man einen Debug-Virtuosen mit Zugriff auf alle Komponenten der
Wirkungskette - und solche Personen sind in der Regel teurer als zusätzliche
Hardware.&lt;/p&gt;
&lt;p&gt;Loggt man in eine MyISAM-Tabelle, dann loggt man eine Datenstruktur mit
Table Locks: MyISAM hat für jede Tabelle entweder den Zustand &amp;lsquo;frei&amp;rsquo; (idle),
&amp;lsquo;shared access&amp;rsquo; (ein oder mehrere konkurrente Lesezugriffe) oder &amp;rsquo;exclusive
access&amp;rsquo; (genau ein Writer).  Es gibt noch den Sonderfall &amp;lsquo;concurrent
inserts&amp;rsquo;, aber der hat auch seine eigenen Probleme und erzeugt in der Hälfte
aller Fälle mehr Probleme als er hilft.&lt;/p&gt;
&lt;p&gt;&lt;p class=&#34;md__image&#34;&gt;
  &lt;img src=&#34;https://blog.koehntopp.info/uploads/myisam_priorities.png&#34; alt=&#34;MyISAM Prioritäten&#34;  /&gt;
&lt;/p&gt;

&lt;/p&gt;
&lt;p&gt;Diese Table Locks haben emergente Effekte im Betrieb.  Die Regeln sind
eigentlich simpel: Wir können nur ENTWEDER Daten loggen ODER geloggte Daten
abfragen.  Per Default haben bereits laufende Abfragen Vorrang vor allem
anderen - MyISAM wird niemals eine bereits laufende Query von sich aus
abbrechen.  Die nächste Vorrangstufe haben Schreibzugriffe und auf der
letzten Ebene liegen Lesezugriffe.&lt;/p&gt;
&lt;p&gt;Ein INSERT in MyISAM braucht eine gewisse Zeit (im Bereich von einer
Millisekunde) und so kommt man mit einzelnen INSERT-Statements auf etwa 700
Operationen pro Sekunde für handelsübliche Hardware mit rotierendem Rost.
Andere Konfigurationen können sich anders, aber nicht zwangsläufig schneller
verhalten - Locking kann sehr interessante Debugsituationen erzeugen.&lt;/p&gt;
&lt;p&gt;Ob das INSERT durchkommt hängt  in erster Linie davon ab, ob schon eine
Query läuft.  Wenn länger laufende SELECT-Statements auf der Tabelle aktiv
sind, dann haben diese bereits ein Lock und MySQL wird bereits laufende
Queries nicht von sich aus unterbrechen.  In der Praxis sieht man meist
einen Mix von schnellen SELECT-Statements mit einem oder zwei schlecht zu
optimierenden, langsam laufenden Queries dazwischen.&lt;/p&gt;
&lt;p&gt;Alles dies läuft ohne Probleme bis eine schreibende Query das exklusive Lock
anfordert.  Diese Query kann das Lock nicht bekommen, weil mindestens eine
lesende Query bereits ein Lock auf der Tabelle hat.  Die Schreibquery, zum
Beispiel ein INSERT, stellt sich nun mit dem Status &amp;lsquo;Locked&amp;rsquo; in die
Prozeßliste und wartet.&lt;/p&gt;
&lt;p&gt;In Folge werden alle weiteren SELECT-Statements, die ja niedrigere Priorität
haben als das INSERT, von dem wartenden INSERT auch in den Wartezustand
geschickt - sie hängen ebenfalls &amp;lsquo;Locked&amp;rsquo; in der Prozeßliste und warten
darauf, daß das INSERT fertig wird.&lt;/p&gt;
&lt;p&gt;Irgendwann enden alle bereits laufenden SELECT-Queries und geben ihre Locks
auf der Tabelle auf.  Das INSERT-Statement wacht aus seinem &amp;lsquo;Locked&amp;rsquo; auf und
ist binnen einer Millisekunde erledigt.  Jetzt können auch alle im Zustand
&amp;lsquo;Locked&amp;rsquo; hängenden SELECT-Statements abgearbeitet werden.  Die meisten von
ihnen sind schnell beendet, da sie gut optimiert sind.  Nur eine von diesen
wartenden Queries ist komplizierter, nicht gut optimierbar und braucht
länger.  Während sie läuft tritt das nächste INSERT-Statement auf&amp;hellip;.&lt;/p&gt;
&lt;p&gt;Diese schwallartige Abarbeitung von SELECT-Queries nennt man
MyISAM-Interlocking.  Sie wird  zwar durch die Logik der MyISAM-Table Locks
gefördert, hat aber ihre Ursache nur mittelbar in der Hierarchie von Locks,
und sie ist auch durch Umpriorisierung nicht zu lösen.  Die eigentliche
Ursache liegt in konkurrenten schreibenden und lesenden Zugriffen und das
ist nur durch eine Datenstruktur mit weniger oder ganz ohne Locks in den
Griff zu bekommen.&lt;/p&gt;
&lt;p&gt;Man braucht Multi Value Concurrency Control (MVCC) und InnoDB.&lt;/p&gt;
&lt;h2 id=&#34;weitere-anmerkungen-zu-myisam&#34;&gt;
    &lt;a href=&#34;#weitere-anmerkungen-zu-myisam&#34;&gt;
	Weitere Anmerkungen zu MyISAM
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Es sei an dieser Stelle noch einmal ausdrücklich darauf hingewiesen, daß
solche Lockingeffekte ausgesprochen nichtlinear sind.  Solange sie nicht
auftreten, treten sie nicht auf (sic!).  Sie sind vollkommen unspürbar und
nicht leicht vorherzusagen - außer, man hat sie schon mal gesehen und weiß
[http://www.amazon.de/Guerrilla-Capacity-Planning-Tactical-Applications/dp/3540261389](wie man sie modelliert).
Wenn sie erst einmal auftreten, dann sind sie selbstverstärkend und bei
weiter steigender Last steht das System binnen kürzester Zeit mit einer
überlaufenden Prozessliste da.&lt;/p&gt;
&lt;p&gt;Das ist der Grund, warum ich im Rootforum und andernorts auf die Frage
&amp;lsquo;Meine Apache/PHP sagt, er könne sich nicht mehr an die Datenbank verbinden,
weil die Connections alle sind&amp;rsquo; nicht mehr antworte: &amp;lsquo;Setze max_connections
herauf&amp;rsquo; ist nicht die korrekte oder auch nur eine hilfreiche Antwort.  Eine
wirklich hilfreiche Antwort hätte nicht nur Buchumfang oder das Format eines
längeren Consulting-Einsatzes, sondern der Fragesteller will sie auch nicht
hören oder ist typischerweise nicht gut vorbereitet, sie zu verstehen.&lt;/p&gt;
&lt;p&gt;MyISAM ist in Situationen, in denen mit genau einem Thread geschrieben wird
und Reads vollkommen abwesend sind, extrem gut und schnell in der Lage,
Daten zu laden: Die Ladegeschwindigkeit von MyISAM ist in solchen
Situationen extrem hoch und nahezu konstant und von der Datengröße
unabhängig - vorausgesetzt man ist schlau genug ist, Indices zu disablen und
nach dem Ende des Loads einmal gesammelt aufzubauen.  Leider ist das kein
sehr typischer Anwendungsfall.&lt;/p&gt;
&lt;p&gt;Man kann den Anwendungsfall &amp;rsquo;typischer&amp;rsquo; machen oder versuchen, daß heiße,
schreibende Ende der Tabelle besser zu isolieren, indem man in kleine
Tabellen mit temporalen Namen lädt und die Abfragen dann nur auf alten,
inerten Daten macht.  Auf diese Weise kommen sich Schreib- und Lesezugriffe
nicht ins Gehege: Der Load erfolgt in logging_20120528_1401 und die Abfragen
dann auf alten, kalten Tabellen.  Dadurch hat man einen Monitoring-Lag von
einer Einheit (also hier im Beispiel von einer Minute).&lt;/p&gt;
&lt;p&gt;MyISAM-Daten lassen sich auch offline packen: Indem man eine Tabelle mit
&amp;ldquo;RENAME TABLE work.logging_20120528_1401 offline.logging_&amp;hellip;&amp;rdquo; in einen
Bereich verschiebt, in dem auf Grund der GRANTs kein Teil der Anwendung
Zugriff hat, kann man dann mit &amp;ldquo;&lt;a href=&#34;http://dev.mysql.com/doc/refman/5.5/en/flush.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FLUSH TABLES offline.logging&amp;hellip;&lt;/a&gt;

&amp;rdquo;
ein Schließen der Filehandles zu dieser Tabelle erzwingen und sicher sein,
daß die Filehandles auch zu bleiben.&lt;/p&gt;
&lt;p&gt;Nun kann man von außen &amp;ldquo;myisampack&amp;rdquo; anwenden, um die MYD-Datei zu packen und
dann mit &amp;ldquo;myisamchk&amp;rdquo; die Indices neu aufbauen.  Das Resultat ist eine
komprimierte (also deutlich kleinere) read-only Version der Tabelle, die nun
mit &amp;ldquo;RENAME TABLE offline.logging&amp;hellip;  work.logging&amp;hellip;&amp;rdquo; in die Produktion
zurück verschoben werden kann.  Die resultierenden Tabellen sind nicht nur
gepackt (das könnte die ARCHIVE-Engine auch), sondern sie haben auch
nutzbare Indices.&lt;/p&gt;
&lt;p&gt;In MySQL hat man seit MySQL 5.1 die Option, das general_log und das
slow_query_log statt als traditionelle Logfiles als CSV- (default) oder
MyISAM-Tabellen (optional) in mysql.* zu realisieren.  Nach den Ausführungen
oben kann man sich leicht überlegen, wieso ein solches Log als
MyISAM-Tabelle ineffizient ist (Lösungshinweis: MySQL ist ein Multithreaded
Server, jeder Thread kann Logevents generieren).&lt;/p&gt;
&lt;p&gt;Mit Kenntnis von &amp;ldquo;a&amp;rdquo; (O_APPEND in open(2)) kann man sich das Verhalten von
CSV-Dateien oder normalen Logdateien im Vergleich überlegen: Wie ist
sichergestellt, daß auch bei konkurrenten Log-Events einem
Multithreaded-Server ein CSV-Record geschrieben wird, ohne daß sich Daten
von einem anderen Log-Event da hinein überschneiden?  Wie ist
sichergestellt, daß CSV adäquat performiert?&lt;/p&gt;
&lt;h2 id=&#34;innodb-und-konkurrente-zugriffe&#34;&gt;
    &lt;a href=&#34;#innodb-und-konkurrente-zugriffe&#34;&gt;
	InnoDB und konkurrente Zugriffe
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Lädt man Daten multithreaded oder hat man auch auf der heißen, aktiven
Tabelle am Ende des Logs Lesezugriffe, weil man sich die Auwerteverzögerung
nicht leisten kann, dann ist MyISAM vollkommen unbrauchbar.  Und das wie
bereits erwähnt relativ schlagartig, da Locks sich in der Regel stark
nicht-linear zuziehen.  In diesem Fall muß man seine Logtabelle als
InnoDB-Tabelle realisieren, und dabei die interne Struktur von InnoDB und
ihre Rückwirkungen auf die Performance im Auge behalten.&lt;/p&gt;
&lt;p&gt;InnoDB-Tabellen sind nach Primärschlüssel geordnet.  Das bedeutet erst
einmal, daß man einen solchen definieren muß, damit
&lt;a href=&#34;http://fromdual.com/disadvantages-of-explicitly-not-using-innodb-primary-keys&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keine schlimmen Dinge passieren&lt;/a&gt;

.
Wählt man den Primary Key so, daß die Daten
physikalisch in der Reihenfolge des Schreibens angeordnet werden, muß man
sich über den
&lt;a href=&#34;http://blogs.innodb.com/wp/2010/09/mysql-5-5-innodb-change-buffering/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Change Buffer&lt;/a&gt;


und seine Performanceimplikationen im Klaren sein.&lt;/p&gt;
&lt;p&gt;Generell muß man damit rechnen, daß dieselben Daten in InnoDB 2-3 mal mehr
Platz auf der Platte und im Speicher belegen als in MyISAM.  Zwar kann man
auch in
&lt;a href=&#34;http://dev.mysql.com/doc/innodb-plugin/1.0/en/innodb-compression.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;InnoDB Compression&lt;/a&gt;


aktivieren, und im Gegensatz zu MyISAM sind komprimierte
InnoDB-Tables sogar normal beschreibbar.  Dennoch braucht auch eine
komprimierte InnoDB-Tabelle noch deutlich mehr Platz als eine komprimierte
MyISAM-Tabelle.  Das liegt einerseits am Verwaltungsoverhead von InnoDB
(MVCC braucht ca.  20 Bytes pro Row zur Verwaltung), und andererseits an dem
in den InnoDB Pages zwangsläufig vorhandenem freien Platz: jede InnoDB-Page
enthält eine gewisse Menge freien Platz, die Updates an Ort und Stelle auch
bei wachsenden Daten ermöglicht.  Wäre das nicht so, würde jede Änderung an
den Daten zu Seitenüberläufen und einem Rebalancing des B-Baumes auf der
Platte führen.&lt;/p&gt;
&lt;h2 id=&#34;ein-praktisches-beispiel-und-die-folgerungen&#34;&gt;
    &lt;a href=&#34;#ein-praktisches-beispiel-und-die-folgerungen&#34;&gt;
	Ein praktisches Beispiel und die Folgerungen
    &lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Das &amp;lsquo;Eventlog&amp;rsquo;-System ist eine interne Entwicklung meines Arbeitgebers, das
man am grob mit &amp;rsquo;ein Business-Level Logsystem, das dem Syslog auf
Systemebene noch am ehesten entspricht&amp;rsquo; beschreiben kann.  Eventlog
generiert gigantische Datenmenge, da so gut wie jede Systemkomponente Daten
an die Eventlog Listener sendet.  Die Listener bearbeiten die Daten in
mannigfaltiger Weise, aber am Ende langen sie in einer Datenbank.&lt;/p&gt;
&lt;p&gt;Dies war vor geraumer Zeit ein MyISAM, und die MyISAM-Dateien sind nach
einer Woche wie oben beschrieben gepackt worden.  Nachdem die Load auf dem
Eventlog so groß geworden ist, daß das System durch Zuziehen der MyISAM
Write-Locks auf den heißen Tabellen Performanceprobleme bekam, haben wir die
heißen Tabellen auf InnoDB umgestellt und konvertieren jetzt nach einer
Woche in compressed MyISAM.&lt;/p&gt;
&lt;p&gt;Problem sind nun eher die laufenden Aggregationen, die schon vor langer Zeit
dadurch begrenzt wurden, daß jede einzelne Query in MySQL immer nur mit
einem Core arbeiten kann.  Durch Auslagern der Aggregationen aus der
Datenbank in Clients und durch geschickte Programmierung der Clients kann
nun über mehrere Cores und sogar mehrere Maschinen parallel aggregiert
werden.&lt;/p&gt;
&lt;p&gt;Dies ist jedoch ein unangemessener Programmieraufwand.  Tatsächlich wird
dieses System durch einen kleinen Hadoop Cluster mit Hive und Flume
abgelöst.&lt;/p&gt;
&lt;p&gt;Hadoop HDFS speichert Dateien, die danach Immutable sind - neueres HDFS hat
jedoch einen Append Mode für diese Daten.  Auf diese Weise können die Daten
auf JBOD redundant gespeichert werden und man braucht sich nicht mehr um
Storage und seine Kosten zu sorgen.&lt;/p&gt;
&lt;p&gt;Hadoop MapReduce erlaubt es, Auswertunge auf diesen Daten automatisch intern
konkurrent zu fahren.&lt;/p&gt;
&lt;p&gt;Dafür Code zu schreiben ist jedoch unangemessen, daher kommt Hive oben drauf -
Hive kompiliert Anfragen in einem SQLishen Dialekt in Java Sourcecode, der
auf dem Hadoop MapReduce Framework parallel ausgeführt werden kann.  Die
Beschleunigung ist dabei nahezu linear - Hive-Anfragen wurden auf einem
5-Blade-Cluster mit 60 Cores in etwa 56 mal schneller ausgeführt als die
identische Query auf einem MySQL.  Mit HiveODBC können die Analysten dabei
ihr bestehendes Tooling weiterverwenden - für sie wird nur das Backend sehr
viel schneller.&lt;/p&gt;
&lt;p&gt;Flume ist ein Framework, daß Logdaten live transformieren, voraggregieren
und in Hadoop/Hive laden kann.&lt;/p&gt;
&lt;p&gt;Die Kombination wird die Performance- und Skalierungsprobleme von
Eventlogging grundsätzlich lösen und die MyISAM und InnoDB inhärenten
Probleme durch neue, aufregende und bisher noch unbekannte Probleme ersetzen -
und wie wir erwarten, auf einem höheren Level.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

